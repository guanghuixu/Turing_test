in this paper , we propose a data-driven approach to phone set construction for code-switching speech recognition . in our data-driven approach , a large-scale code-switching speech database is used for model training . in the proposed data-driven approach , a hierarchical phone unit clustering algorithm is adopted for model construction . in the proposed data-driven approach , a set of acoustic features and a set of cross-lingual context-sensitive articulatory features are extracted from the acoustic features in the distance measure . in the proposed data-driven approach , the phone set construction is performed by maximizing the kl-divergence between the acoustic features in the distance measure and the acoustic features in the distance measure . the experimental results show that the proposed data-driven approach outperforms the conventional phone set construction methods . in addition , the proposed data-driven approach has the potential to alleviate the data sparseness problem in code-switching speech recognition .(A) [1分]
A. Machine
B. Human

we consider the problem of bipartite graph inference in a supervised learning problem . given a network topology of the bipartite graph , we formulate the bipartite graph inference as an optimization problem in a reproducing kernel hilbert space . the objective is to find the optimal solution in a unified euclidean space , where the objective is to find the optimal solution in a unified euclidean space . we demonstrate the effectiveness of our approach on a variety of compound-protein interaction network reconstruction from chemical structure data and genomic sequence data .(A) [1分]
A. Machine
B. Human

in this paper , we propose a point set registration algorithm based on the bidirectional em process . the proposed point set registration algorithm consists of a robust gaussian mixture model with a noise component that is robust to outliers . the proposed point set registration algorithm is evaluated on both synthetic data and point sets obtained from medical images . the accuracy and robustness of the proposed point set registration algorithm is compared to the state-of-the-art registration techniques . the results show that the proposed point set registration algorithm is robust to outliers and is robust to outliers .(A) [1分]
A. Machine
B. Human

we propose a two-layer undirected graphical model , a two-layer undirected graphical model , for learning low-dimensional latent semantic representations from a unstructured collection of documents . two-layer undirected graphical model is a generalization of latent dirichlet allocation , which allows the two-layer undirected graphical model to scale to large collections of held-out documents . we derive learning and inference algorithms for the two-layer undirected graphical model , and evaluate two-layer undirected graphical model on two datasets , showing that two-layer undirected graphical model outperforms latent dirichlet allocation in terms of retrieval accuracy .(A) [1分]
A. Machine
B. Human

noise power spectral density -lrb- pesq -rrb- is one of the most popular speech enhancement algorithms . in this paper , we propose a low complexity method for noise psd estimation based on minimum mean-squared error estima-tor . the low complexity method is based on the minimum mean-squared error estima-tor of the noise magnitude-squared dft coefficients of the noisy data . the proposed low complexity method is suitable for non-stationary noise sources with segmental snr and pesq for non-stationary noise sources . the simulation results show that the proposed low complexity method outperforms the conventional methods in terms of both segmental snr and pesq for non-stationary noise sources . the computational complexity of the proposed low complexity method is much lower than that of minimum statistics based noise tracking .(A) [1分]
A. Machine
B. Human

this paper describes the development of a unified dutch and german speech recognition system in the speechdat domain . the unified dutch and german speech recognition system consists of three components : the acoustic component of the unified dutch and german speech recognition system , the language dependent phoneme models , and the language dependent phoneme models . the first unified dutch and german speech recognition system is based on the mce-based training algorithm . the second unified dutch and german speech recognition system is evaluated on the dutch and german subword recognition tasks . the unified dutch and german speech recognition system is compared with the mce-trained multilingual system in the speechdat domain . the unified dutch and german speech recognition system achieves a overall string error rate reduction of 24.3 % , which is significantly better than the mce-trained multilingual system .(A) [1分]
A. Machine
B. Human

descriptor learning plays an important role in computer vision . in this paper , we propose a novel supervised descriptor learning algorithm to learn discriminative and compact feature representation for multi-output regression . the proposed supervised descriptor learning algorithm is based on supervised manifold regularization to learn generalized low-rank approximations of matrices in a low-dimensional space . the proposed supervised descriptor learning algorithm is able to learn a discriminative and compact feature representation for multi-output regression without supervision of multivariate targets . the proposed supervised descriptor learning algorithm is evaluated on a benchmark pointing '04 dataset for head pose estimation . the experimental results show that the proposed supervised descriptor learning algorithm achieves better estimation accuracy than the state-of-the-art methods in multi-output regression tasks . in addition , the proposed supervised descriptor learning algorithm can also be applied to any representative multi-output regression task . the proposed supervised descriptor learning algorithm can also be applied to any other descriptor learning framework in computer vision .(A) [1分]
A. Machine
B. Human

in this paper , we propose a novel approach for facial age estimation based on ordinal discriminative feature learning . in our approach , each image is represented by a local manifold structure of facial images , and each image is represented by a set of ordinal information . in order to capture the redundant information in the aging process , we propose to use rank correlation and nonlinear correlation for feature selection . in order to capture the locality information in the face , we propose a novel method to learn the ordinal information for age estimation . the proposed method is evaluated on two public available images of groups dataset , and the experimental results show that the proposed method achieves better performance than the state-of-the-art methods . moreover , the proposed method is very effective for aging faces .(A) [1分]
A. Machine
B. Human

personal use of this material is permitted . however , permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists , or to reuse any copyrighted component of this work in other works must be obtained from the ieee . abstract in this paper , we propose a novel method for the recognition of the 3d surface of human faces using 3d facial depth maps . the method is based on summation invariants . the 3d facial depth map is obtained from a rectangular region , and the 3d facial depth map is obtained from the 3d facial depth maps . the proposed method is evaluated on the v1 .0 dataset . the experimental results show that the proposed method can improve the recognition of the 3d surface of human faces by more than 10 % compared to the baseline method . moreover , the proposed method can also be used for other works , such as the v1 .0 dataset .(A) [1分]
A. Machine
B. Human

in this paper , we propose a bilingual lexical cohesion trigger model to capture lexical cohesion for document-level machine translation . the bilingual lexical cohesion trigger model is a generalization of the bilingual lexical cohesion trigger model to hierarchical phrase-based machine translation . experimental results on nist chinese-english test sets show that our bilingual lexical cohesion trigger model can significantly improve the translation performance of document-level machine translation .(A) [1分]
A. Machine
B. Human

finite-state modeling techniques have been successfully applied to language modeling in automatic speech recognition systems . in this paper , we present written-domain language modeling approaches to language modeling in the verbal domain , where lexical and non-lexical entities are expressed in the written domain . our written-domain language modeling approaches is based on a newly proposed formalal-domain language model , which is designed to deal with data sparsity problems in the written domain . the proposed written-domain language modeling approaches is based on a novel decomposition -- recomposition approach to deal with out-of-vocabulary and non-lexical entities such as dollar amounts , phone numbers , and e-mail addresses . the proposed written-domain language modeling approaches is evaluated in terms of speech recognition performance and asr transcript rendering accuracy . the results show that the proposed written-domain language modeling approaches is effective in improving speech recognition performance in the written domain , and that the proposed written-domain language modeling approaches can also be applied to other domains , such as en-glish .(A) [1分]
A. Machine
B. Human

this paper describes the development of a large vocabulary speech recognition system for broadcast news transcription . the large vocabulary speech recognition system is designed for both clean and noisy read speech tasks . unsupervised model adaptation is performed using maximum likelihood linear regression , and maximum likelihood linear regression is used to adapt the parameters of the htk large vocabulary systems with various features such as decoder-guided segmentation , segment clustering , and language modelling . the resulting large vocabulary speech recognition system is evaluated on the h4 evaluation . the results show that the proposed large vocabulary speech recognition system is very competitive with the state of the art in both clean and noisy read speech tasks . dierent front-end analyses of the large vocabulary speech recognition system are also presented .(A) [1分]
A. Machine
B. Human

in this paper , we propose a new model based sparse principal component analysis method . the proposed model based sparse principal component analysis method is based on the l 0 penalty , which is an associated model selection method . the proposed estimation method is based on the iterative hard thresholding and the generalized em algorithm . the proposed estimation method has been tested on simulated data and dna microarray data . the experimental results show that the proposed estimation method outperforms the conventional sparse pca method .(A) [1分]
A. Machine
B. Human

in this paper , we propose a directionally adaptive image interpolation based on directionlets . directionlets are a multiple-direction wavelet transform that encodes the edge information of a high-resolution image . directionally adaptive image interpolation uses directionlets to extract directional features from a low-resolution image . directionlets are then used to estimate the quality of the interpolated image . the directionally adaptive image interpolation is evaluated in terms of both numeric and visual quality . experimental results show that directionally adaptive image interpolation produces better results than the state-of-the-art methods .(A) [1分]
A. Machine
B. Human

this paper presents a method for characterizing human heart beat intervals in electrocardiogram data . the method is based on probabilistic models of the inverse gaussian model used for analysis of autonomic control . the method is based on the adaptive point process filtering paradigm and the kolmogorov-smirnov test . the method is tested on respiratory covariate measurements and the dynamic respiratory sinus arrhythmia analysis . the results show that the proposed method is able to accurately predict the index of vagal control dynamics in the inverse gaussian model of the instantaneous rsa gain .(A) [1分]
A. Machine
B. Human

overlapping acoustic event detection aims at detecting the temporal evolution of sound events in an input time/frequency representation . in this paper , we propose a novel approach to detect overlapping acoustic events based on probabilistic latent component analysis . first , we propose a novel sound event dictionary based on event class-wise hidden markov models . then , the event class-wise hidden markov models is used to generate a sound event dictionary from the equivalent rectangular bandwidth spectrogram . the proposed approach is evaluated on two polyphonic datasets of office sounds using an acoustic scene simulator . the experimental results show that the proposed method outperforms the state-of-the-art frame-based and event-based metrics . furthermore , the proposed method is also shown to be effective in detecting overlapping events in both real and synthesized monophonic datasets .(A) [1分]
A. Machine
B. Human

tensor null space invariants -lrb- tensor null space invariants -rrb- are widely used for archiv-ing and searching motion events in high order data classification . however , tensor null space invariants are not suitable for multidimensional affine transformations because tensor null space invariants are not invariant to camera motions . in this paper , we propose a novel representation for tensor null space invariants , which is based on ten-sor based null space affine invariants . tensor null space invariants can be used for archiv-ing and searching motion events , which can be used for retrieval and retrieval system . a linear classifier is used to classify consecutive motion events . experimental results show the effectiveness of the proposed representation .(A) [1分]
A. Machine
B. Human

we present a top-down induction of decision trees method for clustering in both propositional and re-lational domains . the top-down induction of decision trees method is based on an order logical decision tree representation of the domain . we show that this top-down induction of decision trees method is competitive with instance based learning , and that top-down induction of decision trees method is superior to clustering in both propositional and re-lational domains .(A) [1分]
A. Machine
B. Human

in this paper , we investigate the use of context-expanded region-dependent linear transforms for acoustic modeling in large vocabulary continuous speech recognition . context-expanded region-dependent linear transforms are trained using lattice-based discriminative training , long-span features , weight expansion , and contextual weight expansion . context-expanded region-dependent linear transforms are trained using the maximum mutual information criterion . lattice-based , boosted mmi training is used to combine context-expanded region-dependent linear transforms with hmms . the proposed context-expanded region-dependent linear transforms is evaluated on the switchboard-1 conversational telephone speech transcription task . compared with gmm-hmms , the proposed context-expanded region-dependent linear transforms achieves a relative word error rate reduction of 12.5 % , which is comparable to the conventional gmm-hmms . furthermore , the proposed context-expanded region-dependent linear transforms can be combined with hmms with context-expanded region-dependent linear transforms .(A) [1分]
A. Machine
B. Human

optical flow estimation algorithms have been widely used to solve ill-posed problems . however , most of the existing optical flow estimation algorithms focus on single or fixed data model . in this paper , we propose a novel approach to improve optical flow estimation energy model by incorporating complementary data models into the optical flow framework . specifically , we propose a locally varying data term to combine the complementary data models with a single or fixed data model . the complementary data models are designed to capture the matching ambiguity between the data and regularization terms in a locally varying data term . the complementary data models are optimized to minimize the weighted sum of the complementary data models . the complementary data models are then combined with a minimum description length constraint to reduce the matching ambiguity . experimental results on the middlebury optical flow benchmark show that our approach significantly outperforms state-of-the art methods .(A) [1分]
A. Machine
B. Human

cross language classification aims to learn label knowledge from parallel documents . however , most existing domain adaptation methods and multi-view learning methods are not applicable to multilingual text classification problems . in this paper , we propose a subspace co-regularized multi-view learning method for cross language text classification using machine translation on parallel corpora . the proposed subspace co-regularized multi-view learning method is based on the idea of machine translation , which aims to reduce the labeling cost of a classification model . the proposed subspace co-regularized multi-view learning method is evaluated on two cross language text classification tasks . the experimental results show that the proposed subspace co-regularized multi-view learning method significantly outperforms the state-of-the-art inductive methods . moreover , the proposed subspace co-regularized multi-view learning method can be easily extended to multilingual text classification problems .(A) [1分]
A. Machine
B. Human

in this paper , we present a novel approach to dialog act tagging based on support vector machines and hidden markov models . in contrast to traditional sequence labelling algorithms which estimate posterior probabilities from text and acoustic features , our approach combines sparse high-dimensional text features and dense low-dimensional acoustic features . we evaluate our approach on the hcrc maptask corpus , and show that our approach outperforms the state of the art . we also show that our approach is competitive with support vector machines .(A) [1分]
A. Machine
B. Human

in this paper , we propose a weighted sum rate optimization for the mimo interfering multiple access channel . the weighted sum rate optimization is formulated as a noncooperative game , where the bs congestion is assumed to be known at the base station -lrb- bs -rrb- and the base station -lrb- bs -rrb- is assumed to be known at the base station -lrb- bs -rrb- . we formulate the weighted sum rate optimization problem as a weighted sum rate optimization problem with a stationary solution . we show that the nash equilibrium of the weighted sum rate optimization problem converges to a stationary solution of the weighted sum rate optimization problem . numerical results show that the proposed weighted sum rate optimization outperforms the conventional linear procoders in terms of user fairness and user fairness .(A) [1分]
A. Machine
B. Human

in this paper , we propose a novel approach to estimate the instantaneous frequency and the instantaneous phase of a target signal using the discrete evolutionary transform . the discrete evolutionary transform is based on the representation of the time-dependent spectrum of the target signal , and discrete evolutionary transform is applied to the time-frequency kernel and non-stationary signals in the noiseless and noisy situations . in the proposed method , the instantaneous frequency is estimated by masking and a recursive non-linear correction procedure . in the proposed method , the instantaneous frequency is estimated by time-frequency analysis of the direct sequence spread spectrum , and the instantaneous frequency is estimated by the masking and the recursive non-linear correction procedure . in the proposed method , the instantaneous frequency is estimated by the discrete evolutionary transform . the experimental results show that the proposed method is effective in estimating the instantaneous frequency direct sequence spread spectrum of the target signal , and the proposed method can estimate the instantaneous frequency of the target signal from the target signal .(A) [1分]
A. Machine
B. Human

in this paper , we propose a novel session variability subspace projection svspbased model compensation method for speaker verification . the proposed session variability subspace projection svspbased model compensation method is composed of two components : ubm and compensated speaker models . the first component of the session variability subspace projection svspbased model compensation method is to reduce the mismatch between the ubm and the compensated speaker models . experimental results show that the proposed session variability subspace projection svspbased model compensation method can reduce the relative equal error rate reduction of the gmm-ubm system .(A) [1分]
A. Machine
B. Human

we present a nonparametric approach to estimating drift functions from sparse observations of the state vector . our nonparametric approach is based on a piecewise linearized process , where each state vector is represented by a piecewise linearized process , and the posterior over states is estimated by a sparse gaussian process regression . we derive an approximate em algorithm for learning the posterior over states , and apply approximate em algorithm to map estimation in the presence of unobserved , latent dynamics . we apply our nonparametric approach to the problem of estimating drift functions in stochastic differential equations , where the ornstein-uhlenbeck type is known to be an ornstein-uhlenbeck type .(A) [1分]
A. Machine
B. Human

in this paper , we investigate the use of cross-lingual bottleneck features for acoustic models , such as deep neural networks and gaussian mixture models . we propose a non-parametric kernel density estimation method to estimate the emission probability of hmm states given the speech training data . in the proposed non-parametric kernel density estimation method , speech class posteriors are represented by a kernel density , which is then used to estimate the emission probability of hmm states . we evaluate the proposed non-parametric kernel density estimation method on the wall street journal task and show that the proposed non-parametric kernel density estimation method outperforms the conventional acoustic models when the amount of training data is limited . furthermore , we show that the proposed non-parametric kernel density estimation method can be applied to both gmm and dnn models for the limited training data case .(A) [1分]
A. Machine
B. Human

network topology control in wireless networks is an important research area . in this paper , we propose a fully distributed algorithm for network topology control in wireless networks . the fully distributed algorithm is based on game theory concepts and is able to achieve joint power and topology control of a connected network . simulation results show that the proposed fully distributed algorithm is able to achieve a non-cooperative game with a small number of agents .(A) [1分]
A. Machine
B. Human

in this paper , we consider the sum-rate of a multihop wireless sensor network with complex amplification coefficients at the relay node . we propose an alternating optimization approach to jointly optimize the power allocation parameters and the linear receiver . we derive constrained maximum sum-rate expressions for the achievable sum-rate of a multihop wireless sensor network with equal power allocation at the relay node . we also propose an amplify-and-forward scheme to maximize the sum-rate of a multihop wireless sensor network with complex amplification coefficients . simulation results show that the proposed alternating optimization approach can significantly improve the sum-rate of a multihop wireless sensor network .(A) [1分]
A. Machine
B. Human

single channel source separation -lrb- single channel source separation -rrb- is a challenging problem in single channel source separation . in this paper , we propose a deep neural network architecture based on nonnegative matrix factorization to address the single channel source separation problem . in the training stage , a mixed signal spectrum is learned from the estimated source spectra . in the training stage , a deep neural network architecture is trained to separate the source signals from the mixed signal spectrum . in the training stage , a deep neural network architecture is trained to separate the target signals from the training data . in the separation stage , a deep neural network architecture is trained to separate the target signals from the training data . in the training stage , the energy scale differences between the source and the target signals are minimized . in the testing stage , the deep neural network architecture is used to separate the source signals from the background . in the testing stage , the deep neural network architecture is used to separate the target signals from the background . in the testing stage , the deep neural network architecture is used to separate the source signals from the background . the experimental results show that the proposed deep neural network architecture outperforms the state-of-the-art methods for source separation .(A) [1分]
A. Machine
B. Human

in this paper , we consider the problem of decoding binary symbols transmitted by a linear isi channel corrupted with additive white noise . we propose a receiver based on a variable order markov model , which is trained using a crudely quantized training sequence . the variable order markov model is then used to train the receiver for the inter-symbol interference channel . the maximum likelihood sequence estimator is then used to estimate the inter-symbol interference channel . we compare the performance of the proposed receiver with other gaussian based algorithms such as decision feedback equalization , gradient based adaptation , and decision feedback equalization . the results show that the proposed receiver achieves better receiver performance in the presence of heavy-tailed noise compared to the conventional maximum likelihood sequence estimator .(A) [1分]
A. Machine
B. Human

in this paper , we propose a novel acoustic model for statistical parametric speech synthesis based on neural networks for statistical parametric speech synthesis . in the proposed acoustic model , linguistic features of the speech waveform are modeled as stochastic components in the probability density function of the speech waveform . in the proposed acoustic model , the unvoiced component is modeled as a gaussian process , where the mean and covariance functions of the speech waveforms are modeled as a non-zero mean gaussian process , and the unvoiced component is modeled by a set of neural networks . the experimental results show that the proposed acoustic model can generate natural speech waveforms with high quality speech waveforms .(A) [1分]
A. Machine
B. Human

personal use of this material is permitted . however , permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists , or to reuse any copyrighted component of this work in other works must be obtained from the ieee . abstract in this paper , we consider the problem of spectrum sensing and anomaly detection in cognitive radio . we propose a novel soft decision detector for spectrum sensing and anomaly detection , which is based on a bayesian approach . the soft decision detector is able to perform signal denoising and anomaly detection in the presence of noise . the performance of the soft decision detector is evaluated by comparing its performance to that of the soft decision detector for signal denoising and anomaly detection in the presence of noise . the results show that the soft decision detector is able to perform well in the presence of noise .(A) [1分]
A. Machine
B. Human

in this paper , we propose a birdsong-phrase segmentation and verification algorithm for segmenting continuous recordings with additive noise . the birdsong-phrase segmentation and verification algorithm consists of a noise-robust template and a discriminative classifier for outlier rejection . the proposed birdsong-phrase segmentation and verification algorithm consists of two steps : -lrb- 1 -rrb- a support vector machine to estimate segment boundaries , and -lrb- 2 -rrb- a support vector machine to estimate segment boundaries . the proposed birdsong-phrase segmentation and verification algorithm is robust to noise , class variability , and limited training data . the proposed birdsong-phrase segmentation and verification algorithm is evaluated on cassin 's vireo recordings . the results show that the proposed birdsong-phrase segmentation and verification algorithm outperforms the state-of-the-art energy or entropy-based birdsong segmentation algorithms . moreover , the proposed birdsong-phrase segmentation and verification algorithm does not require manual annotations for training .(A) [1分]
A. Machine
B. Human

in this paper , we consider adaptive channel predictors for orthogonal frequency division multiplexing communications over time-varying channels . adaptive channel pre-dictors are proposed for delay-free equalization . the proposed adaptive channel pre-dictors are based on the normalized least-mean-square and recursive least-squares algorithms . simulation results show that the proposed adaptive channel predictors outperform the normalized least-mean-square in the presence of time-varying channels .(A) [1分]
A. Machine
B. Human

scribbles are an important part of mobile touch-screen devices . in this paper , we propose a novel scrible-based interactive segmentation called graph-cut . scribbles are detected as foreground scribble pixels in the image , and the foreground scribble pixels are detected as foreground scribble pixels in the image . the scribbles are detected by minimizing the ratio energy function of the graph-cut energy with respect to user input information . the robustness of the ratio energy function is measured by the iterated graph cut algorithm . the proposed ratio energy function is evaluated on synthetic scribbles and manual scribbles on the grabcut dataset . the experimental results show that the proposed ratio energy function achieves better segmentation results than the state-of-the-art methods . moreover , the proposed ratio energy function can be used to improve the graph-cut energy .(A) [1分]
A. Machine
B. Human

in this paper , we propose a talker 's head orientation estimation method based on talker localization and head orientation estimation using a network of microphone arrays . the talker 's head orientation is represented by csp -lrb- cross-power spectrum phase -rrb- coefficients , which represent the talker 's position , the head orientation , and the talker 's position . in the proposed talker 's head orientation estimation method , the talker 's head orientation is represented by the csp -lrb- cross-power spectrum phase -rrb- coefficients . in the proposed talker 's head orientation estimation method , the feature vectors of the csp coefficients of the cross-power spectrum phase -lrb- cross-power spectrum phase -rrb- coefficients are used to estimate the talker 's head orientation . the experimental results show that the proposed talker 's head orientation estimation method can accurately estimate the talker 's position from 2-channel microphones without reverberation , and the proposed talker 's head orientation estimation method can estimate the talker 's head orientation from the microphone array sub-microphone arrays . the experimental results show that the proposed talker 's head orientation estimation method can accurately estimate the talker 's position from the 2-channel microphones .(A) [1分]
A. Machine
B. Human

speech separation based on time-frequency masking has been shown to improve the intelligibility of speech signals . in this paper , we propose a novel method to improve the perceptual quality of separated speech by incorporating time-frequency masking into speech separation . in the proposed method , a sparse-representation approach is used to decompose the separated signal into a clean speech dictionary and the short-time fourier transform magnitudes of the separated speech signal . in the proposed method , the separated speech is first converted into a clean speech dictionary , and then the speech signal is transformed into a clean speech dictionary . in the proposed method , the separated speech is separated using the proposed method , and the speech quality measure is calculated based on the perceptual evaluation of speech quality . experimental results show that the proposed method outperforms the conventional binary-masked noisy speech and other reconstruction approaches in terms of speech quality . moreover , the proposed method is able to improve the perceptual quality of separated speech when compared to the conventional methods .(A) [1分]
A. Machine
B. Human

in this paper , we propose an ensemble framework for probability density estimation in hidden markov model with insufficient training data . the proposed ensemble framework consists of a gradient descent search in the function space and a learning algorithm for the gaussian mixture densities . the state emission densities are estimated by minimizing the sum of free parameters of a hidden markov model and a boosting baum-welch algorithm . in the proposed ensemble framework , the mean and variance of the gaussian mixture state emission densities are estimated using the baum-welch algorithm . the proposed ensemble framework is applied to the problem of emotion recognition . the experimental results show that the proposed ensemble framework is effective in reducing the number of free parameters required for training the gaussian mixture densities .(A) [1分]
A. Machine
B. Human

in this paper , we consider the problem of multi-output fir systems driven by white non-gaussian source signals driven by white non-gaussian source signals . we propose a new maximization criteria for blind deconvolution of mimo fir systems driven by the so-called i.i.d. condition . the proposed maximization criteria are based on adaptive algorithms for blind deconvolution of mimo fir systems with source signals driven by white source signals . simulation results demonstrate the effectiveness of the proposed maximization criteria .(A) [1分]
A. Machine
B. Human

in this paper , we propose a corpus-based singing voice synthesis system based on hmm-based speech synthesis . the corpus-based singing voice synthesis system is designed to synthesize a smooth and natural-sounding singing voice . the corpus-based singing voice synthesis system uses hidden markov models to model the singing voice as a context-dependent hmm . in the proposed corpus-based singing voice synthesis system , a context-dependent hmm is used to model the singing style . the proposed corpus-based singing voice synthesis system is evaluated in terms of voice quality and naturalness . the results show that the proposed corpus-based singing voice synthesis system can synthesize a singing voice with high quality .(A) [1分]
A. Machine
B. Human

we present a variational inference algorithm for bayesian non-conjugate inference in continuous parameter spaces . the variational inference algorithm is based on stochastic approximation of the stochastic optimi-sation . the variational inference algorithm can be interpreted as a stochastic approximation of the model joint density and kernel hyperparameters in gaussian process regression . the variational inference algorithm can be interpreted as a stochastic optimi-sation of the variational inference algorithm . illustrative examples are provided to illustrate the effectiveness of the proposed variational inference algorithm . the proposed variational inference algorithm is applied to bayesian inference problems such as variable selection and logistic regression .(A) [1分]
A. Machine
B. Human

log mel-filterbanks -lrb- log mel-filterbanks -rrb- are widely used for adaptation of the auditory system under adverse conditions . in this paper , we propose a novel feature normalization method based on the computation load in log mfb domain using cepstral post-processing techniques . non-linear contrast stretching is applied to log mel-filterbanks to improve the noise robustness of log mel-filterbanks in adverse conditions . the processing artifacts are reduced by a two-dimensional filter in the log mfb domain using the log-scaled spectral domain . the proposed feature normalization method is compared with the baseline mfcc system in terms of both objective and objective measures . the experimental results show that the proposed feature normalization method outperforms the baseline mfcc system in terms of both objective and objective measures .(A) [1分]
A. Machine
B. Human

in this paper , we present a dialogue management strategy limited enquiry negotiation dialogues that can be used to analyze the dialogue behaviour of a dialogue designer . the dialogue management strategy limited enquiry negotiation dialogues consists of two components : a toolbox menu-traversal and slot-filling , and a dialogue designer 's standard components . we describe the dialogue management strategy limited enquiry negotiation dialogues , and describe how dialogue management strategy limited enquiry negotiation dialogues can be used to analyze the dialogue designer 's standard components . the dialogue management strategy limited enquiry negotiation dialogues has been implemented in a dialogue management strategy limited enquiry negotiation dialogues , and the dialogue management strategy limited enquiry negotiation dialogues has been designed to be used to evaluate the dialogue management strategy limited enquiry negotiation dialogues .(A) [1分]
A. Machine
B. Human

in this paper , we propose a m-vector approach to speaker verification based on maximum likelihood linear regression super-vectors . in the m-vector approach , the maximum likelihood linear regression super-vectors is obtained by matching lattice word transcriptions with the universal background model . in the m-vector approach , a uniform segmentation of the maximum likelihood linear regression super-vectors is used to estimate the maximum likelihood linear regression super-vectors . in the m-vector approach , the maximum likelihood linear regression super-vectors is used to estimate the maximum likelihood linear regression super-vectors from the 1-best -lrb- hypothesis -rrb- lattice word transcriptions . in the m-vector approach , the phonetic content of the lattice word transcriptions is used to estimate the maximum likelihood linear regression super-vectors . the proposed m-vector approach is evaluated on the nist sre 2008 core condition . experimental results show that the proposed m-vector approach is effective in reducing asr transcription errors .(A) [1分]
A. Machine
B. Human

in this paper , we propose a robust iterative hard thresolding algorithm for reconstructing sparse signals in impulsive environments . the proposed robust iterative hard thresolding algorithm is based on the idea of iht , which is a generalization of the iht algorithm to heavy-tailed models . the proposed robust iterative hard thresolding algorithm is based on the idea of iht , which is a generalization of iht to impulsive noise . the robustness of the proposed robust iterative hard thresolding algorithm is evaluated by comparing robust iterative hard thresolding algorithm with other recently proposed sparse reconstruction techniques . the experimental results show that the proposed robust iterative hard thresolding algorithm achieves better reconstruction quality in the presence of impulsive noise compared to the existing sparse reconstruction techniques .(A) [1分]
A. Machine
B. Human

common spatial patterns algorithm -lrb- common spatial patterns algorithm -rrb- is a widely used tool in eeg classification and brain computer interface . in this paper , we propose a multilinear formulation for the common spatial patterns algorithm . the multilinear formulation is based on tensor analysis theory for simultaneous optimization of projection matrices and high-order tensor data . the proposed multilinear formulation has several advantages over common spatial patterns algorithm in terms of classification accuracy for multi-class motor imagery eeg . first , the proposed multilinear formulation can be applied to any specific class of common spatial patterns algorithm . second , the proposed multilinear formulation can be applied to any specific class of common spatial patterns algorithm . third , the proposed multilinear formulation can be applied to any specific class of multi-class motor imagery eeg . experimental results show that the proposed multilinear formulation can significantly improve the classification accuracy of common spatial patterns algorithm .(A) [1分]
A. Machine
B. Human

in this paper , we evaluate the performance of four objective quality measures for assessing the quality of reverberant and dereverberated speech in terms of overall speech quality , reverberation tail effect , speech coloration , and reverberation tail effect . we compare the subjective rating scales of four different dereverberation algorithms and compare their performance with respect to subjective quality ratings . the results show that the proposed objective quality measures can be used to assess the performance of a variety of objective quality measures . we also show that the proposed objective quality measures can be used to assess the quality of reverberant speech .(A) [1分]
A. Machine
B. Human

distributed kalman filtering is a classical problem in which the communication resource allocation policy is maximized . in this paper , we propose a scal-able wireless communication architecture based on the data driven average consensus framework . the scal-able wireless communication architecture allows us to exploit the inherent structure of the distributed application in wireless sensor networks . the scal-able wireless communication architecture is based on a data driven average consensus framework , which allows us to exploit the inherent structure of the kalman filtering in order to reduce the component-wise state estimation error . we show that the proposed scal-able wireless communication architecture can be applied to any number of distributed filtering computations . the proposed scal-able wireless communication architecture can be easily applied to any distributed application where filtering is performed .(A) [1分]
A. Machine
B. Human

in this paper , we propose a rspec based instantaneous frequency estimator for the analysis of nonstationary signals corrupted by heavy-tailed distribution noise in the analysis of signals . the rspec based instantaneous frequency estimator is based on a time-varying window length , which is known to be robust to rare high magnitude noise values . the proposed rspec based instantaneous frequency estimator is based on the analysis of signals corrupted by heavy-tailed distribution noise . the proposed rspec based instantaneous frequency estimator has a bias-variance trade-off between the accuracy of the rspec based if estimation and the performance of the adaptive algorithm . simulation results show that the proposed rspec based instantaneous frequency estimator outperforms the existing methods in terms of the accuracy of the estimation of the window length .(A) [1分]
A. Machine
B. Human

this paper describes an experiment comparing the effect of two different approaches to information presentation on item recall . the results show that using discourse cues facilitates recalling the presented information .(B) [1分]
A. Machine
B. Human

belief revision is a ubiquitous process underlying many forms of intelligent behaviour . the agm paradigm is a powerful framework for modeling and implementing belief revision systems based on the principle of minimal change ; agm paradigm provides a rich and rigorous foundation for computer-based belief revision architectures . maxi-adjustment is a belief revision strategy for theory bases that can be implemented using a standard theorem prover , and one that has been used successfully for several applications . in this paper we provide an anytime decision procedure for maxi-adjustments , and study its complexity . furthermore , we outline a set of guidelines that serve as a protomethodology for building belief revision systems employing a maxi-adjustment . the anytime decision procedure is under development in the belief revision module of the cin project .(B) [1分]
A. Machine
B. Human

in this paper , we propose a novel general framework for ten-sor based null space affine invariants , namely , tensor null space invariants with a linear classifier for high order data classification and retrieval . we first derive tensor null space invariants , which is perfectly invariant to multidimensional affine transformations due to camera motions for multiple motion trajectories in consecutive motion events . we subsequently propose an efficient classification and retrieval system relying on tensor null space invariants for archiv-ing and searching motion events consisting of multiple motion trajectories . the simulation results demonstrate superior performance of the proposed classification and retrieval system .(B) [1分]
A. Machine
B. Human

in an extended image sequence of an outdoor scene , one observes changes in color induced by variations in the spectral composition of daylight . this paper proposes a model for these temporal color changes and explores its use for the analysis of outdoor scenes from time-lapse video data . we show that the time-varying changes in direct sunlight and ambient skylight can be recovered with this model , and that an image sequence can be decomposed into two corresponding components . the decomposition provides access to both radiometric and geometric information about a scene , and we demonstrate how this can be exploited for a variety of visual tasks , including color-constancy , background subtraction , shadow detection , scene reconstruction , and camera geo-location .(B) [1分]
A. Machine
B. Human

we present a unified model for face detection , pose estimation , and landmark estimation in real-world , cluttered images . our unified model is based on a mixtures of trees with a shared pool of parts ; we unified model every facial landmark as a part and use global mixtures to capture topological changes due to viewpoint . we show that tree-structured models are surprisingly effective at capturing global elastic deformation , while being easy to optimize unlike dense graph structures . we present extensive results on standard face benchmarks , as well as a new '' in the wild '' annotated dataset , that suggests our unified model advances the state-of-the-art , sometimes considerably , for all three tasks . though our unified model is modestly trained with hundreds of faces , unified model compares favorably to commercial systems trained with billions of examples -lrb- such as google picasa and face.com -rrb- .(B) [1分]
A. Machine
B. Human

an associative memory is a structure learned from a dataset m of vectors -lrb- signals -rrb- in a way such that , given a noisy version of one of the vectors as input , the nearest valid vector from m -lrb- nearest neighbor -rrb- is provided as output , preferably via a fast iterative algorithm . traditionally , binary -lrb- or q-ary -rrb- hopfield neural networks are used to model the above structure . in this paper , for the first time , we propose a model of associative memory based on sparse recovery of signals . our basic premise is simple . for a dataset , we learn a set of linear constraints that every vector in the dataset must satisfy . provided these linear constraints possess some special properties , it is possible to cast the task of finding nearest neighbor as a sparse recovery problem . assuming generic random models for the dataset , we show that it is possible to store super-polynomial or exponential number of n-length vectors in a neural network of size o -lrb- n -rrb- . furthermore , given a noisy version of one of the stored vectors corrupted in near-linear number of coordinates , the vector can be correctly recalled using a neurally feasible algorithm .(B) [1分]
A. Machine
B. Human

efficient two-step algorithms are described for optimizing the stopband response of the prototype filter for cosine-modulated and modified dft filter banks either in the minimax or in the least-mean-square sense subject to the maximum allowable aliasing and amplitude errors . the first step involves finding a good start-up solution using a simple technique . this start-up solution is improved in the second step by using nonlinear optimization . several examples are included illustrating the flexibility of the proposed start-up solution for making compromises between the required filter lengths and the aliasing and amplitude errors . these examples show that by allowing very small amplitude and aliasing errors , the stopband performance of the resulting prototype filter is significantly improved compared to the corresponding perfect-reconstruction filter bank . alternatively , the filter orders and , consequently , the overall delay can be significantly reduced to achieve practically the same performance .(B) [1分]
A. Machine
B. Human

we resolve a several-years old open question in visibility-based pursuit evasion : how many pursuers are needed to capture an evader in an arbitrary polygonal environment with obstacles ? the evader is assumed to be adversarial , moves with the same maximum speed as pursuers , and is '' sensed '' by a pursuer only when it lies in line-of-sight of that pursuer . the players move in discrete time steps , and the capture occurs when a pursuer reaches the position of the evader on its move . our main result is that o -lrb- √ h + log n -rrb- pursuers can always win the game with a deterministic search strategy in any polygon with n vertices and h obstacles -lrb- holes -rrb- . in order to achieve this bound , however , we argue that the environment must satisfy a minimum feature size property , which essentially requires the minimum distance between any two vertices to be of the same order as the speed of the players . without the minimum feature size assumption , we show that ω -lrb- n / log n -rrb- pursuers are needed in the worst-case even for simply-connected polygons of n vertices ! this reveals an unexpected subtlety that seems to have been overlooked in previous work claiming that o -lrb- log n -rrb- pursuers can always win in simply-connected n-gons . our lower bound also shows that capturing an evader is inherently more difficult than just '' seeing '' it because o -lrb- log n -rrb- pursuers are prov-ably sufficient for line-of-sight detection even against an arbitrarily fast evader in simple n-gons .(B) [1分]
A. Machine
B. Human

a new speech enhancement system , which is based on a time-frequency adaptive wavelet soft thresholding , is presented in this paper . the speech enhancement system utilises a bark-scaled wavelet packet decomposition integrated into a modified weiner filtering technique using a novel threshold estimation method based on a magnitude decision-directed approach . first , a bark-scaled wavelet packet transform is used to decompose the speech signal into critical bands . threshold estimation is then performed for each wavelet band according to an adaptive noise level-tracking algorithm . finally , the speech is estimated by incorporating the computed threshold into a wiener filtering process , using the magnitude decision-directed approach . the proposed speech enhancement technique has been tested with various stationary and non-stationary noise cases . reported results show that the speech enhancement system is capable of a high-level of noise suppression while preserving the intelligibility and naturalness of the speech .(B) [1分]
A. Machine
B. Human

efficient learning equilibrium -lrb- efficient learning equilibrium -rrb- is a natural solution concept for multi-agent encounters with incomplete information . it requires the learning algorithms themselves to be in equilibrium for any game selected from a set of -lrb- initially unknown -rrb- games . in an optimal efficient learning equilibrium , the learning algorithms would efficiently obtain the surplus the agents would obtain in an optimal nash equilibrium of the initially unknown game which is played . the crucial part is that in an ele deviations from the learning algorithms would become non-beneficial after polynomial time , although the game played is initially unknown . while appealing conceptually , the main challenge for establishing learning algorithms based on this concept is to isolate general classes of games where an efficient learning equilibrium exists . unfortunately , it has been shown that while an efficient learning equilibrium exists for the setting in which each agent can observe all other agents ' actions and payoffs , an efficient learning equilibrium does not exist in general when the other agents ' payoffs can not be observed . in this paper we provide the first positive results on this problem , constructively proving the existence of an optimal efficient learning equilibrium for the class of symmetric games where an agent can not observe other agents ' payoffs .(B) [1分]
A. Machine
B. Human

this paper applies a dynamic sinusoidal synthesis model to statistical parametric speech synthesis . for this , we utilise regularised cepstral coefficients to represent both the static amplitude and dynamic slope of selected sinusoids for statistical modelling . during synthesis , a dynamic sinusoidal synthesis model is used to reconstruct speech . a preference test is conducted to compare the selection of different sinusoids for cepstral representation . our results show that when integrated with statistical parametric speech synthesis , a relatively small number of sinusoids selected according to a perceptual criterion can produce quality comparable to using all harmonics . a mean opinion score test shows that our proposed dynamic sinusoidal synthesis model is preferred to one using mel-cepstra from pitch synchronous spectral analysis .(B) [1分]
A. Machine
B. Human

in a lifelong learning framework , an lifelong learning framework acquires knowledge incrementally over consecutive learning tasks , continually building upon its experience . recent lifelong learning algorithms have achieved nearly identical performance to batch multi-task learning methods while reducing learning time by three orders of magnitude . in this paper , we further improve the scalability of lifelong learning by developing curriculum selection methods that enable an lifelong learning framework to actively select the next task to learn in order to maximize performance on future learning tasks . we demonstrate that active task selection is highly reliable and effective , allowing an lifelong learning framework to learn high performance models using up to 50 % fewer tasks than when the lifelong learning framework has no control over the task order . we also explore a variant of transfer learning in the lifelong learning setting in which the lifelong learning framework can focus knowledge acquisition toward a particular target task .(B) [1分]
A. Machine
B. Human

bilingual speakers are known for their ability to code-switch or mix their languages during communication . this phenomenon occurs when bilinguals substitute a word or phrase from one language with a phrase or word from another language . for code-switching speech recognition , it is essential to collect a large-scale code-switching speech database for model training . in order to ease the negative effect caused by the data sparseness problem in training code-switching speech recognizers , this study proposes a data-driven approach to phone set construction by integrating acoustic features and cross-lingual context-sensitive articulatory features into distance measure between phone units . kl-divergence and a hierarchical phone unit clustering algorithm are used in this study to cluster similar phone units to reduce the need of the training data for model construction . the experimental results show that the proposed data-driven approach outperforms other traditional phone set construction methods .(B) [1分]
A. Machine
B. Human

this paper introduces matrix filters as a tool for localiza-tion and detection problems in passive sonar . the outputs of an array of sensors , at some given frequency , can be represented by a vector of complex numbers . a linear filtering operation on the sensor outputs can be expressed as the multiplication of a matrix -lrb- called a matrix filters -rrb- times this vector . the purpose of a matrix filters is to attenuate unwanted components in the measured sensor data while passing desired components with minimal distortion . matrix filters are designed by defining an appropriate pass band and stop band and solving a convex optimization problem . this paper formulates the design of matrix filters for passive sonar and gives two examples .(B) [1分]
A. Machine
B. Human

communication among participants -lrb- agents , robots -rrb- is central to an appearance of collective ai . in this work we deal with the development of local communication mechanisms for real microro-botic swarms . we demonstrate that despite of very limited capabilities of the microrobot , the specific construction of communication hardware and software allows very extended collective capabilities of the whole swarm . we propose local communication mechanisms providing information content and context for collective navigation , coordination and spatial perception in a group of microrobots .(B) [1分]
A. Machine
B. Human

1 this paper presents an analysis of lombard speech produced under different types and levels of noise . the speech used for the analysis forms a part of the ut-scope database and consists of sentences from the well-known timit corpus , spoken in the presence of highway , large crowd and pink noise . differences are shown to exist in the speech characteristics under these varying noise types . the deterioration of the eer of an inset speaker identification system trained on neutral and tested with lombard speech is also illustrated . a clear demarcation between the effect of noise and lombard effect on noise is also given by testing with noisy lombard speech . the effect of test-token duration on system performance under the lombard condition is addressed . it is seen that test duration has no effect on the eer under lombard effect . the average eer for 3s test duration is 14 .(B) [1分]
A. Machine
B. Human

confusion matrices have been widely used to increase the accuracy of speech recognisers , but usually a mean confusion matrix , averaged over many speakers , is used . however , analysis shows that confusion matrices for individual speakers vary considerably , and so there is benefit in obtaining estimates of confusion matrices for individual speakers . unfortunately , there is rarely enough data to make reliable estimates . we present a technique for estimating the elements of a speaker 's confusion matrix given only sparse data from the speaker . it utilizes non-negative matrix factorisation to find structure within confusion matrices , and this structure is exploited to make improved estimates . results show that under certain conditions , this technique can give estimates that are as good as those obtained with twice the number of utterances available from the speaker .(B) [1分]
A. Machine
B. Human

we address the problem of automatically learning the main steps to complete a certain task , such as changing a car tire , from a set of narrated instruction videos . the contributions of this paper are threefold . first , we develop a joint model for video and natural language narration that takes advantage of the complementary nature of the two signals . second , we collect an annotated dataset of 57 internet instruction videos containing more than 350,000 frames for two tasks -lrb- changing car tire and cardiopulmonary resuscitation -rrb- . third , we experimentally demonstrate that the proposed joint model automatically discovers , in an unsupervised manner , the main steps to achieve each task and locate them within the input videos . the results further show that the proposed joint model outperforms single-modality baselines , demonstrating the benefits of joint modeling video and text .(B) [1分]
A. Machine
B. Human

discriminative approaches to human pose inference involve mapping visual observations to articulated body configurations . current probabilistic approaches to learn this mapping visual observations have been limited in their ability to handle domains with a large number of activities that require very large training sets . we propose an online probabilistic regression scheme for efficient inference of complex , high-dimensional , and multimodal mappings . our online probabilistic regression scheme is based on a local mixture of gaussian processes , where locality is defined based on both appearance and pose , and where the mapping hyperparameters can vary across local neighborhoods to better adapt to specific regions in the pose space . the mapping hyperparameters are defined online in very small neighborhoods , so learning and inference is extremely efficient . when the mapping visual observations is one-to-one , we derive a bound on the approximation error of local regression -lrb- vs. global regression -rrb- for monotonically decreasing co-variance functions . our online probabilistic regression scheme can determine when training examples are redundant given the rest of the database , and use this criteria for pruning . we report results on synthetic -lrb- poser -rrb- and real pose databases , obtaining fast and accurate pose estimates using training set sizes up to 10 5 .(B) [1分]
A. Machine
B. Human

in this paper we propose a robust iterative hard thresolding algorithm for reconstructing sparse signals in the presence of impulsive noise . to address this problem , we use a lorentzian cost function instead of the í µí ° ¿ 2 cost function employed by the traditional iht algorithm . the derived robust iterative hard thresolding algorithm is comparable in computational load to the least squares based iht . analysis of the proposed robust iterative hard thresolding algorithm demonstrates its robustness under heavy-tailed models . simulations show that the proposed robust iterative hard thresolding algorithm significantly outperform commonly employed sparse reconstruction techniques in impulsive environments , while providing comparable reconstruction quality in less demanding , light-tailed environments .(B) [1分]
A. Machine
B. Human

lexical resources such as wordnet and verbnet are widely used in a multitude of nlp tasks , as are annotated corpora such as treebanks . often , the resources are used as-is , without question or examination . this practice risks missing significant performance gains and even entire techniques . this paper addresses the importance of resource quality through the lens of a challenging nlp task : detecting selec-tional preference violations . we present david , a simple , lexical resource-based preference violation detector . with as-is lexical resources , david achieves an f 1-measure of just 28.27 % . when the resource entries and parser outputs for a small sample are corrected , however , the f 1-measure on that sample jumps from 40 % to 61.54 % , and performance on other examples rises , suggesting that the algorithm becomes practical given refined resources . more broadly , this paper shows that resource quality matters tremendously , sometimes even more than algorithmic improvements .(B) [1分]
A. Machine
B. Human

acoustic models -lrb- acoustic models -rrb- of an hmm-based classifier include various types of hidden variables such as gender type , speaking rate , and acoustic environment . if there exists a canonicalization process that reduces the influence of the hidden variables from the acoustic models , a robust automatic speech recognition system can be realized . in this paper , we describe the configuration of a canonicalization process targeting gender type as a hidden variable . the proposed canonicalization process is composed of multiple distinctive phonetic feature extractors corresponding to the hidden variable and a dpf selector in which the distance between input dpf and acoustic models is compared . in a dpf extraction stage , an input sequence of acoustic feature vectors is mapped onto three dpf spaces corresponding to male , female , and neutral voice by using three multilayer neural networks -lrb- mlns -rrb- . experiments are carried out by comparing -lrb- a -rrb- the combination of the canonicalized dpf and a single hmm classifier , and -lrb- b -rrb- the combination of a single acoustic feature and multiple hmm classifiers . the result shows that the proposed canonicalization process outperforms both of the conventional robust automatic speech recognition system with acoustic feature and a single hmm and the robust automatic speech recognition system with multiple hmms in spite of less memories and computation time .(B) [1分]
A. Machine
B. Human

recently , esprit-based parameter estimation algorithms have been developed to exploit the structure of signals from strictly second-order -lrb- so -rrb- non-circular -lrb- nc -rrb- sources . they achieve a higher estimation accuracy and can resolve up to twice as many sources . however , these nc methods assume that all the received signals are strictly non-circular . in this paper , we present the c-nc standard esprit and the c-nc unitary esprit algorithms designed for the more practical scenario of a received mixture of circular and strictly non-circular signals . assuming that the number of circular and strictly non-circular signals is known , the two proposed esprit-based parameter estimation algorithms yield closed-form estimates and c-nc unitary esprit algorithms also enables an entirely real-valued implementation . as a main result , it is shown that the estimation accuracy of the presented esprit-based parameter estimation algorithms improves with an increasing number of strictly non-circular signals among a fixed number of sources . thereby , not only the estimation accuracy of the strictly non-circular signals themselves is improved , but also the estimation accuracy of the circular signals . these results are validated by simulations .(B) [1分]
A. Machine
B. Human

speech separation is a challenging problem at low signal-to-noise ratios . separation can be formulated as a classification problem . in this study , we focus on the snr level of-5 db in which speech is generally dominated by background noise . in such a low snr condition , extracting robust features from a noisy mixture is crucial for successful classification . using a common neural network classifier , we systematically compare separation performance of many monaural features . in addition , we propose a new multi-resolution cochleagram called multi-resolution cochleagram , which is extracted from four cochlea-grams of different resolutions to capture both local information and spectrotemporal context . comparisons using two non-stationary noises show a range of feature robustness for speech separation with the proposed multi-resolution cochleagram performing the best . we also find that multi-resolution cochleagram , a post-processing technique previously used for robust speech recognition , improves speech separation performance by smoothing the temporal trajectories of feature dimensions .(B) [1分]
A. Machine
B. Human

this paper focuses on the novel task of automatic extraction of phrases related to causes of emotions . the analysis of emotional causes in sentences , where emotions are explicitly indicated through emotion keywords can provide the foundation for research on challenging task of recognition of implicit affect from text . we developed a corpus of emotion causes specific for 22 emotions . based on the analysis of this corpus we introduce a method for the detection of the linguistic relations between an emotion and its cause and the extraction of the phrases describing the emotion causes . the method employs syntactic and dependency parser and rules for the analysis of eight types of the emotion-cause linguistic relations . the results of evaluation showed that our method performed with high level of accuracy -lrb- 82 % -rrb- .(B) [1分]
A. Machine
B. Human

we address the problem of answering new questions in community forums , by selecting suitable answers to already asked questions . we approach the task as an answer ranking problem , adopting a pairwise neural network architecture that selects which of two competing answers is better . we focus on the utility of the three types of similarities occurring in the triangle formed by the original question , the related question , and an answer to the related comment , which we call relevance , relatedness , and appropriateness . our proposed pairwise neural network architecture models the interactions among all input components using syntactic and semantic embeddings , lexical matching , and domain-specific features . it achieves state-of-the-art results , showing that the three similarities are important and need to be mod-eled together . our experiments demonstrate that all feature types are relevant , but the most important ones are the lexical similarity features , the domain-specific features , and the syntactic and semantic embeddings .(B) [1分]
A. Machine
B. Human

iterative methods that take steps in approximate subgradient directions have proved to be useful for stochastic learning problems over large or streaming data sets . when the objective consists of a loss function plus a nonsmooth regularization term , whose purpose is to induce structure -lrb- for example , spar-sity -rrb- in the solution , the solution often lies on a low-dimensional manifold along which the regularizer is smooth . this paper shows that a regularized dual averaging algorithm can identify this manifold with high probability . this observation motivates an algorith-mic strategy in which , once a near-optimal manifold is identified , we switch to an regularized dual averaging algorithm that searches only in this manifold , which typically has much lower intrinsic dimension than the full space , thus converging quickly to a near-optimal point with the desired structure . computational results are presented to illustrate these claims .(B) [1分]
A. Machine
B. Human

we introduce parma , a parma for cross-document , semantic predicate and argument alignment . our parma combines a number of linguistic resources familiar to researchers in areas such as recognizing textual entailment and question answering , integrating linguistic resources into a simple discrimina-tive model . parma achieves state of the art results on an existing and a new dataset . we suggest that previous efforts have focussed on data that is biased and too easy , and we provide a more difficult dataset based on translation data with a low base-line which we beat by 17 % f1 .(B) [1分]
A. Machine
B. Human

most methods for decision-theoretic online learning are based on the hedge algorithm , which takes a parameter called the learning rate . in most previous analyses the learning rate was carefully tuned to obtain optimal worst-case performance , leading to suboptimal performance on easy instances , for example when there exists an action that is significantly better than all others . we propose a new way of setting the learning rate , which adapts to the difficulty of the decision-theoretic online learning : in the worst case our procedure still guarantees optimal performance , but on easy instances it achieves much smaller regret . in particular , our adaptive method achieves constant regret in a probabilistic setting , when there exists an action that on average obtains strictly smaller loss than all other actions . we also provide a simulation study comparing our approach to existing methods .(B) [1分]
A. Machine
B. Human

stress and syllabification are essential attributes for several components in text-to speech systems . stress are responsible for improving grapheme-to-phoneme conversion rules and for enhancing the synthetic intelligibility , since stress and syllable are key units in prosody prediction . this paper presents three linguistically rule-based automatic algorithms for catalan text-to-speech conversion : a word stress marker , an orthographic syllabification algorithm and a phonological syllabification algorithm . the linguistically rule-based automatic algorithms were implemented and tested . the results gave rise to the following word accuracy rates : 100 % for the stress marker algorithm , 99.7 % for the orthographic syllabification algorithm and 99.8 % for the phonological syllabification algorithm .(B) [1分]
A. Machine
B. Human

this paper provides an overview of the developments in auditory visual speech processing , a special interest group within eurospeech . i hope that this discussion will be informative and useful to readers in a variety of fields , including psychology , speech science , animation , psycholinguistics , human-machine interaction , hearing-impaired communication , and numerous other fields which also share in this fruitful intersection .(B) [1分]
A. Machine
B. Human

the map seeking circuit has been suggested to address the inverse problem of transformation discovery as found in signal processing , vision , inverse kinematics and many other natural tasks . according to this idea , a parallel search in the transformation space of a high dimensional problem can be decomposed into parts efficiently using the ordering property of superpositions . deterministic formulations of the circuit have been suggested . here , we provide a proba-bilistic interpretation of the architecture whereby the superpositions of the circuit are seen as a series of marginalisations over parameters of the transform . based on this , we interpret the weights of the map seeking circuit as importance weights . the latter suggests the incorporation of monte-carlo approaches in the map seeking circuit , providing improved resolution of parameter estimates within resource constrained implementations . as a final contribution , we model mixed serial/parallel search strategies of biological vision to reduce the problem of collusions , a common problem in the standard map seeking circuit .(B) [1分]
A. Machine
B. Human

in this paper , we present a novel feature normalization method in the log-scaled spectral domain for improving the noise robustness of speech recognition front-ends . in the proposed feature normalization method , a non-linear contrast stretching is added to the outputs of log mel-filterbanks to imitate the adaptation of the auditory system under adverse conditions . this is followed by a two-dimensional filter to smooth out the processing artifacts . the proposed feature normalization method perform remarkably well on censrec-2 in-car database with an average relative improvement of 29.3 % compared to baseline mfcc system . it is also confirmed that the proposed processing in log mfb domain can be integrated with conventional cepstral post-processing techniques to yield further improvements . the proposed feature normalization method is simple and requires only a small extra computation load .(B) [1分]
A. Machine
B. Human

this paper presents a representation theory for permutation-valued functions , which in their general form can also be called listwise ranking functions . point-wise ranking functions assign a score to each object independently , without taking into account the other objects under consideration ; whereas listwise loss functions evaluate the set of scores assigned to all objects as a whole . in many supervised learning to rank tasks , it might be of interest to use listwise ranking functions instead ; in particular , the bayes optimal ranking functions might themselves be listwise , especially if the loss function is listwise . a key caveat to using list-wise ranking functions has been the lack of an appropriate representation theory for such functions . we show that a natural symmetricity assumption that we call exchangeability allows us to explicitly characterize the set of such exchangeable listwise ranking functions . our analysis draws from the theories of tensor analysis , functional analysis and de finetti theorems . we also present experiments using a novel reranking method motivated by our representation theory .(B) [1分]
A. Machine
B. Human

in chinese , most of the language processing starts from word segmentation and part-of-speech tagging . these two steps tokenize the word from a sequence of characters and predict the syntactic labels for each segmented word . in this paper , we present two distinct sequential tagging models for the above two tasks . the first sequential tagging models was basically similar to previous work which made use of conditional random fields and set of predefined dictionaries to recognize word boundaries . second , we revise and modify support vector machine based chunking model to label the pos tag in the pos tagging task . our support vector machine based chunking model in the ws task achieves moderately rank among all participants , while in the pos tagging task , it reaches very competitive results .(B) [1分]
A. Machine
B. Human

we address the problem of detecting batches of emails that have been created according to the same template . this problem is motivated by the desire to filter spam more effectively by exploiting collective information about entire batches of jointly generated messages . the application matches the problem setting of supervised clustering , because examples of correct clusterings can be collected . known decoding procedures for supervised clustering are cubic in the number of instances . when decisions can not be reconsidered once they have been made -- owing to the streaming nature of the data -- then the decoding problem can be solved in linear time . we devise a sequential decoding procedure and derive the corresponding optimization problem of supervised clustering . we study the impact of collective attributes of email batches on the effectiveness of recognizing spam emails .(B) [1分]
A. Machine
B. Human

learning to hash involves learning hash functions from a set of images for embedding high-dimensional visual descriptors into a similarity-preserving low-dimensional hamming space . most of existing methods resort to a single representation of images , that is , only one type of visual descriptors is used to learn a hash function to assign binary codes to images . however , images are often described by multiple different visual descriptors -lrb- such as sift , gist , hog -rrb- , so it is desirable to incorporate these multiple representations into learning a hash function , leading to multi-view hashing . in this paper we present a sequential spectral learning approach to multi-view hashing where a hash function is sequentially determined by solving the successive maximiza-tion of local variances subject to decorrelation constraints . we compute multi-view local variances by α-averaging view-specific distance matrices such that the best averaged distance matrix is determined by minimizing its α-divergence from view-specific distance matrices . we also present a scalable implementation , exploiting a fast approximate k-nn graph construction method , in which α-averaged distances computed in small partitions determined by recursive spectral bisection are gradually merged in conquer steps until whole examples are used . numerical experiments on caltech-256 , cifar-20 , and nus-wide datasets confirm the high performance of our sequential spectral learning approach , in comparison to single-view spectral hashing as well as existing multi-view hashing methods .(B) [1分]
A. Machine
B. Human

the goal of speech emotion recognition is to identify the emotional or physical state of a human being from his or her voice . one of the most important things in a speech emotion recognition is to extract and select relevant speech features with which most emotions could be recognized . in this paper , we present a smoothed nonlinear energy operator - based amplitude modulation cepstral coefficients -lrb- amcc -rrb- feature for recognizing emotions from speech signals . smoothed nonlinear energy operator estimates the energy required to produce the am-fm signal , and then the estimated energy is separated into its amplitude and frequency components using an energy separation algorithm . amcc features are obtained by first decomposing a speech signal using a c-channel gammatone filterbank , computing the am power spectrum , and taking a discrete cosine transform of the root compressed am power spectrum . conventional mfcc -lrb- mel-frequency cepstral coefficients -rrb- and mel-warped dft -lrb- discrete fourier transform -rrb- spectrum based cepstral coefficients -lrb- mwdcc -rrb- features are used for comparing the recognition performances of the proposed features . emotion recognition experiments are conducted on the fau aibo spontaneous emotion corpus . it is observed from the experimental results that the amcc features provide a relative improvement of approximately 3.5 % over the baseline mfcc .(B) [1分]
A. Machine
B. Human

this work presents our research results on the capability of passive source localization using a towed multi-module array in underwater acoustic environments . we developed new cramer-rao lower bound results for assessing the array 's source localization capability under environmental uncertainties , such as array modules ' positions and acoustic-field 's spatial coherence . we also developed a two-stage approach and provide details for passive ranging by utilizing data either non-coherently or coherently , depending on the availability of spatial coherence in the received data from multiple modules of towed array .(B) [1分]
A. Machine
B. Human

many real-world decision-theoretic planning problems are naturally modeled using both continuous state and action spaces , yet little work has provided exact solutions for the case of continuous actions . in this work , we propose a symbolic dynamic programming solution to obtain the optimal closed-form value function and policy for csa-mdps with mul-tivariate continuous state and actions , discrete noise , piecewise linear dynamics , and piecewise linear -lrb- or restricted piecewise quadratic -rrb- reward . our key contribution over previous sdp work is to show how the continuous action maximization step in the dynamic programming backup can be evaluated optimally and symbolically -- a task which amounts to symbolic constrained optimization subject to unknown state parameters ; we further integrate this technique to work with an efficient and compact data structure for sdp -- the extended algebraic decision diagram -lrb- xadd -rrb- . we demonstrate empirical results on a didactic nonlinear planning example and two domains from operations research to show the first automated exact solution to these problems .(B) [1分]
A. Machine
B. Human

for sequential probabilistic inference in nonlinear non-gaussian systems approximate solutions must be used . we present a novel recursive bayesian estimation algorithm that combines an importance sampling based measurement update step with a bank of sigma-point kalman filters for the time-update and proposal distribution generation . the posterior state density is represented by a gaussian mixture model that is recovered from the weighted particle set of the measurement update step by means of a weighted em algorithm . this recursive bayesian estimation algorithm replaces the resampling stage needed by most particle filters and mitigates the '' sample depletion '' problem . we show that this new recursive bayesian estimation algorithm has an improved estimation performance and reduced computational complexity compared to other related algorithms .(B) [1分]
A. Machine
B. Human

we present a technique for coarsely extracting the regions of natural color images which contain directional detail , e.g. , edges , texture , etc. , which we then use for image database indexing . as a measure of color activity , we use a perceptually modified distance measure based on the sum-of-angles criterion . we then apply histogram thresholding techniques to separate the image into smooth color regions and busy regions where edge , texture and colour activity exists . database indices are then created from the busy regions using the direcional detail histogram technique and retrieval is performed using these .(B) [1分]
A. Machine
B. Human

our understanding of the input-output function of single cells has been substantially advanced by biophysically accurate multi-compartmental models . the large number of parameters needing hand tuning in these biophysically accurate multi-compartmental models has , however , somewhat hampered their applicability and inter-pretability . here we propose a simple and well-founded method for automatic estimation of many of these key parameters : 1 -rrb- the spatial distribution of channel densities on the cell 's membrane ; 2 -rrb- the spatiotemporal pattern of synaptic input ; 3 -rrb- the channels ' reversal potentials ; 4 -rrb- the in-tercompartmental conductances ; and 5 -rrb- the noise level in each compartment . we assume experimental access to : a -rrb- the spatiotemporal voltage signal in the dendrite -lrb- or some contiguous subpart thereof , e.g. via voltage sensitive imaging techniques -rrb- , b -rrb- an approximate kinetic description of the channels and synapses present in each compartment , and c -rrb- the morphology of the part of the neuron under investigation . the key observation is that , given data a -rrb- - c -rrb- , all of the parameters 1 -rrb- -4 -rrb- may be simultaneously inferred by a version of constrained linear regression ; this constrained linear regression , in turn , is efficiently solved using standard algorithms , without any '' local minima '' problems despite the large number of parameters and complex dynamics . the noise level 5 -rrb- may also be estimated by standard techniques . we demonstrate the method 's accuracy on several model datasets , and describe techniques for quantifying the uncertainty in our estimates .(B) [1分]
A. Machine
B. Human

we improve the automatic speech recognition of broadcast news using paradigms from web 2.0 to obtain time-and topic-relevant text data for language modeling . we elaborate an un-supervised text collection and decoding strategy that includes crawling appropriate texts from rss feeds , complementing un-supervised text collection and decoding strategy with texts from twitter , language model and vocabulary adaptation , as well as a 2-pass decoding . the word error rates of the tested french broadcast news shows from europe 1 are reduced by almost 32 % relative with an underlying language model from the globalphone project -lsb- 1 -rsb- and by almost 4 % with an underlying language model from the quaero project . the un-supervised text collection and decoding strategy that we use for the text normalization , the collection of rss feeds together with the text on the related websites , a tf-idf-based topic words extraction , as well as the opportunity for language model interpolation are available in our rapid language adaptation toolkit -lsb- 2 -rsb- -lsb- 3 -rsb- .(B) [1分]
A. Machine
B. Human

lexical co-occurrence is an important cue for detecting word associations . we present a theoretical framework for discovering statistically significant lexical co-occurrences from a given corpus . in contrast with the prevalent practice of giving weightage to unigram frequencies , we focus only on the documents containing both the terms -lrb- of a candidate bi-gram -rrb- . we detect biases in span distributions of associated words , while being agnostic to variations in global unigram frequencies . our framework has the fidelity to distinguish different classes of lexical co-occurrences , based on strengths of the document and corpus-level cues of co-occurrence in the data . we perform extensive experiments on benchmark data sets to study the performance of various co-occurrence measures that are currently known in literature . we find that a relatively obscure measure called ochiai , and a newly introduced measure csa capture the notion of lexical co-occurrence best , followed next by llr , dice , and ttest , while another popular measure , pmi , suprisingly , performs poorly in the context of lexical co-occurrence .(B) [1分]
A. Machine
B. Human

this acoustic study explored dialect effects on realization of nuclear pitch accents in three regional varieties of american english spoken in central ohio , southeastern wisconsin and western north carolina . fundamental frequency -lrb- f0 -rrb- change from vowel onset to offset in the most prominent syllable in a sentence was examined along four parameters : maximum f0 change , relative location of f0 maximum , f0 offset and f0 fall from maximum to offset . a robust finding was that the f0 contours in the southern -lrb- north carolina -rrb- variants were significantly distinct from the two midwestern varieties whose contours did not differ significantly from one another . the southern vowels had an earlier f0 rise , a greater f0 fall and a lower f0 offset than either ohio or wisconsin vowels . there was a sharper f0 drop preceding a voiceless than a voiced syllable coda . no significant dialect-related differences were found for flat f0 contours in unstressed vowels , which were also examined in the study . this study contributes the finding that dynamic variations in pitch are greater for vowels which also exhibit a greater amount of spectral dynamics . the interaction of these two sets of cues contributes to the melodic component associated with a specific regional accent .(B) [1分]
A. Machine
B. Human

we have recently proposed a new plda-based acoustic model based on prob-abilistic linear discriminant analysis which enjoys the flexibility of using higher dimensional acoustic features , and is more capable to capture the intra-frame feature correlations . in this paper , we investigate the use of bottleneck features obtained from a deep neural network for the plda-based acoustic model . experiments were performed on the switchboard dataset -- a large vocabulary conversational telephone speech corpus . we observe significant word error reduction by using the bottleneck features . in addition , we have also compared the plda-based acoustic model to three others using gaussian mixture models , subspace gmms and hybrid deep neural networks , and plda can achieve comparable or slightly higher recognition accuracy from our experiments .(B) [1分]
A. Machine
B. Human

symmetry reduction has significantly contributed to the success of classical planning as heuristic search . however , it is an open question if symmetry reduction techniques can be lifted to fully observable nondeterministic planning . we generalize the concepts of structural symmetries and symmetry reduction to fond planning and specifically to the lao ⇤ algorithm . our base implementation of lao ⇤ algorithm in the fast downward planner is competitive with the lao ⇤ algorithm - based fond planner mynd . our experiments further show that symmetry reduction can yield strong performance gains compared to our base implementation of lao ⇤ algorithm .(B) [1分]
A. Machine
B. Human

this paper describes the realization of a corpus-based chinese speech synthesis system , including the corpus design and unit selection procedure . the corpus-based chinese speech synthesis system selects the synthesis unit according to context similarity between target unit and candidate unit . neither prosody parameter prediction nor prosody feature modification is needed . the informal test shows that the synthesized speech is quite natural , and the speaking style of original speaker is preserved because units are all from the speaker 's utterances .(B) [1分]
A. Machine
B. Human

this paper describes our recent work in developing an unified dutch and german speech recognition system in the speechdat domain . the acoustic component of the unified dutch and german speech recognition system is accomplished through sharing common phonemes without preserving any information about the languages . we propose a more robust mce-based training algorithm , where only the language dependent phoneme models are allowed to be adjusted , according to the type of training data . experimental results on dutch and german subword recognition tasks clearly show an overall string error rate reduction of about 7 % and 13 % obtained by the newly trained unified dutch and german speech recognition system in comparison with the conventional mce-trained multilingual system .(B) [1分]
A. Machine
B. Human

