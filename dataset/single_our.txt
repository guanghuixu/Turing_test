this paper presents a learning architecture for lexical semantic classification problems . the learning architecture consists of two components : -lrb- 1 -rrb- a hierarchical learning architecture that learns from task-specific training data and -lrb- 2 -rrb- a hierarchical learning architecture that learns from background data and -lrb- 3 -rrb- a learning architecture that learns from task-specific and background data . the effectiveness of the learning architecture is demonstrated on a word sense disambiguation task .
thompson sampling is a stochastic multi-armed bandit problem with reward distributions . in this paper , we consider the stochastic multi-armed bandit problem with reward distributions , where the rewards are drawn from a prior distribution . we show that , for a non-bayesian stochastic bandit , the regret of the stochastic multi-armed bandit problem is o -lrb- √ t -rrb- , where t is the number of arms , and t is the number of arms . we show that the regret of the stochastic multi-armed bandit problem is o -lrb- √ t -rrb- , where t is the number of arms and t is the number of arms . in particular , we show that the bayesian regret of the stochastic multi-armed bandit problem is o -lrb- √ t -rrb- , where t is the number of arms and t is the number of arms . in particular , we show that , for a non-bayesian stochastic bandit , the regret of the stochastic multi-armed bandit problem is o -lrb- √ t -rrb- , where t is the number of arms , and t is the number of arms . we also show that , for a non-bayesian stochastic bandit , we can achieve a regret bound of o -lrb- √ t -rrb- , where t is the number of arms and t is the number of arms . finally , we show that , in the non-bayesian stochastic bandit , the regret bound is o -lrb- √ t -rrb- , where t is the number of arms and t is the number of arms . finally , we show that , in the non-bayesian stochastic bandit , the regret bounds are o -lrb- √ t -rrb- .
this paper describes the development of an end-to-end spoken information retrieval solution for elderly conversational speech . the speech processing flow consists of speaker tracking , transcription , and speaker tracking . the speech processing flow consists of two components : -lrb- 1 -rrb- speech processing components , -lrb- 2 -rrb- speech processing components , -lrb- 3 -rrb- speaker tracking , and -lrb- 3 -rrb- transcription , and -lrb- 3 -rrb- speech processing components . the speech processing flow is designed to support the ambient assisted living area on a personal audio archive . the experimental results show that the proposed end-to-end spoken information retrieval solution is capable of detecting and retrieving spoken conversations in elderly conversational speech .
in this paper , we present an automatic speech recognition system that uses acoustic data at the phonemic level to improve the performance of an automatic speech recognition system . the proposed automatic speech recognition system uses a phonemic confusion model of the acoustic test data . the phonemic transcription pairs are extracted from phonemic transcription pairs to form a confusion model . the probabilistic phoneme sequence conversion rules are trained using leave-one-out decoding . the phonemic confusion model is then used to estimate the probability distribution of the word hypotheses given the acoustic test data . the proposed automatic speech recognition system is evaluated on the text test corpus and the results show that the proposed automatic speech recognition system can improve the word error rate of the automatic speech recognition system . in addition , the proposed automatic speech recognition system is evaluated on the acoustic data collected at the phonemic level . the proposed automatic speech recognition system is also compared with a conventional asr strategy and grammar design .
in this paper , we propose a method to extract cepstral features from a speech signal using the modified group delay function based on mel-frequency cepstral coefficients . in the proposed method , the magnitude spectrum of the phase spectrum of the speech signal is represented by a group delay function . in the proposed method , cepstral features are extracted from the power spectrum of the modified group delay function , and the phase spectrum of the modified group delay function is used as features for speech recognition . the experimental results show that the proposed method can improve the performance of the proposed method .
in this paper , we propose a sender-driven mechanism for streaming 3d scenes in a resource-constrained environment . the proposed sender-driven mechanism is based on the idea that the network bandwidth for three-dimensional graphic scenes can be reduced to a factor of three , namely , a 100-kb bit rate , and a heuristic for evaluating the quality of the delivery . the experimental results show that the proposed sender-driven mechanism is able to achieve a 100-kb bit rate of up to 80 % , which is comparable to the state-of-the-art methods for streaming 3d scenes .
in this paper , we propose a method to recover the geometric structure of a scene from a set of images captured under different illumination conditions . the method is based on structure-from-motion and correlation-based stereo techniques . the geometric structure of a scene is represented by a set of images captured under different illumination conditions . the geometric structure of the scene is represented by a set of basis images , each of which is represented by a low-dimensional linear space . the geometric structure of the scene is represented by a set of images captured under different illumination conditions , and the position of the scene is represented by a set of basis images . the geometric information of the scene structure is then used to estimate the position and orientation of the scene model in the 3d space . the proposed method is tested on real images captured by product advertisement , virtual reality , and object recognition .
in this paper , we address the problem of detection using contextual information from local image data . we propose to use boosted random fields to learn dense graphs from local image data . the graph structure is represented by a set of graph fragments in an additive model , and a conditional random field is used to learn the parameters of the conditional random field . in order to improve the accuracy and speed of the detection , we use boosted random fields to learn the graph structure from local image data . the boosted random fields is then used as a computational cascade to learn the parameters of the boosted random fields . the experimental results show that the proposed boosted random fields can achieve comparable or better detection performance than the state-of-the-art methods in terms of accuracy and speed .
we study the computational complexity of cp-nets in cyclic dependency graphs . we show that the complexity of cp-nets is polynomial in the size of the dependency graph , and that the complexity of cp-nets is polynomial in the number of classes . we also show that the complexity of cp-nets is exponential in the number of classes , even when the number of classes is exponential in the number of classes . finally , we show that the complexity of cp-nets is exponential in the number of classes , even when the number of classes is exponential in the number of classes . finally , we show that the complexity of cp-nets is polynomial in the number of classes , even when the number of classes is exponential in the number of classes . finally , we show that the complexity of cp-nets is polynomial in the number of classes , even when the number of classes is exponential in the number of classes . finally , we show that the complexity of cp-nets is exponential in the number of classes , even when the number of classes is exponential in the number of classes .
sleep apnea syndrome is a sleep disordered breathing in which oral snoring sounds are affected by heavy snoring oral breathing . in this study , the acoustic properties of snoring sounds are analyzed and compared with those of snoring sounds . the acoustic properties of snoring sounds are analyzed and compared with those of snoring sounds . cross validation evaluations show that the acoustic properties of snoring sounds are quite similar to those of snoring sounds , but the differences between snoring and snoring sounds are significantly different from those of snoring sounds . the results suggest that oral snoring is an important medical treatment of the sleep disordered breathing .
sentiment words play an important role in sentiment analysis . many real-life sentiment corpora , such as water , electricity , gas , etc. , can be expressed as a bipartite graph . in this paper , we propose a method to extract sentiment words for sentiment analysis . we first extract sentiment words from documents , and then extract sentiment words from these documents using an iterative algorithm . then , we extract positive or negative opinions from the documents , and extract sentiments from them . finally , we extract sentiment words from the documents , and extract sentiment words from them . experimental results show that our method can effectively extract sentiments from real-life sentiment corpora .
in this paper , we consider the problem of estimating the graph laplacian from 2-regularized or 1-regularized 2-regression data . in particular , we consider the regression problem where the coefficient vector of the laplace prior corresponds to a gaussian prior . we show that the laplace prior on the coefficient vector of the regularized sdp is equivalent to the laplace prior on the coefficient vector of the regression problem . we propose an efficient approximation procedure based on the mahoney-orecchia regularized sdp , which we call the regularized estimation problem , and show that it can be viewed as an approximate eigenvector computation of the laplace prior on the coefficient vector of the regularized estimation problem . we show that the proposed approximation procedure can be viewed as a special case of regularized semi-definite programs , which we call the regularized estimation problem . we show that the proposed approximation procedure can be viewed as a special case of ridge regression and lasso regression , and that it can be interpreted as a nontrivial eigenvector of the regularized estimation problem . we also show that the proposed approximation procedure can be interpreted as a special case of the regularized estimation problem .
interactive machine learning -lrb- cuet -rrb- systems have become increasingly popular in recent years due to their ability to learn a low-level device health information . however , the triage decisions of operators are often too expensive to obtain . in this paper , we present cuet , a novel cuet for fast and accurate network alarm triage . cuet is based on interactive machine learning , where the goal is to maximize the likelihood of a user 's activity given a set of training examples . cuet uses a set of rule-based tools to automatically select a small subset of training examples that are most likely to contain the user 's activity . we show that cuet can learn accurate network alarm triage using only a small number of training examples , and that cuet can learn accurate network alarm triage with reasonable accuracy . we also show that cuet can be used to predict alarm triage using only a small number of training examples . finally , we show that cuet can be used to learn accurate and accurate network alarm triage using only a few examples .
in this paper , we propose a new gpca algorithm for subspace clustering . the proposed gpca algorithm is based on linear and polynomial algebra , and can be viewed as a generalization of the standard pca for computer vision problems such as vanishing point detection , face clustering , and news video segmentation . unlike traditional algebraic algorithms based on polynomial factorization , gpca algorithm does not require the initialization of the original gpca algorithm . instead , gpca algorithm does not require the initialization of the original gpca algorithm . instead , gpca algorithm does not require the distance function of the subspaces to be represented by the polynomials . instead , gpca algorithm does not require the initialization of the original gpca algorithm . the proposed gpca algorithm is general and can be applied to any number of subspaces and can be applied to any number of subspaces . the proposed gpca algorithm is general and can be applied to any number of computer vision problems .
in this paper , we propose a novel measure of distance based on statistics of dependent noun-ve-verb triples in atr dialogue corpus . the measure of distance is based on the assumption that the single-case clusters are clustered according to their similarity to the single-case clusters . the proposed measure of distance is evaluated by clustering analysis of the semantic cases in atr dialogue corpus . the experimental results show that the proposed measure of distance is effective in improving the accuracy of the correlation analysis . the accuracy of the proposed measure of distance is higher than that of correlation analysis , and the consistency rates of the proposed measure of distance are higher than that of the conventional measure of distance based on statistics of dependent noun-ve-verb triples .
human motion analysis is a fundamental problem in the signal processing community . sophisticated signal processing techniques , such as the discrete fourier transform and the discrete wavelet transform , have been widely used for the characterization and recognition of human motion sequences . however , most of the existing signal transform methods , such as the discrete fourier transform , are not applicable to general discrete time signals . in this paper , we propose discriminating features for motion dynamics , which are invariant to articulated motion . we demonstrate the effectiveness of our discriminating features on a variety of data sets , and show that discriminating features can be used to capture motion dynamics .
this paper presents a sound coding framework for commercial cochlear implant processors . the sound coding framework is based on the observation that the instantaneous signal , formant location of speech , and noise can be modeled as noise-dominant channels in the time-frequency unit of the cochlear implant devices . in order to improve the perception quality of the sound coding framework , two spectral maxima sound coding algorithms are proposed . the first spectral maxima sound coding algorithms is based on a channel selection criterion . the second spectral maxima sound coding algorithms is based on the assumption that the noise is present in the cochlear implant users . the second spectral maxima sound coding algorithms is based on the assumption that the noise is present in the cochlear implant users . the second spectral maxima sound coding algorithms is based on the assumption that the noise is present in the cochlear implant devices . the third spectral maxima sound coding algorithms is capable of reducing the number of noise-dominant channels required for stimulation . the proposed spectral maxima sound coding algorithms is evaluated in terms of speech intelligibility and low signal-to-noise ratio , and the results show that the proposed spectral maxima sound coding algorithms can significantly improve the speech intelligibility of commercial cochlear implant devices . in addition , the n-of-m strategies can also be used in commercial cochlear implant devices .
in this paper , we present a novel approach to temporally coherent stereo disparity . given a pair of stereo images and a pair of optical flow maps , we compute a disparity map for each pair of stereo images and compute a disparity map for each pair of optical flow maps . this disparity map is then used to estimate the disparity map for each pair of stereo images . this disparity map is then used to estimate the disparity map for each pair of stereo images and optical flow maps . a seed growing algorithm is used to estimate the disparity map for each pair of stereo images . the seed growing algorithm is used in a binocular stereo setup to estimate the disparity map for each pair of images . the reconstructed 3d point is then used to estimate the disparity map for each pair of images . experimental results show that the proposed algorithm is able to recover the scene flow from a single image without calibration and inherent search space reduction .
in this paper , we address the problem of unsupervised online task adaptation for a task independent seed model in an automatic speech recognition system . we propose to use a multilingual romanic/germanic seed model in order to improve the recognition performance of a task independent seed model . the multilingual romanic/germanic seed model is used as the target task to adapt the hmm parameters of the multilingual romanic/germanic seed model in order to improve the recognition performance of the task independent seed model . the experimental results show that the proposed language dependent models improve the recognition accuracy of the proposed language dependent models when compared to the baseline system . the proposed language dependent models also improve the recognition accuracy when the task dependent models are trained on the same amount of acoustic data . the proposed language dependent models also improve the recognition accuracy when the task dependent models are trained on the same amount of acoustic data .
we present an unsupervised algorithm for inferring word boundaries in transcribed adult conversations . the unsupervised algorithm is based on a dis-criminative model of boundary marking , which uses phone ngrams as input to a dis-criminative model of boundary marking . wordends can be used for child language acquisition , but can also be used for speech understanding . we evaluate our unsupervised algorithm on two miniature datasets , english and arabic , and show that our unsupervised algorithm is capable of inferring word boundaries in morphologically complex words .
the present study investigates the influence of vowel and consonant identification on the signal-to-noise ratio of american english phonemes in english . native listeners were asked to distinguish between vowel and consonant identification in the presence of noise in the native phoneme inventory . listeners were asked to distinguish between vowel and consonant identification in the presence of multispeaker babble . the results showed that the signal-to-noise ratio of the vowel and consonant identification was significantly higher than the signal-to-noise ratios of the native listeners . however , the signal-to-noise ratio of the vowel and consonant identification was significantly higher when the vowel position was longer than the consonant . these results suggest that dutch listeners are able to distinguish between vowel and consonant identification in the presence of noise .
in this paper , we address the problem of weakly-supervised object detection -lrb- weakly-supervised object detection -rrb- in the presence of strong human supervision -lrb- e.g. , manually annotated bounding boxes -rrb- . to this end , we propose a novel approach to automatically learn discriminative regions from a set of tracked object boxes . specifically , we first extract a set of posi-tive/negative images from a set of labeled bounding boxes , and then use these bounding box annotations to train object detectors . then , we use the hough transform algorithm to learn a pseudo gt from the bounding box annotations . finally , we propose a status quo approach to learn the parameters of the pseudo gt from a set of manually annotated bounding boxes . we evaluate our approach on the challenging pascal 2007 and 2010 datasets , and show that our approach significantly outperforms the state-of-the-art methods . moreover , we show that our approach is able to learn discriminative regions that are useful for a new image collection .
the aim of this paper is to investigate the effects of age and culture on the performance of pakistani children playing children . the aim of this study is to investigate the effects of audiovisual speech on the performance of the pakistani children in cross-cultural perception studies . the results show that the classification accuracy of pakistani children is significantly higher than the classification accuracy of the pakistani children .
gauss mixture vector quantization -lrb- gauss mixture vector quantization -rrb- has been widely used in many applications such as image retrieval . in this paper , we propose a new method for gauss mixture vector quantization based on the lloyd algorithm . the proposed method is based on the asymptotic likelihood approximation of the gauss mixture expectation-maximization , which is a similarity criterion between the gm parameter values . the computational complexity of the em is o -lrb- n 2 -rrb- , where n is the number of samples , and n is the number of samples . the performance of the proposed method is compared with that of the conventional em in terms of classification performance and convergence speed . the experimental results show that the proposed method is superior to the em in terms of classification performance .
semi-supervised learning -lrb- semi-supervised learning algorithms -rrb- algorithms have been widely used in natural language processing to learn classifiers for structured learning tasks . in this paper , we propose a novel semi-supervised learning algorithms that incorporates domain knowledge into the semi-supervised learning algorithms for machine learning . the proposed semi-supervised learning algorithms is able to learn classifiers for a wide range of structured learning tasks . we demonstrate the effectiveness of the proposed semi-supervised learning algorithms by applying semi-supervised learning algorithms to a challenging information extraction domain .
we present a kernel-based approach to reinforcement learning in the average-cost framework . the kernel-based approach is based on the concept of a markov decision process , where the goal is to maximize the expected return of a portfolio choice problem . we show that this kernel-based approach can be applied to a wide range of problems , including parametric function approximators , neural networks , temporal-diierence learning , and neural networks . we show that the proposed kernel-based approach is competitive with existing learning algorithms .
in this paper , we propose a block-iterative parallel decomposition method for solving quadratic signal recovery problems with convex constraints . the block-iterative parallel decomposition method is based on the assumption that the block-parallel structure of the signal is known to be sparse . the block-iterative parallel decomposition method can be viewed as a multi-constraint problem , which can be solved using deconvolution . the block-iterative parallel decomposition method can be viewed as an extension of the block-iterative parallel decomposition method to the multi-constraint problem , which can be solved by approximate enforcement using linearization . the effectiveness of the block-iterative parallel decomposition method is demonstrated by numerical examples .
in this paper , we propose an optimization method for layered neural networks based on the modified information criterion . the experimental results show that the proposed optimization method is effective in improving the performance of layered neural networks .
in this paper , we present a data-driven approach to the realization of simultaneity in a japanese-to-english speech-to-speech translation system : commentary programs , tv news and commentary programs . in our data-driven approach , the translation rules are learned from a parallel corpus by means of a data-driven approach . in our data-driven approach , the initial translation rules are adapted to the specific speaking styles and the final translation rules are selected according to their absolute size . the experimental results show that our data-driven approach outperforms the baseline system .
in this paper , we propose a new prototype filter for <s> <s> <s> this prototype filter , which is suitable for <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> in this paper , we propose efficient two-step algorithms to minimize the aliasing and amplitude errors of the prototype filter bank . efficient two-step algorithms are developed to minimize the stopband response . the effectiveness of the proposed prototype filter is demonstrated by comparing the performance of the proposed prototype filter with that of the proposed prototype filter bank , and the results show that the proposed prototype filter can be used to design efficient dft filter banks .
in this paper , we propose a speaker diarization system for the analysis of meeting speech . the proposed speaker diarization system is based on a robust cluster modeling perspective , which aims at modeling the conversation patterns as a priori information about the participant 's speech segments . the proposed speaker diarization system is evaluated on meeting speech corpora , and the results show that the proposed speaker diarization system is effective in improving the diarization error rate . moreover , the proposed speaker diarization system is also compared with the baseline system based on participant interaction pattern modeling . experimental results show that the proposed speaker diarization system is very effective in modeling the conversation patterns and that the proposed speaker diarization system is effective in modeling the participant interaction pattern modeling .
in natural vision , it is often assumed that the stimulus sequence is delayed , and that the stimulus sequence is delayed . in this paper , we show that the classical energy mechanism , which is based on nonclassical gain control , can be applied to a wide range of natural images . in particular , we show that the classical energy mechanism can be applied to a wide range of natural images . in particular , we show that the classical energy mechanism can be applied to a wide range of natural images . in particular , we show that the classical energy mechanism can be applied to a wide range of natural images , and that the energy mechanism can be applied to a broad class of problems , such as those encountered in vi . in particular , we show that the classical energy mechanism can be applied to a broad class of problems , such as delayed , delayed , delayed , and delayed , in a natural area vi .
short-time fourier transform -lrb- short-time fourier transform -rrb- is a time-frequency analysis tool that can be used for filtering purposes . short-time fourier transform is an extension of the short-time fourier transform , which is a spectral representation of voiced speech . short-time fourier transform is an extension of the short-time fourier transform , which has been shown to be effective for time-frequency localization . however , the short-time fourier transform is not robust to inconsistent bins . in this paper , we propose a new analysis tool , called the short-time fourier transform , that is based on the analysis of the quadratic chirps of the short-time fourier transform . the proposed analysis tool consists of two steps : first , time-frequency localization is performed on a segment-by-segment , and second , time-frequency localization is performed on the basis of the pitch tendency segment-by-segment . the results show that the proposed analysis tool can be used for filtering purposes .
in this paper , we propose a reverberant speech enhancement method . the proposed reverberant speech enhancement method is based on estimating reverberation time using a pitch-based reverberation measure . the proposed reverberant speech enhancement method is composed of two steps : -lrb- 1 -rrb- estimating reverberation time using a pitch-based reverberation measure , and -lrb- 2 -rrb- estimating reverberation time based on the harmonic structure of the signal . in the proposed reverberant speech enhancement method , the fundamental frequency -lrb- f0 -rrb- of the signal is estimated based on the pitch strength of the signal , and -lrb- 3 -rrb- estimating reverberation time based on the pitch strength of the signal . the experimental results show that the proposed reverberant speech enhancement method is effective in reverberant speech enhancement . the proposed reverberant speech enhancement method is very effective in suppressing reverberation effects , and the proposed reverberant speech enhancement method outperforms the conventional methods .
we derive frequency-domain bounds for the non-negative impulse response filter in continuous and discrete-time domains . we show that the spectral gain of the non-negative impulse response filter depends on the spectral gain and the maximally allowable power attenua-tion of the input signal . we derive upper-bounds on the power spectral attenuation power of the non-negative impulse response filter , and show that the spectral gain of the non-negative impulse response filter can be arbitrarily close to the spectral gain of the input signal . we also show that the non-negative impulse response filter can be interpreted as a special case of the frequency-domain bounds , which are derived for geometrically spaced frequency regions .
in this paper , we propose a new representation theorem for horn logic , which is based on the notion of partial meet horn contraction . we show that the relevance-based partial meet horn contraction operator can be viewed as a special case of the partial meet horn contraction operator , and we show that horn formulae can be interpreted as a special case of the classical propositional logic . we also show that horn logic can be viewed as a parallel interpolation theorem , and that horn logic can be viewed as a special case of the partial meet horn contraction . finally , we show that the relevance-based partial meet horn contraction operator can be viewed as a special case of the partial meet horn contraction . finally , we show that the relevance-based partial meet horn contraction operator can be seen as a special case of the partial meet horn contraction operator .
in this paper , a statistical model of prosodic boundary location in mandarin is proposed for speech recognition . in the statistical model , the prosodic boundary type is determined by cart , which is calculated by a serial acoustic parameter . in the acoustic feature , syllable duration , intensity , and duration are taken into account . in the statistical model , the prosodic boundary type is predicted by cart , and the boundary efficiency is measured by the duration of the acoustic parameter . the experimental results on a large speech corpus show that the proposed statistical model is effective in improving the boundary efficiency in mandarin . moreover , the prosodic boundary type is also determined by the proposed statistical model .
denoising algorithms aim to recover missing textural details in the hr domain . in this paper , we propose a novel denoising algorithm to recover the original image from noisy and the denoised images . our denoising algorithm is inspired by the patch-similarity based sr algorithm , which is a convex combination of the hr versions of the hr image and the noisy image processing pipeline . in contrast to the patch-similarity based sr algorithm , our denoising algorithm takes into account the textural details in the hr domain . in contrast to existing denoising algorithms , our denoising algorithm is able to recover the original textural details in the noisy and the denoised images , without the need for noise in the hr versions . in addition , our denoising algorithm is able to recover the original image from the noisy and the denoised images . in addition , our denoising algorithm is able to recover the original textural details in the noisy image , without the need for noise in the sr step . we demonstrate the effectiveness of our denoising algorithm by comparing our denoising algorithm with other state-of-the-art denoising algorithms .
we present tetris , a new evaluation function for sequential decision problems , that combines domain knowledge into learning algorithms . tetris is is , a generalization of the standard evaluation function , and applies it to a variety of decision problems , including noncompensation , cumulative dominance , dominance , and dominance . we show that tetris is is a special case of tetris , and show that tetris can be used to find optimal decision problems with high probability . we also show that tetris is is a special case of tetris , and that tetris can be used to find optimal decision problems with high probability .
many computer vision tasks rely on the raw format of the camera images . however , most of these computer vision tasks require a mapping from raw images to raw values . in this paper , we propose a illumination-independent mapping approach that leverages white-balancing in a global and illumination-specific manner and linear and non-linear transformations . our illumination-independent mapping approach takes advantage of the fact that the raw-rgb values of a raw image can be represented by a set of minimally processed sensor responses . the mapping from raw images to raw values is invariant to camera manufacturers , and the mapping from raw images to raw values is invariant to changes in camera spectral sensitivities . we demonstrate the effectiveness of our illumination-independent mapping approach on a variety of images of arbitrary scenes and illuminations . our illumination-independent mapping approach is general and can be applied to any type of mapping strategies such as linear and non-linear transformations . our illumination-independent mapping approach is demonstrated on a variety of consumer cameras and a variety of images of arbitrary scenes .
in this paper , we study the representation of multi-agent environments with modal operators . we introduce the concept expressions as a syntax for the description of multi-agent environments , which allows us to define terminological knowledge representation formalisms , including modal operators . we show that such modal operators can be expressed in terms of notions such as belief , intentions , and other notions such as belief . we also show that such notions can be expressed in terms of modal logics . we also show that such modal operators can be expressed in terms of the language of the application domain . finally , we show that such a formalism can be used in conjunction with existing terminological knowledge representation formalisms .
contextual information selection based on word relationships , such as proximity , sentence co-occurrence , etc. , has been shown to be effective for automatic synonym acquisition . however , contextual information selection based on word relationships has not been thoroughly investigated . in this paper , we propose a novel approach to automatically select contextual clues of words based on the dependency relations between words . the contextual clues of words are automatically extracted from the contextual information , and the contextual information is utilized to select the appropriate modification categories . the experimental results show that the proposed method can effectively select the appropriate contextual information for synonym acquisition . moreover , the proposed method can select the appropriate modification categories based on contex-tual information . the experimental results show that the proposed method can achieve better performance than the state-of-the-art methods .
in this paper , we propose a constraint model based on domain transition graphs . the constraint model is based on the minion the constraint solver , which is a parallel planning planner . the constraint model uses table constraints to guide the search for a parallel plan . the constraint model is trained on domain transition graphs , which are used to guide the search for an optimal solution . we evaluate the constraint model on two benchmark domains : the wild cards and the wild cards . the results show that the constraint model outperforms constraint-based planners , and that the constraint model is competitive with state-of-the-art constraint-based planners .
we present an unsupervised learning approach for learning action classes from training images . our unsupervised learning approach is based on spectral clustering , a linear programming relaxation technique for finding a coarse shape of an action class given a small number of training images . the pruning method is applied to both clustering and image labeling . the pruning method is demonstrated on a variety of images , and the results show that our unsupervised learning approach compares favorably to the state of the art in both clustering and image labeling .
statistical pcfg -lrb- pcfg -rrb- parsers trained on small datasets have been shown to be effective in reducing the annotation cost of the in-domain case . in this paper , we propose self-training to improve the performance of a parser trained on small datasets . we show that self-training improves the performance of the statistical pcfg parsers trained on small datasets , and that self-training improves the performance of the in-domain case . we also show that self-training improves the performance of the parser trained on small datasets , and that self-training improves the performance of the in-domain case . we also show that the domain adaptation case is not limited to a small amount of manually annotated seed data , and that self-training improves the performance of the in-domain case by a significant margin in the out-of-domain adaptation scenario and a small amount of seed and test data .
we present a computer-controlled version of the umeda & teranishi model of the human vocal tract . the head-shaped model consists of a sliding tongue and a sliding three-tube model , and a computer-controlled version of the umeda & teranishi model . physical models of the vocal tract are used to model the dynamics of the human vocal tract . the head-shaped model is used to model the dynamics of the human vocal tract . the head-shaped model is compared with two popular dynamic models : the sliding three-tube model and the recently proposed the standard , and the recently proposed models of the vocal tract . the results show that the proposed models are capable of modeling the dynamics of the human vocal tract .
the margin-based algorithm is a popular margin-based algorithm for classification problems . in this paper , we consider the problem of selective sampling when the instance distribution is unknown . we propose a selective sampler based on logarithmic factors , and prove that the convergence rate of the selective sampler converges to the bayes risk under low noise condition . we also propose selective sampling versions of the margin-based algorithm for classification problems under low noise condition . experiments on textual data show that the selective sampler achieves better performance than the bayes risk when the instance distribution is unknown .
in this paper , we propose a data-driven approach to phone set construction for code-switching speech recognition . in our data-driven approach , a large-scale code-switching speech database is used for model training . in the proposed data-driven approach , a hierarchical phone unit clustering algorithm is adopted for model construction . in the proposed data-driven approach , a set of acoustic features and a set of cross-lingual context-sensitive articulatory features are extracted from the acoustic features in the distance measure . in the proposed data-driven approach , the phone set construction is performed by maximizing the kl-divergence between the acoustic features in the distance measure and the acoustic features in the distance measure . the experimental results show that the proposed data-driven approach outperforms the conventional phone set construction methods . in addition , the proposed data-driven approach has the potential to alleviate the data sparseness problem in code-switching speech recognition .
stochastic models of discourse coherence have been shown to be effective in improving the performance of coherence models . in this paper , we show that these models can be used to improve the performance of a variety of coherence models . we also show that these models can be used to improve the performance of a wide range of coherence models . finally , we show how these models can be used to improve the performance of a wide range of coherence models .
maximum margin matrix factorization -lrb- mmmf -rrb- is a popular method for learning the parameters of multiple collaborative prediction benchmarks . in this paper , we propose an ensemble approach to learn the parameters of the mmmf model , which can be efficiently solved by fast gradient-based methods for maximum margin matrix factorization . in addition , we propose an ensemble approach to learn the parameters of the mmmf model , which significantly reduces total training time . experimental results show that the proposed mmmf model significantly outperforms the state-of-the-art methods in terms of evaluation metrics .
this study investigates the influence of jaw movements on syllable nucleus position on syllable nucleus position . the influence of jaw opening on syllable nucleus type and phonemic length effects on syllable nucleus type is examined . the results show that the influence of jaw opening on syllable nucleus position on syllable nucleus position is more important than the influence of jaw opening on syllable nucleus position . furthermore , the influence of the phonemic length distinction on vowels is investigated . the results also show that the influence of jaw opening on syllable nucleus type is more important than the effect of jaw opening on syllable nucleus position . the influence of jaw opening on the rising-falling sonand the phonemic length distinction on vowels is also discussed .
in this paper , we study the relationship between wavelet moments and the zero scaling function . we show that the wavelet moments and the zero scaling function are equivalent to the nonunique solutions . moreover , we show that these nonunique solutions are less sensitive to the choice of the wavelet moments . finally , we show that these nonunique solutions can be implemented in a simple manner .
in this paper , we propose a probabilistic model for information retrieval based on a probabilistic model that captures both topical or semantic content of documents . the probabilistic model is based on a lower-dimensional latent variable representation of common words and a mixture distribution over the background distribution . the probabilistic model is able to capture both the specific aspects of the document and the specific aspects of the document . the proposed probabilistic model can be used for dimension-reduction of sparse count data . the probabilistic model can be used as a prior for information retrieval , and can be used as a prior for abstraction . the proposed probabilistic model can be applied to various topic models , and the probabilistic model can be used for information retrieval . the experimental results show that the proposed probabilistic model can effectively capture the specific aspects of the document and the specific aspects of the document . moreover , the proposed probabilistic model can also be used for other applications , such as topic models , and the proposed probabilistic topic models .
planning in dynamic continuous environments is a challenging problem due to the lack of domain knowledge . hierarchical task network planners have been shown to be effective in planning under uncertainty , but hierarchical task network planners are still limited in their ability to deal with continuous effects . in this paper , we propose a novel htn planner with nonlinear continuous effects . htn planner is based on a state projection algorithm , which can deal with nonlinear continuous effects in the planning domain . the proposed htn planner is evaluated in a benchmark domain and compared with a discrete effects htn planner and a linear continuous effects planner . the results show that the proposed htn planner is able to cope with continuous effects in the planning domain , and that htn planner is able to cope with complex nonlinear continuous effects . furthermore , we show that the proposed htn planner is able to cope with continuous effects in the planning domain .
in this paper , we present an automatic voice response application of mandarin chinese and mandarin chinese . the automatic voice response application is based on the analysis of the f 0 context contour of the inserted word . the f 0 context contour of the inserted word is used as the basic unit for tone combination . the f 0 context contour of the inserted word is used as the basic unit of the automatic voice response application . the experiment results show that the f 0 rs of the inserted word can be used as the basic unit of the automatic voice response application .
this paper presents a novel search method for computer-assisted translation engines that uses finite-state automata to combine the output of automatic speech recognition models with the output of statistical machine translation models . the statistical prediction engine is a search method for computer-assisted translation engines that uses asr word graphs to combine the output of the statistical prediction engine with the output of the automatic speech recognition models . the finite-state automata are then used to combine the output of the statistical prediction engine with the output of the automatic speech recognition models . we present experimental results that show that the use of finite-state automata improves the performance of the n-best rescoring approach . furthermore , we show that the use of finite-state automata improves the performance of the automatic speech recognition models , especially when human translator types are used .
the modulated orthogonal sequence is an extension of information construction methods to the modulated orthogonal sequence . in this paper , we introduce dummy , a novel method for symbol generation based on integer sums and modular techniques . the method is based on the autocorrelation and cram correlation characteristics of the modulated orthogonal sequence . it is shown that the symbol error probability of the modulated orthogonal sequence is independent of the choice of cross-correlation , and that the symbol error probability of the dummy is independent of the number of bits .
in underwater acoustic environments , the array 's source localization capability is affected by environmental uncertainties such as acoustic-field 's spatial coherence and array modules . in this paper , we propose a two-stage approach to passive ranging that exploits the spatial coherence of the towed multi-module array to improve the array 's source localization capability in underwater acoustic environments . the proposed two-stage approach exploits the correlation between the array 's source localization capability and the spatial coherence of the towed array . simulation results show that the proposed two-stage approach significantly improves the performance of passive ranging .
in this paper , we present a novel approach to automatic road extraction from aerial imagery . the approach is based on geometric constrained snake-based edge extraction , which exploits the scale-space behavior of roads and the bridging of shadows . the proposed approach has been tested on two different databases and the results show that the proposed approach outperforms the state-of-the-art methods .
multistage rvq -lrb- multistage rvq -rrb- is a powerful tool for fine-grained feature attribution in image understanding . multistage rvq is a bayesian framework for class conditional pattern recognition based on a markov random field . multistage residual vector quantizers are derived from direct sum decoder codebooks in a maximum a-posteriori sense . multistage residual vector quantizers are used for class conditional pattern recognition and data compression . multistage rvq is used for image understanding and classification . multistage rvq is based on stage-wise codebooks in order to reduce the number of voronoi cell partitions in the input space and to reduce the dimensionality of the multistage structure . optimized classification is achieved by minimizing the number of bits needed for data compression . the proposed multistage residual vector quantizers is evaluated in the context of image-content classification . the proposed multistage residual vector quantizers are compared with the state of the art in image understanding .
surface normal direction estimation is a fundamental problem in many indoor environments . in this paper , we present a novel approach to surface normal direction estimation from images . unlike previous approaches , our approach does not require any prior knowledge of the scene geometry or the scene geometry . instead , it does not require any prior knowledge of the scene geometry . instead , it does not require any prior knowledge of the scene geometry or the scene geometry . instead , it does not require any prior knowledge of the scene geometry or the scene geometry . instead , it does not require any prior knowledge of the scene geometry . instead , it does not require any prior knowledge of the scene geometry or the classifier responses . we demonstrate the effectiveness of our approach on two real-world datasets and show that our approach outperforms state-of-the-art methods for binocular stereo matching and single view depth estimation using driven classification . we also show that our approach outperforms the state of the art benchmark datasets .
in this paper , we present a natural language generation system for german text . the natural language generation system uses topolog-ical fields to generate constituent orders for coherent text . topological fields are used to represent the high-level , semantic , semantic , semantic , semantic , and semantic information . topological fields are used to represent the semantic order of an entity grid model , and are used to model the local coherence of a sentence . the coherence component of the natural language generation system is then used to generate constituent orders for each sentence . the proposed natural language generation system is evaluated using manual annotations and is shown to be effective in generating coherent text from natural language generation . the results show that the proposed natural language generation system is able to generate more complex german text than the state-of-the-art systems .
client-server automatic speech recognition -lrb- client-server automatic speech recognition systems -rrb- systems use packet loss recovery to improve the performance of client-server automatic speech recognition systems . in this paper , we analyze the effect of packet loss recovery on client-server automatic speech recognition systems performance . we show that under low and medium loss channel conditions , packet loss rates can be reduced by up to 50 % relative to a forward error correction system . we also analyze the effect of data acquisition delay on the performance of client-server automatic speech recognition systems . finally , we analyze the effect of channel loss models on the performance of client-server automatic speech recognition systems . finally , we analyze the effect of simulated packet on the performance of client-server automatic speech recognition systems .
deep belief nets -lrb- deep belief nets -rrb- are a powerful multi-layer generative model for natural language call routing . in this paper , we introduce a new learning technique for deep belief nets that is able to learn from unlabeled data . we show that deep belief nets can be used to train a multi-layer generative model for natural language call routing . the deep belief nets can be trained end-to-end using standard text classification algorithms such as support vector machines , boosting , and maximum entropy . we show that the deep belief nets can be used to train a feed-forward neural network with backpropagation , and that deep belief nets can learn features that are useful for image , audio and speech classification . we also show that the deep belief nets can be used to train a multi-layer generative model for natural language call routing .
in this paper , we investigate the role of time-frequency grouping in object localization . we propose a method for binaural and stereo speech segregation that uses localization information for sequential grouping of time-frequency objects . the proposed method is based on the localization of groups of time-frequency units in the room reverberation . we show that the proposed method is effective in localization of groups of time-frequency units in reverberant speech .
in this paper , we present a novel approach to semantic interpretation based on first-order unification-based semantic interpretation . the approach is based on the montagovian semantics of coordination , which allows for partial execution of the form of a first-order unification-based semantic interpretation . the semantic interpretation of the coordinate constructs is obtained by means of a set of simple and efficient and efficient algorithms . we also show that the proposed approach can be applied to the task of semantic interpretation .
scan-line optimization -lrb- sgm -rrb- has been widely used in many computer vision applications . it has been shown that sgm is a semi-global cost integration strategy for 3d medical image registration , especially when high dimensional data are available . however , when high dimensional data is available , sgm is a coarse-to-fine strategy . in this paper , we propose a novel cost accumulation for scan-line optimization for stereo estimation . sgm is a semi-global cost integration strategy that can handle registration errors in sgm-3d . sgm is designed to reduce the search space dimension for consecutive pyramid levels . the performance of sgm is evaluated on 3d ct scan pairs collected from copdgene study archive . the experimental results show that sgm can significantly improve the performance of sgm-3d in clinical applications .
in this paper , we propose a multi-view domain generalization approach for visual recognition and domain generalization . in our multi-view domain generalization approach , a set of multi-view features are learned from unlabeled target domain samples , and a set of exemplar svms are used to learn the svm classifiers for domain generalization capability . in the proposed multi-view domain generalization approach , the weight matrix of each target domain is represented by a low-rank representation of the target domain samples , and the weight vectors of the target domain are learned from the target domain samples . in the proposed multi-view domain generalization approach , the weight vectors of the target domain are learned from the target domain samples , and the weight vectors of the target domain samples are learned by an alternating optimization algorithm . in the proposed multi-view domain generalization approach , each target domain is represented by a low-rank representation of the target domain samples , and the weight matrices of the target domain samples are learned from the target domain samples by the proposed multi-view domain generalization approach . the proposed multi-view domain generalization approach is evaluated in the context of domain generalization and visual recognition . the experimental results show that the proposed multi-view domain generalization approach outperforms the state-of-the-art methods in both domain generalization and visual recognition .
in this paper , we propose a novel approach to audio tag annotation and retrieval based on audio tags . given a piece of music clip -lrb- e.g. , mood , etc. -rrb- , the audio tags are annotated according to their tags , and the audio tags are annotated according to their musical knowledge . we formulate the audio tagging problem as a cost-sensitive multi-label learning problem , and formulate the audio tagging problem as a cost-sensitive classification problem . in order to deal with noisy information , we propose a mirex 2009 winning method to learn the tag correlation for automatic audio tagging . the experimental results show that the proposed method can achieve better performance than the state-of-the-art methods , especially when the tag count is very low . moreover , the proposed method can be applied to a wide range of applications .
we consider the problem of bipartite graph inference in a supervised learning problem . given a network topology of the bipartite graph , we formulate the bipartite graph inference as an optimization problem in a reproducing kernel hilbert space . the objective is to find the optimal solution in a unified euclidean space , where the objective is to find the optimal solution in a unified euclidean space . we demonstrate the effectiveness of our approach on a variety of compound-protein interaction network reconstruction from chemical structure data and genomic sequence data .
in this paper , we consider the problem of reconstructing a spatial field from a moving sensor . in particular , we consider the problem of sampling time-invariant spatial fields from a single time-domain signal , where the field values are assumed to be static . we propose a method for sampling time-invariant spatial fields from static sensors , where the spatial field is sampled from a moving sensor . we show that the temperature measurement problem can be reduced to a temperature measurement problem , which can be solved by sampling from a single time-domain signal . we show that the proposed method is able to recover a wide spatial area , even in out-of-band noise , and can be used for filtering and mobile sensors . the reconstruction accuracy of the proposed method is demonstrated by simulation .
tractable models for complex high level structure can be used to learn complex high level structure from a single image . in this paper , we propose a novel loss-sensitive joint learning procedure to learn compositional high order pattern potentials . the compositional high order pattern potentials is composed of a set of linear deviation pattern potentials in the compositional high order pattern potentials . the compositional high order pattern potentials is composed of a set of linear deviation pattern potentials in the compositional high order pattern potentials , and a quantitative variability measure of the internal pattern parameters in the compositional high order pattern potentials is used to learn an image-dependent mapping from image features . the proposed loss-sensitive joint learning procedure is based on restricted boltzmann machines , which can learn an image-dependent mapping from the input image to the output of the mod-eling structure . the proposed loss-sensitive joint learning procedure has been tested on two challenging high variability datasets , and the results show that the proposed loss-sensitive joint learning procedure can effectively learn high order potentials for prediction and prediction with high variability datasets .
we present a generative model for unsupervised learning of dependency structures . the generative model is based on a model of linear constituency , which is able to capture distributional regularities in the data . the generative model is evaluated on three evaluation metrics : unsupervised constituency parsing and un-supervised dependency parsing . the results show that the generative model is able to learn the structure of a sentence , and that generative model is able to learn the structure of a sentence .
we consider the problem of compressed sensing with small alphabets of a k × n measurement matrix . we consider additive character sequences with small alphabets , and propose an l 1-minimization method to recover the deterministic sensing matrix from noiseless measurements . the proposed l 1-minimization method minimizes the weil bound of the deterministic sensing matrix subject to an incoherent tight frame . we show that the proposed l 1-minimization method converges to an asymptotically optimal coherence , and that l 1-minimization method achieves the weil bound for noiseless measurements . we also show that the proposed l 1-minimization method can be applied to the problem of compressed sensing with small alphabets in compressed sensing . simulation results show that the proposed l 1-minimization method outperforms existing methods .
we propose a nonparametric , wavelet-based density estimation method for inferring queuing delay distributions from host-based , end-to-end measurements . the proposed nonparametric , wavelet-based density estimation method is based on the assumption that the unknown parameters are known a priori limit . we derive a fast fourier transform implementation of the expectation-maximization optimization algorithm , and derive an efficient estimation procedure for the unknown parameters of the nonparametric , wavelet-based density estimation method . we demonstrate the accuracy of the proposed estimation procedure through network level ns simulations . we also show that global internet monitoring provides spatially localized information about the delay distributions .
distributed constraint optimization -lrb- distributed constraint optimization -rrb- is a fundamental problem in coordinated multiagent decision making . in this paper , we propose a convergent message-passing algorithm for distributed constraint optimization based on probabilistic inference . the convergent message-passing algorithm is based on two inference techniques : expectation-maximization and convex optimization machinery . the first convergent message-passing algorithm is a centralized solver , and the second convergent message-passing algorithm is guaranteed to converge to near-optimal solutions . the second convergent message-passing algorithm is based on a novel set of inference techniques , called expectation-maximization and convex optimization machinery , which is guaranteed to converge to the optimal solution of the coordination problem . we evaluate the performance of the proposed convergent message-passing algorithm on several benchmark problems and show that the proposed convergent message-passing algorithm achieves a better failure rate than the centralized solver .
conditional random fields -lrb- conditional random fields -rrb- are powerful multivariate evaluation measures for sequential segmentation tasks such as segmentation f-score , text chunking , and named entity recognition . however , conditional random fields are usually designed to optimize a target evaluation measure . in this paper , we propose a novel loss function for conditional random fields , which is able to optimize a variety of non-linear measures such as f-score . the proposed loss function is based on a novel error minimization approach , which can be easily incorporated into crf training . experimental results show that the proposed loss function can significantly improve the performance of sequential segmentation tasks , especially when the evaluation measure is not available .
lifted probabilistic inference -lrb- lifted probabilistic inference -rrb- is an important class of inference methods for non-relational probabilistic inference . existing inference methods for lifted probabilistic inference assume that parameterized random variables are parameterized . in this paper , we show that lifted probabilistic inference can be viewed as a special case of lifted probabilistic inference . we show that lifted probabilistic inference can be viewed as a special case of lifted probabilistic inference , and that lifted probabilistic inference can be viewed as a special case of lifted probabilistic inference . we show that lifted probabilistic inference can be viewed as a special case of lifted probabilistic inference , and that lifted probabilistic inference can be interpreted as a special case of lifted probabilistic inference . we show that the population sizes of lifted probabilistic inference can be reduced to np-complete , and that the population sizes of lifted probabilistic inference can be reduced to np-complete .
partially observable markov decision processes -lrb- partially observable markov decision processes -rrb- provide a framework for modeling uncertainty in partially observable markov decision processes with cost observations . in this paper , we consider the problem of learning a policy in partially observable markov decision processes with cost observations . we propose a search-based algorithm , called search-based algorithm , that learns a policy that minimizes the cumulative cost of a partially observable markov decision processes subject to a user-defined cost threshold . we prove that search-based algorithm converges to the optimal policy under a user-defined cost threshold . we empirically evaluate search-based algorithm on both synthetic domains and on a variety of synthetic domains . the results show that search-based algorithm significantly outperforms the state-of-the-art algorithms in both domains .
we consider the phase retrieval problem where the objective function is a lipschitz continuous gradient with respect to a poisson noise model . the maximum-likelihood estimator is formulated as a convex program with the nuclear norm constraint . we show that the frank-wolfe algorithm has the same global convergence rate as the frank-wolfe algorithm for the poisson phase retrieval problem , but with convergence guarantees as the iteration counter . we also show that the lanczos method can be used to solve the poisson phase retrieval problem under nuclear norm constraints . we show that the proposed lanczos method outperforms the frank-wolfe algorithm for nuclear norm constraints , and that the proposed lanczos method is competitive with the frank-wolfe algorithm for the poisson phase retrieval problem .
in this paper , we propose a method to recognize speaking styles using two-dimensional visual map . the method is based on the use of hmm acoustic models derived from gaussian distributions of multidimensional vectors . the hmm acoustic models are obtained by applying a multidimensional scaling technique to the marginal region of a speech recognition system . the recognition performance of the proposed method is compared with that of a conventional acoustic model library . the results show that the proposed method is capable of representing speaking styles with a high degree of variability in human visual perception .
in this paper , we propose a novel expectation-maximization clustering algorithm for chinese verb sense discrimination . chinese verbs are represented by a semantic taxonomy which is constructed from electronic chinese semantic dictionaries . in order to capture predicate-argument structure information between chinese verbs , we propose a novel expectation-maximization clustering algorithm based on rich linguistic features , which utilizes fine-grained semantic categories -lrb- e.g. , lexical sets , and predicate-argument structure information -rrb- as well as normalized mutual information . experimental results show that the proposed expectation-maximization clustering algorithm is effective for chinese verb sense discrimination .
in this paper , we propose a method for disfluent speech synthesis based on local modifications to the segmental units of the synthetic disfluent speech . in our method , the disfluency elements of the sentence are automatically determined by the insertion of editing terms and the insertion of editing terms . in the proposed method , the prosodic modifications of the disfluency elements are automatically generated by the proposed method . the proposed method was evaluated by means of spoken translation and automatic film , and it was confirmed that the proposed method was able to synthesize the synthetic disfluent speech with a high degree of prosody .
rolling shutter is an essential component of cmos image sensors . however , the rolling shutter phenomenon in cmos image sensors causes rolling shutter deformations . in this paper , we propose a closed-form linear solution to the problem of estimating the 3d pose and velocity of a moving object from a single view . the proposed closed-form linear solution is based on bundle adjustment and non-linear optimization . the proposed closed-form linear solution can handle planar objects with full 3d velocity and rolling shutter deformations without 2d-3d point correspondences . the accuracy of the proposed closed-form linear solution is demonstrated on several challenging datasets . the proposed closed-form linear solution can be used to estimate the 3d pose of a moving object from a single view of a velocity sensor .
in this paper , we propose a two dimensional maximum margin criterion for dimensionality reduction in images . the proposed two dimensional maximum margin criterion is a generalization of the maximum margin criterion for feature extraction . the proposed two dimensional maximum margin criterion is based on the two dimensional maximum margin criterion . in the first step , a set of orthogonal projection matrices is obtained by means of the proposed two dimensional maximum margin criterion . in the second step , the proposed two dimensional maximum margin criterion is applied to the subspace matrix representation data . theoretical analysis and experimental results on benchmark face recognition data sets demonstrate the effectiveness of the proposed two dimensional maximum margin criterion .
bruneians are frequently used in mandarin chinese as well as mandarin chinese . in this study , acoustic characteristics of brunei mandarin are analyzed and analyzed . the acoustic characteristics of brunei mandarin are analyzed in terms of their ability to identify the sound change in brunei mandarin . the acoustic characteristics of brunei mandarin are analyzed in terms of their ability to identify the sound change in brunei mandarin . the results show that the acoustic characteristics of brunei mandarin are quite similar to those of female speakers , and that the perceptual judgments of frication are quite similar to those of female speakers . correct classification of the acoustic characteristics of brunei mandarin is found to be significantly higher than those of female speakers . the perceptual judgments also show that the acoustic characteristics of brunei mandarin are important for closure identification .
in this paper , we propose a novel approach to automatically generate comparative news summaries . we first extract topic-related concepts from news topics , and then extract semantic-related cross-topic concept pairs from these topics . we formulate the optimization problem as a linear programming model , which can be solved efficiently . experimental results show that our approach significantly outperforms the state-of-the-art methods .
in this paper , we consider the problem of precoding in the multi-antenna fading channel for stochastic power allocation in multi-antenna channels . we consider the stochastic optimization problems where the objective function is the sum of the laplace transform order with nonnegative random variables , and the objective function is the sum of the sum of the sum of the sum of the laplace transform order and the maximum ergodic or effective capacity . we show that the laplace transform order is a nonconvex structure of the laplace transform order , and we show that the laplace transform order is a special case of the laplace transform order . we also show that the laplace transform order can be interpreted as a special case of relaying .
in this paper , we investigate design tradeoffs for orthogonal frequency-division multiple access in an uplink . the proposed open-loop space-frequency block coding scheme is based on the idea of reducing the number of transmit antennas required to achieve full spatial diversity in the uplink . the proposed open-loop space-frequency block coding scheme is capable of providing a good tradeoff between performance degradation and robustness against doppler . the proposed open-loop space-frequency block coding scheme can be applied to an lte standard with a small number of antennas and a small number of antennas . the proposed open-loop space-frequency block coding scheme can also be applied to an existing , orthogonal frequency-division multiple access , where the doppler robustness is limited by the number of users . the proposed open-loop space-frequency block coding scheme can also be applied to an efficient and scalable , lte-advanced standardization uplink . simulation results show that the proposed open-loop space-frequency block coding scheme can achieve significant performance gains over the existing lte-advanced standardization uplink transmit diversity schemes .
in this paper , we present a two step approach to face model synthesis in 3d synthesis . the first step uses active contour models and real-time facial segmentation to generate a 3d-face model . the second step uses a two step approach which combines active contour models with real-time facial segmentation to generate a global analysis/synthesis chain . the second step uses a two step approach which combines the advantages of the two step approach . the second step uses the advantages of the two step approach . the third step uses the advantages of the two step approach in two steps : facial segmentation , facial segmentation , feedback control , and augmented reality . the third step uses the advantages of the two step approach in a real time application . the third step uses the advantages of the two step approach . we present results on a global real-time face tracking application .
word sense disambiguation is the task of determining the sense of a word given its context words . in this paper , we propose a new perl package , called a targetword , to address the problem of word sense disambiguation . we introduce a targetword , a perl package , which includes three similarity perl modules , and evaluate its performance on two tasks : -lrb- 1 -rrb- word sense disambiguation , -lrb- 2 -rrb- word sense disambiguation , -lrb- 3 -rrb- word sense disambiguation , and -lrb- 3 -rrb- word sense disambiguation . the experimental results show that the targetword outperforms the state-of-the-art methods , and -lrb- 3 -rrb- word sense disambiguation performance is competitive with the best reported results .
in this paper , we propose a method to enhance the speech signal reflections in reverberant environments . the proposed method is based on the observation that the relative transfer functions of the source and target signals can be approximated by the relative transfer functions of the source and target signals . the proposed method consists of two steps : -lrb- 1 -rrb- noise reduction and suppression of reverberations . -lrb- 2 -rrb- noise reduction is performed by the proposed method . -lrb- 3 -rrb- noise reduction is achieved by the proposed method . -lrb- 3 -rrb- noise reduction is achieved by the proposed method . -lrb- 3 -rrb- the proposed method is compared with the conventional delay-and-sum beamformer . -lrb- 3 -rrb- the experimental results show that the proposed method is effective in reducing the speech signal reflections in reverberant environments . -lrb- 3 -rrb- the proposed method is also compared with the conventional methods . -lrb- 3 -rrb- the proposed method is shown to be more robust to noise reduction and suppression of reverberations compared with the conventional methods .
we consider the problem of supervised learning for rank tasks . in particular , we consider the problem of learning point-wise ranking functions , where the loss function is a function of the set of ranking functions , and the goal is to minimize the bayes optimal ranking functions subject to a natural symmetricity assumption . we propose a reranking method based on representation theory , which can be viewed as a natural extension of the standard representation theory for permutation-valued functions . we show that the proposed reranking method can be viewed as a natural extension of the widely used list-wise ranking functions , such as tensor analysis , functional analysis , de finetti theorems , and show that the proposed reranking method can be viewed as a special case of the proposed representation theory . in particular , we show that the proposed reranking method can be viewed as a natural extension of the standard supervised learning for rank tasks .
in this paper , we propose a method to improve the dialogue efficiency of dialogue systems by incorporating higher level information in the recognition process . in the proposed method , the dialogue manager is first used to parse the dialogue state , and then the dialogue manager is used to predict the next dialogue state . in the proposed method , the dialogue expectation is used to improve the recognition performance . in the proposed method , the dialogue expectation is used as the decoder expectation for the next dialogue state , and the dialogue manager is used as the decoder expectation for the next dialogue state . the proposed method is evaluated on a flight reservation task . the experimental results show that the proposed method is effective in reducing speech recognition errors and improve the dialogue efficiency .
in this paper , we propose a point set registration algorithm based on the bidirectional em process . the proposed point set registration algorithm consists of a robust gaussian mixture model with a noise component that is robust to outliers . the proposed point set registration algorithm is evaluated on both synthetic data and point sets obtained from medical images . the accuracy and robustness of the proposed point set registration algorithm is compared to the state-of-the-art registration techniques . the results show that the proposed point set registration algorithm is robust to outliers and is robust to outliers .
in this paper , we propose a novel image representation for indoor and outdoor scene classification . we propose a novel scene representation model , called latent pyramidal regions , to capture both global and local scene characteristics . latent pyramidal regions represent the discriminative characteristic of the scenes by a spatial pyramid based on non-linear locality constraint coding . the spatial pyramid representation is learned by nonlinear feature coding and latent support vector machine . a latent svm training procedure is adopted to learn the parameters of the latent pyramidal regions . the proposed image representation is evaluated on two challenging datasets : uiuc-sports and pascal voc 2007 . the experimental results show that the proposed image representation outperforms the state-of-the-art methods .
in many machine learning applications , there is a need for a priori knowledge about the structure of the problem . in this paper , we present a formalism for specifying invariances in an adaptive network . the formalism is based on the notion of a set of distortion operators that are invariant to rotations , scale changes , and rotations . we show how these distortion operators can be used to control the learning time of a character recognizer . we present experimental results that demonstrate the effectiveness of the formalism .
in this paper , we consider the problem of blind channel estimation in ofdm systems . we consider the problem of blind identification in orthogonal orthogonal frequency division multiplexing -lrb- ofdm -rrb- systems , where the channel is assumed to have an integer part and a fractional part . we propose a multiple-constellation scheme to resolve the inherent ambiguity in the orthogonal frequency division multiplexing -lrb- ofdm -rrb- system . the proposed multiple-constellation scheme exploits the information of source constellation and channel constellation in order to reduce the impact of pilot overhead on semi-blind identification performance . the proposed multiple-constellation scheme is based on the assumption that the scalar ambiguity is independent of the number of channels and the number of channels is equal to the number of channels . simulation results show that the proposed multiple-constellation scheme outperforms the existing methods in blind channel estimation .
minimisation-based approaches to belief merging and belief revision are typically based on the set-theoretic notion of minimisation . in this paper , we consider minimisation-based belief change , where vertices are represented by an undirected graph . vertices are represented by semantic and syntactic characterisations of the graph . we show that the vertices of the graph correspond to spatial locations , and that the vertices of the graph correspond to the cardinality-based and priority-based minimisation . we show that the vertices of the graph correspond to a set-theoretic notion of minimisation , and that the vertices of the graph correspond to the vertices of the graph .
in this paper , we propose a fast regression model for single image super-resolution using in-place examples . our fast regression model is based on a set of super-resolution approaches , where each image is represented by a patch and its origin location is represented by a set of low-to high-resolution image patches . given an external database , our fast regression model learns a nonlinear mapping function based on a first-order approximation of the low-to high-resolution image patches . the in-place self-similarity of the input images is exploited for robust estimation . the in-place self-similarity of the input images is exploited to preserve the local self-similarity of the input images . the proposed fast regression model is evaluated on both benchmark and real-world images , and the experimental results show that our fast regression model is robust to noise and robust to diverse textures .
in this paper , we present a formal language for specifying combinatorial problems with arbitrary depth . essence is a complex combinatorial object that can be represented by a set of combina-torial objects such as tuples , multisets , partitions , relations , etc. . each combinatorial object is represented by a set of decision variables , each of which represents a complex combinatorial object . each decision variable is represented by a set of decision variables , and each decision variable is represented by a set of natural rigorous specifications . each decision variable is represented by a formal language , and each decision variable is represented by a set of simpler , simpler , simpler , simpler , and more compact , and more compact . we show that this language can be used to specify a variety of combinatorial problems that can be solved by discrete mathematics and natural language .
we present an unsupervised learning algorithm for program synthesis that uses probabilistic modeling and solver-based techniques for program synthesis . the unsupervised learning algorithm is designed to learn visual concepts from noisy data , and can be used for unsupervised learning of symbolic composi-tional structures . we apply the program synthesis tools to the language learning problem , the visual learning domain , and the language learning problem . our results show that the learned program synthesis tools can learn from noisy data , and that the learned program synthesis tools can learn from noisy data .
in this paper , we address the problem of camera pose estimation from a single calibrated camera . we assume that the image of a known scene is known , and that the position of the calibrated camera is known to be known . we propose two optimal algorithms for this problem : one based on ransac and the other based on l ∞ norm , and the other based on classical geometry . the other is based on the l ∞ optimality of the l ∞ norm , which is robust to outliers . the former is based on the assumption that the image features of the calibrated camera are known , and the latter is robust to outliers . in the branch and bound setting , we propose two algorithms for computing the l ∞ optimality of the l ∞ norm . we demonstrate the effectiveness of our algorithms on real data .
in this paper , we present a controlled query evaluation framework for the evaluation of datalog and owl 2 profile ontologies . the controlled query evaluation framework is based on the assumption that the owl 2 profiles are strongly correlated with the ontology languages . we show that the proposed controlled query evaluation framework can be used to evaluate the performance of both datalog and owl 2 profile ontologies . we also show that the proposed controlled query evaluation framework can be used to evaluate the performance of the proposed controlled query evaluation framework . finally , we show that the proposed controlled query evaluation framework can be used to provide a reliable and efficient way to compare the existing owl 2 enforcement with censors .
in this paper , we address the problem of inferring the number of people in a large pedestrian dataset . in particular , we consider the problem of inferring the number of people in a large pedestrian dataset , where each person is represented by a set of holistic features extracted from the segmented region . we propose a privacy-preserving system , where each person is represented by a dynamic textures motion model , and each person is represented by a single dynamic textures motion model . we then use gaussian process regression to learn the parameters of the dynamic textures motion model , which can be used for explicit object segmentation and tracking . we evaluate our privacy-preserving system on a large pedestrian dataset and compare our crowd segmentation algorithm with a crowd counting system . our results show that our privacy-preserving system outperforms the state of the art in crowd tracking .
we propose a two-layer undirected graphical model , a two-layer undirected graphical model , for learning low-dimensional latent semantic representations from a unstructured collection of documents . two-layer undirected graphical model is a generalization of latent dirichlet allocation , which allows the two-layer undirected graphical model to scale to large collections of held-out documents . we derive learning and inference algorithms for the two-layer undirected graphical model , and evaluate two-layer undirected graphical model on two datasets , showing that two-layer undirected graphical model outperforms latent dirichlet allocation in terms of retrieval accuracy .
forward pruning is a powerful decision-making technique for game playing . in this paper , we introduce a new strategy for forward pruning in game playing . the strategy is based on the minimax values of sibling nodes in the game tree . we show that this strategy can be used to reduce the number of chess-playing programs by a factor of two orders of magnitude . we also show that the strategy of forward pruning can be used to reduce the number of game trees required to achieve a desired level of performance . finally , we show that the strategy of forward pruning can be used to improve the performance of game playing .
high-dimensional gaussian graphical model -lrb- ggm -rrb- is a powerful network estimation technique for reducing the number of variables in a high-dimensional gaussian graphical model . however , in many real-world networks , the number of variables in the ggm grows exponentially with the number of variables . in this paper , we propose a new module graphical lasso , called module graphical lasso , to reduce the dimensionality of the high-dimensional gaussian graphical model by exploiting the graph structure of the ggm . the proposed module graphical lasso is capable of reducing the number of latent variables in the ggm . the scalability of the proposed module graphical lasso is evaluated by comparing module graphical lasso with other clustering algorithms for predicting survival time of patients and functionally coherent gene sets in cancer biology . the results show that the proposed module graphical lasso outperforms the graphical lasso in terms of both scalability and ro-bustness . the proposed module graphical lasso is applied to gene expression data collected from ovarian cancer .
the earth mover 's distance -lrb- earth mover 's distance -rrb- is a well known kantorovich-rubinstein transshipment problem that has received much attention in recent years . in this paper , we propose a linear time algorithm for computing the earth mover 's distance in linear time . the key idea of earth mover 's distance is to formulate the earth mover 's distance as an optimization problem in the wavelet domain , where the histogram bins are represented by a weighted wavelet transform . we show that the earth mover 's distance can be computed by minimizing the earth mover 's distance in the dual form of the normal euclidean distance . we show that the optimization problem of earth mover 's distance can be efficiently solved using the wavelet emd metric . the computational complexity of the earth mover 's distance is linear in the number of bins and the number of bins is proportional to the hölder continuity constraint in the dual form of the earth mover 's distance . furthermore , we show that the earth mover 's distance can be efficiently computed by solving an optimization problem in the wavelet domain . finally , we show that the earth mover 's distance can be efficiently computed using the wavelet emd metric , and that earth mover 's distance can be computed by solving a linear time algorithm for low dimensional his-tograms .
in this paper , we consider the problem of parallel transmission of an unknown mimo channel . we propose an iterative demodulation algorithm to improve the transmission performance of a single input multiple output multiple output multiple output multiple output multiple output multiple output multiple output multiple output multiple output multiple output multiple output multiple output multiple output multiple output multiple output multiple output multiple output multiple output multiple output multiple output multiple output multiple output multiple output multiple output multiple output multiple output multiple output multiple output output multiple output output multiple output output multiple output output multiple output output multiple output output multiple output output multiple output output output multiple output output multiple output output multiple output output multiple output output multiple output output multiple output output output multiple output output multiple output output output multiple output output output -lrb- mimo -rrb- output multiple output output multiple output output multiple output output multiple output output output multiple output output output -lrb- mimo -rrb- output multiple output output multiple output output multiple output output multiple output output output multiple output output output multiple output output output multiple output output output output output multiple output output output output output output output output multiple output output output output output multiple output output output output output multiple output output output output output output multiple output output output multiple output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output output
noise power spectral density -lrb- pesq -rrb- is one of the most popular speech enhancement algorithms . in this paper , we propose a low complexity method for noise psd estimation based on minimum mean-squared error estima-tor . the low complexity method is based on the minimum mean-squared error estima-tor of the noise magnitude-squared dft coefficients of the noisy data . the proposed low complexity method is suitable for non-stationary noise sources with segmental snr and pesq for non-stationary noise sources . the simulation results show that the proposed low complexity method outperforms the conventional methods in terms of both segmental snr and pesq for non-stationary noise sources . the computational complexity of the proposed low complexity method is much lower than that of minimum statistics based noise tracking .
in this paper , a speech enhancement system based on time-frequency adaptive wavelet soft thresholding is proposed . the proposed speech enhancement system is based on the bark-scaled wavelet packet decomposition using the magnitude decision-directed approach . the bark-scaled wavelet packet decomposition is used as a threshold estimation method to estimate the wavelet band based on the computed threshold for the wiener filtering process . the proposed speech enhancement system is evaluated in stationary and non-stationary noise cases . the proposed speech enhancement technique is compared with the conventional speech enhancement technique based on the bark-scaled wavelet packet decomposition using the magnitude decision-directed approach . the experimental results show that the proposed speech enhancement system is effective in noise suppression . moreover , the proposed speech enhancement system is more robust to noise suppression than the conventional methods .
in this paper , we propose a decentralized state estimation scheme to estimate the global state estimate of a mobile base station in smart grid . the proposed decentralized state estimation scheme is based on network and distributed control areas , where the network reconfigurations are assumed to be distributed . the decentralized state estimation scheme is based on the power flow equations , which are robust against random failures and bad data . in the proposed decentralized state estimation scheme , the global state estimate is obtained by using the proposed decentralized state estimation scheme . the simulation results show that the proposed decentralized state estimation scheme outperforms the existing distributed techniques in terms of both the state estimation and the network reconfigurations . furthermore , the proposed decentralized state estimation scheme is very robust to noise variances . the proposed decentralized state estimation scheme is applied to the problem of smart grid <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> in the presence of bad data and random failures .
we consider the problem of integration in discrete graphical models , where the goal is to minimize the sum of a small number of map queries . we propose a randomized algorithm for finding the optimal partition function that minimizes the sum of a small number of randomly generated parity constraints . we show that this randomized algorithm can be viewed as a discrete combinatorial optimization problem with randomly generated parity constraints . we show that our randomized algorithm can be applied to a wide range of problems , including model selection , marginal computation , and computation .
this paper presents a new method for spectral estimation of sinusoids in voiced speech . the method is based on a family of mvdr estimates -lrb- mvdr estimates -rrb- and ſxed order mvdr-mfcc . the mvdr estimates -lrb- mvdr estimates -rrb- are obtained in a linear manner with coefſcients , and are obtained in a linear manner by using the least squares approach . in order modeling the sinusoidal frequency of the voiced speech , the sinusoidal and noise power of the signal are estimated in a ſxed model of the sinusoidal signal . in order modeling the sinusoidal and noise power of the estimated mvdr spectra , the mvdr estimates -lrb- mvdr estimates -rrb- are estimated in a linear manner using the mvdr estimate . recognition experiments on synthetic vowels show that the proposed method is able to accurately estimate the sinusoidal frequency of the voiced speech , and that the recognition performance of the proposed method is comparable to that of the original mvdr estimates -lrb- mvdr estimates -rrb- and ſxed order mvdr-mfcc .
this paper addresses the signal restoration problem in high-dimensional audio data processing . the signal restoration problem is formulated as a signal restoration problem , where the received signal is corrupted by noise , and the reconstructed signal is corrupted by saturation . we propose two declipping algorithms , one based on iterative hard thresholding , and another based on iterative hard thresholding . the first algorithm is a modification of the previously proposed declipping algorithms . the second algorithm is based on the assumption that the signal is generated by a small number of samples , and the second algorithm is based on the assumption that the signal is generated by a small number of samples . we evaluate the performance of the proposed declipping algorithms through subjective user listening evaluations . the results show that the proposed algorithms outperform the existing methods in terms of snr and snr .
in this paper , we consider the problem of joint base station assignment and linear beam-former design in a mimo heterogeneous network . we consider the problem of maximizing the sum rate between the base station assignment and the linear beam-former design subject to constraints on the system wide utility . we consider the problem of maximizing the α-fairness utility functions subject to constraints on the system wide utility . we propose an optimization problem to maximize the α-fairness utility functions subject to constraints on the system wide utility . we show that the proposed optimization problem can be efficiently solved by sum rate maximization . simulation results show that the proposed optimization problem can significantly improve the sum rate of linear transmit beamformers .
in this paper , we consider the problem of block synchronization in a zero-padding precoder for blind block synchronization problem in zero-padding systems . the proposed blind block synchronization algorithm is based on two generalized versions of the well-known blind block synchronization algorithm : one based on the repetition index and the other based on the parameter of the zero-padding precoder . the proposed blind block synchronization algorithm achieves a block synchronization error rate that is comparable to that of the original blind block synchronization algorithm . the performance of the proposed blind block synchronization algorithm is evaluated in terms of the block synchronization error rate and the performance of the proposed blind block synchronization algorithm is compared with that of linear redundant filterbank precoders for blind channel identification .
bounded pd-grammars -lrb- pd - -rrb- are widely used in many applications , such as unbounded raising , extraction , ex-trcompesition , and extraction . in this paper , we present a general framework for bounded pd-grammars , which extends the cf-grammar of -lrb- pd - -rrb- grammars to include both negative and positive va-lencies of words , and non-saturated valencies rules . in particular , we show that the lf-grammar of -lrb- pd - -rrb- grammars can be interpreted as a generalization of the cf-grammar of -lrb- pd - -rrb- grammars . we also show that the derived structures can be interpreted as a generalization of the cf-grammar of -lrb- pd - -rrb- grammars of -lrb- pd - -rrb- grammars . in particular , we show that the cf-grammar of -lrb- pd - -rrb- grammars can be interpreted as a generalization of the -lrb- pd - -rrb- grammars of -lrb- pd - -rrb- grammars .
in this paper , we propose a novel vision model for handwritten digit recognition based on biological vision . the proposed vision model consists of two steps . first , a linear classifier is used to extract features from the input image . second , a linear classifier is used to extract features from the input image . the experimental results show that the proposed vision model can achieve better performance than the state-of-the-art methods .
in this paper , we propose a method to extract spectral notches from pinna images using linear prediction residual cepstrum . the proposed method consists of two steps : first , the spectral notches are extracted from the batteaches reflection model , and second , the spectral notches are extracted from the linear prediction residual cepstrum . the experimental results show that the accuracy of the proposed method is comparable to that of the conventional method based on linear prediction residual cepstrum , and the accuracy of the proposed method is comparable to that of the conventional method based on linear prediction residual cepstrum .
we present a sound and complete algorithm for computing approximate subsumption in description logics . the sound and complete algorithm is based on a sound and complete algorithm for computing approximate subsumption in the presence of mismatch between the query and the query . the subsumption relation between the query and the query is parameterized by the subsumption relation between the query and the query . the sound and complete algorithm is applied to a wide range of matching tasks , including service discovery , information integration , and reasoning about structured objects in the web ontology language owl . the sound and complete algorithm is based on the concept of subsumption , which is a natural extension of subsumption in description logics . the sound and complete algorithm has been implemented in the context of approximate logical reasoning in the presence of mismatch . the sound and complete algorithm has been implemented in the context of computing approximate subsumption in the presence of mismatch between query and query queries . the sound and complete algorithm has been implemented in the context of the web ontology language owl .
in this paper , we propose a generalized version of the perceptually-shaped side-informed data hiding scheme . the perceptually-shaped side-informed data hiding scheme is a logarithmic quantization algorithm whose embedding power is bounded by the number of bits . simulation results show that the perceptually-shaped side-informed data hiding scheme can significantly improve the performance of the perceptually-shaped side-informed data hiding scheme .
in this paper , we propose a multiscale representation for point clouds that is based on lifting . the multiscale representation is based on the idea of lifting that the unknown smooth manifold can be represented by a point cloud with a lower-dimensional manifold structure . the multiscale representation can be seen as a generalization of the wavelet thresholding ideas and can be applied to a wide range of real world data sets with higher-dimensional space . the multiscale representation can be used to reconstruct a wide range of point clouds from noisy point cloud samples . the proposed multiscale representation can be used to reconstruct a wide variety of different types of point clouds .
in this paper , we propose an error-resilient scheme for the bit allocation problem in a video stream . the proposed error-resilient scheme is based on the distributed source coding principles of the main stream . the proposed error-resilient scheme consists of two stages : -lrb- 1 -rrb- a dsc based auxiliary stream for the bit allocation problem , and -lrb- 2 -rrb- a dsc based auxiliary stream for the bit allocation problem . in the decoder side , the key stream is encoded as an auxiliary stream , and the encoder is designed to minimize the channel loss at the decoder side . the robustness of the proposed error-resilient scheme is evaluated by simulations .
in this paper , we present a comparative study of several feature combinations strategies for content based image retrieval on corel images . we show that the performance of these feature combinations strategies depends on the choice of the combmin , the choice of the combmin , and the choice of the combination strategies . we also show that the choice of evidence combination strategies depends on the choice of the combination strategies , and that the choice of the combination strategies depends on the choice of the combination strategies . we also show that the choice of the combination strategies depends on the choice of the combination strategies . finally , we show that the choice of the combination strategies depends on the choice of the combination strategies , and that the choice of the combination strategies depends on the choice of the combination strategies . finally , we show that the choice of the combination strategies depends on the choice of the combination strategies , and that the choice of the combination strategies depends on the choice of the combination strategies .
acoustic contrast control -lrb- acoustic contrast control -rrb- is a sound zoning method for controlling the flat frequency response of sound zones in anechoic environments . sound field control has been shown to be effective in improving the intelligibility of sound zones in a bandlimited low-frequency scenario . in this paper , we propose a sound zoning method , called acoustic contrast control , to reduce the loudspeaker layout of sound zones in a reverberant environment . the sound zoning method is based on the assumption that the sound zones are generated by the sound field control in the listening space . the sound zoning method is based on the assumption that the loudspeaker layout of the sound zones is constant in the listening space . experimental results show that the proposed sound zoning method can reduce the average squared sound pressure for controlled zones in a acousti-cally damped room .
we study the computational social choice problems in which we assume that the preferences are single-peaked or , and that the preferences are single-peaked . we consider a restricted domain where we assume that the preferences are single-peaked , and that the preferences are single-peaked , and that the preferences are single-peaked . we show that these problems can be reduced to hard computational social choice problems , where the preferences are single-peaked , and we show that these problems can be solved in the restricted domain . we also show that these problems can be solved by exploiting dichotomous profiles . finally , we show that restricted domains can be used to derive computationally hard approand winner rules .
in this paper , we propose a novel approach for simultaneous color and depth inpainting from stereo images . our approach is based on a depth-assisted texture synthesis technique , which can handle occlusions and object removal . in contrast to previous works , our approach does not require 3d warping , and can handle missing color in the input images . in contrast , our approach does not require 3d warping , and can handle occlusion regions using a segmentation-based approach . we demonstrate the effectiveness of our approach on several challenging data sets .
reconstruction of detailed scene geometry from range data captured by commodity handheld cameras with low-frequency distortion and high-frequency errors is a challenging problem . in this paper , we propose a novel approach to reconstructing locally smooth scene fragments from range data captured by commodity handheld cameras . we formulate the problem as an optimization over the space of possible fragments , and propose an efficient algorithm to solve it . experimental results demonstrate the effectiveness of our approach .
we present a variational approach to top-down image segmentation . given a set of point correspondences between a reference object and a reference object , we compute the transformation parameters of the reference object in terms of the visible contour , perspective distortion and scaling of the visible contour . our variational approach is based on the minimization of a generalized cone over the set of unlevel sections of the reference object . we show how to compute the shape term of the original image using the recovered transformation parameters . we also show how to compute the shape term of the original image by minimizing a set of transformation parameters . finally , we show how to use this shape term to derive a novel , efficient , and efficient algorithm to compute the parameters of the proposed variational approach . we demonstrate the effectiveness of our variational approach on a challenging problem of top-down image segmentation .
cross-language review rating prediction -lrb- review rating prediction -rrb- is the task of predicting whether a given review is presented or not . in this paper , we propose a co-regression algorithm for review rating prediction from unlabeled reviews . we evaluate our co-regression algorithm on two datasets : german and german . our results show that our co-regression algorithm outperforms existing regression algorithms for review rating prediction . we also show that our co-regression algorithm outperforms several baselines .
in this paper , we present a probabilistic algorithm for artificial bandwidth expansion . the proposed probabilistic algorithm is based on a mapping from a source signal to a target signal using entropic priors . the mapping is obtained by mapping the source signal onto a subspace where the missing frequency components of the source signal are known . the proposed probabilistic algorithm is able to recover the mapping from the source signal to the target signal . the proposed probabilistic algorithm can be applied to artificial bandwidth expansion , where the source signal is reconstructed from the source signal and the target signal is reconstructed from the source signal . the proposed probabilistic algorithm can be used to estimate the mapping from the source signal to the target signal . the experimental results show that the proposed probabilistic algorithm is able to estimate the mapping from the source signal to the target signal , even when the target signal is corrupted by noise . the results also show that the proposed probabilistic algorithm can be used to estimate the mapping from the source signal to the target signal .
in this paper , we propose a novel segmentation method for foreground regions in mri medical images . our segmentation method is based on the minimization of the average case normalized cut of a parameterized family of shapes subject to a constraint of matrix sparsity . we show that the proposed segmentation method is equivalent to the spectral relaxation of the spectral relaxation approaches used in graph partitioning . in contrast to the spectral relaxation approaches used in graph partitioning , our segmentation method does not require any prior information about the shape or shape of the object . moreover , our combinatorial solution is based on cl optimization , which can be interpreted as a weighted graph . we show that the proposed combinatorial solution can be interpreted as an extension of edge-relaxation to the spectral relaxation . moreover , we show that the proposed combinatorial solution provides a quantitative comparison between the ground truth and the ground truth . finally , we show that the proposed combinatorial solution outperforms the spectral relaxation in terms of the cut cost .
we consider the stochastic binary optimization problem of learning parameterized controllers for real world systems . in this stochastic binary optimization problem , the stochastic binary optimization problem is formulated as a bayesian optimization framework , where the stochastic binary outcome is a stochastic binary outcome , and the stochastic binary optimization problem is modeled as gaussian processes . the stochastic binary optimization problem is a variant of the bayesian optimization framework , where the stochastic binary optimization problem is an offline training phase . the stochastic binary optimization problem can be interpreted as a stochastic binary outcome , where the objective is to minimize the expected loss of the expected loss of the expected loss of the expected loss of the expected loss of the expected loss of the expected loss of the expected loss of the expected loss of the expected loss of the expected loss . the stochastic binary optimization problem can be viewed as a special case of the bayesian optimization problem , where the objective is to minimize the expected loss of the expected loss of the expected loss of the expected loss of the expected loss of the expected loss of the expected loss of the expected loss of the expected loss of the expected loss of the expected loss . we show that the stochastic binary optimization problem can be solved efficiently using the bayesian optimization framework , and present experimental results on synthetic problems that illustrate the effectiveness of the proposed stochastic binary optimization problem .
compilation of bayesian networks into arithmetic circuits is an important problem in the field of bayesian networks . in this paper , we consider the compilation of bayesian networks into arithmetic circuits , where the map is represented by a compiled arithmetic circuit , and the map is represented by a constrained treewidth of the network . we present structure-based inference methods for finding the map of a compiled arithmetic circuit . our structure-based inference methods exploit the local structure of the compiled arithmetic circuit to find the maximum a posteriori hypothesis -rrb- problem . our structure-based inference methods exploit the structure of the compiled arithmetic circuit to find the maximum a posteriori hypothesis -lrb- map -rrb- problem , which can be solved efficiently by branch-and-bound search . we show that our structure-based inference methods can be used to find the map with linear-time operations , including variable elimination and join-tree algorithms . we empirically evaluate our structure-based inference methods on several benchmark datasets and show that our structure-based inference methods are competitive with the state of the art .
in this paper , we propose a method for japanese noun phrase segmentation using non-parametric bayesian language models . in our method , a morphological ana-lyzer is used as a block sampling procedure , and a morphological dictionary is used to select the most appropriate segmentation criteria . the morphological ana-lyzer is used to find the best segmentation criteria for each word in a given lexical resource , and a high-coverage dictionary is used to find the best segmentation criteria for each word . the local optimum is obtained by searching for the best segmentation criteria for each word in the dictionary , and the local optimum is obtained by searching for the best segmentation criteria . the proposed method is applied to japanese noun phrase segmentation with external lexical resources , and it is shown that the proposed method is effective for word segmenta-tion .
the combinatory categorial grammar -lrb- combinatory categorial grammar -rrb- is a grammatical formalism for representing and representing actions in terms of lexicalized intent recognition -rrb- . in this paper , we show how combinatory categorial grammar can be used for plan recognition . we show how combinatory categorial grammar can be used to learn a combinatory categorial grammar from examples , and show how combinatory categorial grammar can be used to learn a representation of the domain of actions that can be used to recognize actions . we also show how to use combinatory categorial grammar in conjunction with combinatory categorial grammar to learn a representation of the domain of actions and their effects on plan goals .
we present an entity-centric coreference system that uses features extracted from the english portion of the conll shared task dataset . our entity-centric coreference system learns a policy for coreference chains using mention pair models , and then uses mention pair scores to filter the search space . our entity-centric coreference system learns a policy for each coreference chains based on a loss function that combines mention pair scores into a single model for coref-erence resolution . we evaluate our entity-centric coreference system on the english portion of the conll shared task dataset , and show that our entity-centric coreference system significantly outperforms a strong baseline .
information presentation -lrb- information presentation -rrb- is an important component of information presentation for item recall . in this paper , we investigate the effect of discourse cues on item recall on information presentation . we find that the effect of discourse cues on item recall is more important than the effect of item recall on information presentation .
in this paper , we propose a ransac algorithm for finding the homography matrix of a computer vision field from stereo images . our ransac algorithm is based on the observation that the homography matrix of a computer vision field can be transformed into a model estimation step . we show that the homography matrix of a computer vision field can be transformed into a homography matrix that can be solved efficiently by solving a sequence of constraint satisfaction problems . we show how to efficiently compute the homography matrix of a computer vision field from a set of stereo images by solving the correspondence problem . we also show how to efficiently compute the homography matrix for a given image using the ransac algorithm . we also show how to efficiently compute the homography matrix for degenerate features by solving a series of constraint satisfaction problems . we also show that our ransac algorithm is able to efficiently find the number of feature points that can be used to solve the correspondence problem . our experiments show that our ransac algorithm is faster than ransac and is faster than ransac in terms of execution time .
the exchange , growth , and transport processes is a fundamental problem in environmental physics , biology , and environmental physics . in this paper , we propose a new image sequence processing techniques for exchange , growth , and transport processes . the proposed image sequence processing techniques is based on the optimization of low-level motion estimators . the proposed image sequence processing techniques consists of three steps : -lrb- 1 -rrb- motion estimation from ccd sensors with spatial nonuni-formity , -lrb- 2 -rrb- motion estimation from real-world images , -lrb- 3 -rrb- estimation of the moving objects and the first-order derivatives of the motion field , -lrb- 3 -rrb- estimation of the moving objects and -lrb- 3 -rrb- estimation of the moving objects based on derivative filters . the proposed tensor method is evaluated on computer-generated sequences and a calibrated image sequence . the results show that the proposed tensor method achieves higher accuracy than the state-of-the-art methods in two-point calibration . the proposed image sequence processing techniques is applied to sediment transport and ocean surface microturbulence in ir image sequences .
in this paper , we present time-frequency synthesis techniques for multiple source signals captured by an antenna array . the proposed time-frequency synthesis techniques are based on the assumption that the spatial signatures of sources are independent of the communication channel , i.e. , the smearing of the signal terms . in contrast to existing blind source separation methods , the proposed time-frequency synthesis techniques does not require whitening , i.e. , the source positions and angular separations are assumed to be independent of the number of sources . the proposed time-frequency synthesis techniques exploit the fact that the time-frequency distributions of the source signals are independent of the number of sources . the proposed time-frequency synthesis techniques is based on the quadratic t-f distributions of the time-frequency distributions of the source signals and the time-frequency distributions of the time-frequency distributions of the source signals . the proposed time-frequency synthesis techniques is based on the assumption that the time-frequency distributions of the signal terms are independent of the number of sources and the noise levels . the proposed time-frequency synthesis techniques is applied to the problem of multiple source signals recorded by a single antenna array . the experimental results show that the proposed time-frequency synthesis techniques can achieve better performance than the conventional methods , especially when the number of sources is large .
probabilistic latent variable models -lrb- probabilistic latent variable models -rrb- have been shown to be effective in distinguishing between cause and effect in real-world data . however , bayesian model selection in the causal direction has not been well explored . in this paper , we propose a novel approach to estimating the hypothetical cause variable from a set of observed variables . the hypothetical cause variable is assumed to be a hypothetical effect variable , and the unobserved noise is assumed to be known . the proposed approach is based on the observation that the hypothetical cause variable is observed in the model class , and the causal direction is determined by the bayesian model selection . the effectiveness of the proposed approach is demonstrated on synthetic data and on real-world data .
in this paper , we present a method for automatic recognition of speech based on audio information . the method is based on hidden markov models trained on an electromagnetic and a device . the hidden markov models are trained on a small set of acoustic units -lrb- tongue , articulation , articulation , and articulation -rrb- of the speaker . the hidden markov models are trained on a small set of acoustic units -lrb- tongue , tongue , tongue -rrb- and the lip parameters are compared to the lip parameters . the results show that the tongue parameters are more accurate than the lip parameters , and that the accuracy of the automatic recognition of speech is better than that of the lip parameters alone . we also show that the use of the audio information improves the performance of the automatic speech recognition .
we propose a new image descriptor for broad image categorization based on statistical descriptors of lsb occurrences . the image descriptor is based on the concept of progressive randomiza-tion , and can be seen as a special case of progressive randomiza-tion . the image descriptor is invariant to perturbations in the training examples , and can be used to detect images with high accuracy . we demonstrate the effectiveness of the proposed image descriptor on a variety of image databases .
in this paper , we propose a tuned eigenspace technique to recognize human motion in an outdoor environment . the tuned eigenspace technique is based on the assumption that human motions can be represented by sequential eigenspaces , which can be represented by a set of tuned eigenspaces . the proposed tuned eigenspace technique is applied to both real-world and synthetic pose recognition , where human poses are represented by a set of tuned eigenspaces . the proposed tuned eigenspace technique is applied to both real-world and synthetic pose recognition , and compared to a background subtraction method , the proposed tuned eigenspace technique is able to recognize articulated motion in real-world data . the experimental results show that the proposed tuned eigenspace technique is effective in recognizing human motion in an outdoor environment . in addition , the proposed tuned eigenspace technique is able to recognize human motion in real time , even when the clothing texture is not known .
in this paper , we propose a continuous optimization framework for interactive tracking of 2d generic objects . the proposed continuous optimization framework is able to deal with tracking ambiguity in the presence of illumination changes , scale , and illumination changes . the proposed continuous optimization framework is based on the spacetime optimization framework , which allows for the simultaneous tracking of multiple objects , and the overall continuous optimization framework is robust to tracking ambiguity . the proposed continuous optimization framework has been implemented in a spacetime optimization framework , and the experimental results demonstrate the effectiveness of the proposed continuous optimization framework .
in this paper , we consider the problem of parameter estimation using a dynamic dictionary subset selection approach . the proposed dynamic dictionary subset selection approach is based on the assumption that the parameterized functions of the dictionary elements are sparse , and the parameter bias is controlled by fixed dictionary approaches . simulation results show that the proposed dynamic dictionary subset selection approach is effective in parameter estimation .
in this paper , we address the problem of speaker-environment tracking in the context of broadcast news . in particular , we address the problem of cluster identification in the context of speaker-environment tracking . we propose a novel approach to cluster identification in the context of a cluster, which is based on the concept of the clusterand ling scheme selection . we show that the proposed approach is superior to the state of the art in the area of speaker-environment tracking , and that it outperforms the state of the art in the area of speaker-environment tracking .
in this paper , we investigate robust linear and nonlin-ear estimation techniques to extract acoustic features in the emotion estimation context . the robust linear and nonlin-ear estimation techniques consists of three main steps : -lrb- 1 -rrb- feature selection , -lrb- 2 -rrb- selection of features from mfcc , -lrb- 3 -rrb- selection of features from mfcc , -lrb- 3 -rrb- selection of features from mfcc , and -lrb- 3 -rrb- selection of features from mfcc , and -lrb- 3 -rrb- selection of features from mfcc . the final emotion estimation context consists of three different acoustic features : valence , activation , and dominance . experimental results show that the proposed robust linear and nonlin-ear estimation techniques are effective in estimating the relative importance of various emotion primitives , including local and global speech duration , energy , and mean absolute error . the proposed robust linear and nonlin-ear estimation techniques can be applied to various types of emotion primitives such as valence , activation , and dominance .
the problem of cepstral feature extraction for bird call classification is addressed . the features are extracted from a mel-scaled filter bank , and the optimal acoustic model parameters are estimated using the expectation-maximization algorithm . a gradient ascent method is used to find the optimal combination of the filter bank and the filter bank . the performance of the proposed gradient ascent method is evaluated on a set of antbird calls . the results show that the proposed gradient ascent method is able to reduce the classification error rate by 30 % .
we propose a reinforcement learning algorithm called utile suffix memory , which uses short-term memory to reduce state aliasing . utile suffix memory is based on a tree-structured representation of the hidden state and uses short-term memory to reduce state aliasing . statistical tests show that utile suffix memory can reduce the number of hidden states by up to 50 % compared to conventional methods .
this paper presents a data driven approach to recognizing speech examples in both speaker and environment . the proposed data driven approach is based on a dominant acoustic modeling methodology . in contrast to pure example based recognition , the proposed data driven approach does not require any prior knowledge of speaker information or time dependencies . instead , it does not require any prior knowledge of the speaker and environment , instead , it does not require any prior knowledge of the speaker or environment . the proposed data driven approach is based on the dtw algorithm , which is used to find the most likely hmm for the given utterance . the data driven approach is used to find the most likely hmm for the given utterance . the search space is reduced by searching for the most likely hmm with a dominant acoustic modeling methodology . experiments on large vocabulary speech recognition show that the proposed data driven approach is able to recognize speech examples in both cases .
in this paper , we consider a multiple-input multiple-output wireless communication scenario where a base station has a spatially-correlated complex gaussian distribution with non-zero mean and covariance feedback at low snrs . we study the ergodic achievable rate of the proposed multiple-input multiple-output wireless communication scenario under the ergodic rate perspective . in particular , we consider the case where the number of users is large and the number of users is larger than the number of users . we consider the case where the number of users is larger than the number of users , and propose a beamforming strategy to maximize the ergodic achievable rate under the assumption that the number of users is larger than the number of users . we show that the performance of the proposed beamforming strategy depends on the number of users and the number of users , and the number of users , the number of users and the number of users , the number of users , the number of users , the number of users , the number of users , the number of users , the number of users , the number of users , the number of users , the number of users , and the number of users , the number of users , the number of users , and the number of users , the number of users , the number of users , the number of users , the number of users , the number of users , the number of users , the number of users and the number of users , the number of users , the number of users , the number of users , the number of users , the number of users , the number of users , the number of users , and the number of users , the number of users , the number of users , the number of users , the number of users , the number of users , and the number of the number of users , the number of users , the number of users , the number of users , the number of users , the number of the number of the number of users , the number of users , the number of the number of users , the number of users , the number of users , and the number of users , the number of the number of users , the number of users , the number of the number of users , the number of the number
in this paper , we propose a novel approach to solve motion deblurring problems using kernel estimation and non-blind deconvolution . the proposed approach is based on iterative support detection kernel refinement with a spatial prior . the iterative support detection kernel refinement consists of two steps : -lrb- 1 -rrb- a variable substitution scheme to remove noise and -lrb- 2 -rrb- an iterative support detection kernel refinement based on the spatial prior . -lrb- 3 -rrb- a hard threshold to enforce sparsity in the image edges and the gradient selection process for motion deblurring . -lrb- 3 -rrb- a variable substitution scheme is proposed to estimate the tv-1 deconvolution model . the effectiveness of the proposed approach is demonstrated on several challenging motion deblurring problems .
in this paper , we consider the analysis of outdoor scenes from a set of time-lapse video data . we propose a novel approach to capture temporal color changes in an image sequence by exploiting the radiometric and geometric information in the form of direct sunlight . the proposed method is based on the spectral composition of daylight and the ambient skylight . we demonstrate the effectiveness of the proposed method in two visual tasks : scene reconstruction , camera geo-location background subtraction , shadow detection , and background subtraction .
the automatic alignment of parallel texts at the clause level is an important task in software systems . the automatic alignment of parallel texts at the clause level is an important component of the software systems . in this paper , we propose a probabilistic model of parallel texts in a dynamic progranuning framework , which combines shallow linguistic processing and statistical techniques . the probabilistic model consists of two parts : word occurrence , character lengths , co-occurrence probabilities , and word occurrence . in the first part , the clause alignments are automatically extracted from the parallel bilingual corpus . in the second part , a simulated annealing system is used to estimate the probabilities of each word in the parallel texts . in the second part , a modified annealing system is used to estimate the probabilities of each word in the parallel texts . in the second part , a word is segmented into regular grammars , which are then used to estimate the probabilities of each word in the sentence . the experimental results show that the 1he method achieves the best results on the small eng ~ and greek corpus .
in this paper , we introduce a semi-markov decision process framework for concurrent decision making . the semi-markov decision process framework is based on the notion of concurrent temporally extended actions , which are characterized by a set of parallel termination schemes . we show that the semi-markov decision process framework can be used to model the problem of concurrent decision making .
in this paper , we propose a new approach to detect within-cluster homogeneity in unknown speech utterances based on a genetic algorithm . in the proposed method , the within-cluster utterances are clustered into clusters according to their similarity to each cluster . in the proposed method , each cluster is represented by a set of clusters , and each cluster is represented by a weighted sum of the likelihood probability of each cluster . in the proposed method , each cluster is represented by a weighted sum of the likelihood probability of the within-cluster utterances . in the proposed method , the number of clusters is determined by the proposed method , and the computational efficiency of the proposed method is compared with that of the conventional method . the experimental results show that the proposed method is effective in identifying within-cluster utterances with high accuracy .
in this paper , we present a parallel depth recovery scheme for four-camera multibaseline stereo with conver-gent configuration . our parallel depth recovery scheme takes advantage of the local discriminability of the stereo depth data to improve the three-dimensional tracking performance . our parallel depth recovery scheme is based on the observation that dense stereo depth data can be captured in a single camera view areas . we show that our parallel depth recovery scheme can be used to improve the image capture performance of a four-camera multibaseline stereo with a conver-gent configuration . our experimental results show that our parallel depth recovery scheme improves the quality of the image capture by up to 30 % relative .
in this paper , we propose practical schemes for distributed video coding with side information at the decoder . practical schemes exploit the side information at the decoder to improve the coding performance . in particular , we consider non-standard correlation models , where the gaussian correlation is modeled by a rate-distortion function . we derive lower and upper bounds on the rate-distortion functions of these non-standard correlation models . these lower and upper bounds are derived for the rate-distortion functions of these non-standard correlation models . in particular , we consider the case of impulse noise with impulse noise , and show that the gaussian correlation can be interpreted as a special case of the ge correlation model , and that the non-stationarities of the gaussian correlation can be modeled as a sum of a rate-distortion function . simulation results illustrate the effectiveness of the proposed practical schemes .
we study additive combinatorial auctions , where the goal is to minimize the sum of the sum of the player 's revenue and the player 's revenue . we show that the problem of finding a n-player strongly monotone scheduling mechanisms is np-complete , and that the problem of finding an n-player strongly monotone scheduling mechanisms is np-complete . we show that the problem of finding an n-player strongly monotone scheduling mechanisms is np-complete , and that the problem of finding an n-player strongly monotone scheduling mechanisms is np-complete . we also show that the problem of finding an n-player strongly monotone scheduling mechanisms is np-complete , and that the problem of player-grouping minimizer and task-independent is np-complete .
sparse signal approximation has been shown to be very effective in low bit-rate coding schemes , especially in low bit rate compression of audio signals . in this paper , we consider the problem of parameter estimation in a probabilistic fashion , where the dictionary space is assumed to be sparse , and the sparsity is assumed to be sparse . we propose a greedy decomposition process , where the dictionary space is assumed to be sparse , and the goal is to minimize the sum of squared errors between the dictionary and the dictionary . we show that the greedy decomposition process can be interpreted as a special case of the greedy decomposition process . we also show that the proposed greedy decomposition process can be used to reduce the number of samples needed to achieve a controlled computational complexity .
recognizing emotions from speech signals is a challenging task . in this paper , we propose a novel approach to speech emotion recognition based on speech emotion recognition . we first extract amcc features from the speech signal using the c-channel gammatone filterbank , and then extract amcc features from the speech signal using the discrete cosine transform root compressed am power spectrum . the am power spectrum is divided into amplitude and frequency components , and a smoothed nonlinear energy operator is used to extract the am-fm signal from the speech signal . finally , we use the smoothed nonlinear energy operator to extract the amplitude and frequency components of the am-fm signal . recognition experiments on the fau aibo spontaneous emotion corpus show that the proposed approach is effective in recognizing emotions from speech signals .
this paper describes the development of a unified dutch and german speech recognition system in the speechdat domain . the unified dutch and german speech recognition system consists of three components : the acoustic component of the unified dutch and german speech recognition system , the language dependent phoneme models , and the language dependent phoneme models . the first unified dutch and german speech recognition system is based on the mce-based training algorithm . the second unified dutch and german speech recognition system is evaluated on the dutch and german subword recognition tasks . the unified dutch and german speech recognition system is compared with the mce-trained multilingual system in the speechdat domain . the unified dutch and german speech recognition system achieves a overall string error rate reduction of 24.3 % , which is significantly better than the mce-trained multilingual system .
singular value decomposition -lrb- singular value decomposition -rrb- is a popular spectral embedding for learning tasks . singular value decomposition has been shown to be a powerful tool for spectral embedding , but it is not clear whether singular value decomposition is a predefined function of the problem structure . in this paper , we propose a low-complexity compressive spectral embedding algorithm that can be used for downstream inference tasks such as clustering . our low-complexity compressive spectral embedding algorithm is based on random projections and finite order polynomial expansions . the key idea of our low-complexity compressive spectral embedding algorithm is to project arbitrary vectors into a m × n matrix and then use singular vectors to compute general svd-based embeddings . our low-complexity compressive spectral embedding algorithm is based on the observation that the problem size is independent of the problem size and the problem size is independent of the problem structure . our low-complexity compressive spectral embedding algorithm is based on the observation that the singular vectors of the dominant singular vectors of the m × n matrix are independent of the problem size . we show that the proposed low-complexity compressive spectral embedding algorithm is able to perform di-mensionality reduction on several network datasets , and that low-complexity compressive spectral embedding algorithm is much faster than state-of-the-art algorithms in terms of both time complexity and embedding dimension . we also show that the proposed low-complexity compressive spectral embedding algorithm can also be applied to arbitrary vectors by exploiting the problem structure .
in this paper , we propose a data-driven technique for designing acoustic models for commercial applications . the data-driven technique is based on data weighting , which aims to reduce the number of recognition errors and reduce the amount of poorly modeled data . the proposed data-driven technique is applied to acoustic models that are commonly used in speech recognition systems . the proposed data-driven technique consists of two steps : -lrb- 1 -rrb- data weighting for acoustic models and -lrb- 2 -rrb- data weighting for acoustic models . in the first step , the foreground scores are estimated based on frame-averaged foreground log-likelihoods -lrb- foreground scores -rrb- . in the second step , the foreground scores are updated according to their confidence scores . the experimental results on a live evaluation set show that scouter optimization can reduce the number of recognition errors by about 10 % compared to the baseline system .
in this paper , we propose a statistical parametric approach to singing voice synthesis based on hidden markov models . the proposed statistical parametric approach is capable of generating synthesized singing voices from singing voice data . in the proposed statistical parametric approach , singing voice synthesis is modeled as a '' singer adaptive training '' data consisting of context-dependent hmms . in the proposed statistical parametric approach , singing voice synthesis is modeled as a '' singer adaptive training '' data , where vibrato and vibrato are modeled as a sequence of context-dependent hmms . in the proposed statistical parametric approach , singing voice synthesis is modeled as a sequence of hidden markov models , and the contextual factors of each hidden markov models are modeled as a sequence of hmms . experimental results show that the proposed statistical parametric approach is effective in improving the naturalness of synthesized singing voices .
we present a novel approach to building de-terministic prolog parsers from corpora of parsed sentences . our approach is based on inductive logic programming and uses machine learning methods to learn prolog rules from treebanks . we evaluate our approach on the atis corpus and compare it to several state-of-the-art statistical methods . our results show that our approach is competitive with the state of the art .
we consider the problem of estimating viewpoint from a single camera viewpoint . given a rough viewpoint , our goal is to recover the 3d appearance tensor of a person from its rough viewpoint . given a set of synthetic views of people , our goal is to recover the 3d appearance tensor of a person from its rough viewpoint . we formulate unseen view synthesis as a probabilistic tensor completion problem , where the 3d appearance tensor of a person is inferred from the inferred views , and the 3d appearance tensor is learned from the training data . we show that our approach is robust to unseen views , and can be used to estimate viewpoint , viewpoints , and image positions . we evaluate our approach on a variety of challenging datasets , and show that it outperforms existing methods .
in this paper , we propose a kernel-based approach to the clustering of diffusion tensors based on atlas-based registration of diffusion-free images . the proposed kernel-based approach is based on nonlinear kernel support vector machines , which is a soft fiber representation of the diffusion tensors . the fiber tracts are represented by a tensor kernel with a multi-instance kernel , and the tensor space is represented by a mercer kernel . the spatial and diffusion information of the diffusion tensors are captured by the tensor kernel , and the fiber tracts are represented by the tensor kernel using the multi-instance kernel . the proposed kernel-based approach is applied to the clustering of diffusion tensors . the experimental results show that the proposed kernel-based approach outperforms the state-of-the-art methods based on kernel-pca for tensor segmentation , k-means clustering for the data set of normal subjects . the proposed kernel-based approach is also applied to the clustering of diffusion tensors .
in this paper , we propose a novel approach to improve the performance of query spelling correction models by incorporating distributional similarity from query logs to improve the performance of a search engine . our approach is based on the idea that distributional similarity can be used to improve the performance of query spelling correction models . the proposed approach is evaluated on a web query spelling correction task . the experimental results show that distributional similarity can significantly improve the performance of query spelling correction models . we also show that dis-tributional similarity can be used to improve the performance of the distributional similarity based models .
conditional random fields -lrb- crfs -rrb- are a popular sparse learning framework for nature language processing . in this paper , we propose a novel two-stage training algorithm , called stochastic gradient descent method , to speed up the learning rate parameter settings . the proposed stochastic gradient descent method employs a heuris-tic line search strategy to speed up the stochastic gradient descent method . unlike the traditional l1 regularization method , the proposed stochastic gradient descent method does not require l1 regularization and can be easily applied to any learning rate parameter settings . moreover , the proposed two-stage training algorithm can speed up the training time by a factor of three . experiments on chinese word segmentation and name entity recognition tasks show that the proposed two-stage training algorithm can achieve comparable or even better generalizability than the state-of-the-art methods . moreover , the proposed two-stage training algorithm can achieve comparable or even better performance than the state-of-the-art methods .
channel tracking in mimo-ofdm systems is an important problem in communication systems . in this paper , we propose a zero-forcing soft detector for symbols detection in mimo-ofdm systems over gauss-markov channels . the zero-forcing soft detector is designed to minimize the error propagation effect on the detected symbols . in order to avoid mis-detections , the zero-forcing soft detector is adopted to reduce the error propagation effect . in the proposed zero-forcing soft detector , the viterbi ¿ lter is applied to the detected symbols and the viterbi ¿ lter is applied to the detected symbols . in the proposed zero-forcing soft detector , the viterbi ¿ lter is designed to minimize the error probability of the soft detector . in the proposed zero-forcing soft detector , the bit error probability of the viterbi ¿ lter is minimized . the proposed zero-forcing soft detector is compared with the conventional zero-forcing soft detector in terms of reduced spectral ef ¿ ciency . simulation results show that the proposed zero-forcing soft detector is robust to mis-detections .
in this paper , we address the problem of shape matching in gray-level images . we propose a class of distinguished regions , which are defined as convex local arrangements of contours . the class of distinguished regions is defined as a set of cost functions , which are defined on the basis of local convexity . the local interest points are defined by a set of distinguished regions , which are defined by their angular positions and orientations . the local interest points are obtained by minimizing an entropy term that measures the local support of the detected regions . the proposed class of distinguished regions is invariant to scale changes , rotations , and spurious edge detections , and is robust to clutter and occlusions . we apply the proposed class of distinguished regions to recognize objects in gray-level images , and show that the proposed class of distinguished regions is robust to clutter and occlusions .
many large-scale 1-regularized loss minimization problems arise in many high-dimensional applications , such as compressed sensing , high-dimensional supervised learning , classification , and regression problems . existing coordinate descent algorithms for 1-regularized problems suffer from the high computational cost of solving such large-scale 1-regularization problems . in this paper , we propose a unified convergence analysis for block-greedy algorithms , called block-greedy coordinate descent , for solving large-scale 1-regularization problems . in particular , we provide a theoretical convergence analysis for block-greedy coordinate descent with maximum inner product . our analysis shows that the proposed unified convergence analysis can be applied to any class of block-greedy algorithms , including thread-greedy , shot, and greedy cd . moreover , our analysis shows that the proposed unified convergence analysis can be applied to any class of large-scale 1-regularized loss minimization problems , and can be applied to many real-world applications .
overlapping laughter is an important phenomenon in spoken dialogue systems . in this paper , we investigate the acoustics of overlapping laughter in conversational speech . in particular , we investigate the influence of overlapping laughter on the group size and the extent to which laughter occurs in spoken dialogue systems . in particular , we investigate the influence of overlapping laughter on the acoustics of overlapping , i.e. , the group size and the maximum intensity of the laughter event . the results show that overlapping laughter can be considered as a source of joint vocal action , and that non-overlapping ones can be considered as a source of joint vocal action .
in this paper , we propose a half-duplex distributed beamforming technique for relay networks over frequency selective fading channels . the proposed half-duplex distributed beamforming technique is based on the idea of maximizing the relay transmitted power subject to a destination quality-of-service constraint on the transmit relay power and the destination qos constraint on the transmit relay power . the relay and relay-to-destination channels are modeled as a distributed beamforming problem with finite impulse response filters , and the destination qos constraint on the received signal is minimized . the proposed half-duplex distributed beamforming technique has a closed-form solution and can be applied to any network relays . simulation results show that the proposed half-duplex distributed beamforming technique outperforms existing amplify-and-forward distributed beamforming techniques in terms of both relay and relay-to-destination channels .
in this paper , we investigate the use of mlps for frame level detection of laughter in meetings . the mlps are trained on short-term features -lrb- e.g. mfccs , mfccs , and mfccs -rrb- , and combine high-level and long-term features -lrb- e.g. median filtering -rrb- with long-term features -lrb- e.g. , median filtering and long-term features -rrb- . the results show that laughter detection results in a relative improvement of 12 % in eer on the icsi meeting recorder corpus compared to the equal-prior test set , while laughter detection results in a relative improvement of 13 % in recall rate and 10.5 % in recall rate compared to the baseline system . in addition , we investigate the effect of laughter segments on speaker recognition performance . finally , we investigate the effect of different types of laughter segments on the performance of a hybrid mlp/hmm system .
we present a novel neural architecture for natural language inference . our neural architecture is based on the idea of intra-sentence attention , which is motivated by the observation that word-order information can be incorporated into the neural architecture for natural language inference . we evaluate our neural architecture on the stanford natural language inference dataset , and show that our neural architecture achieves state-of-the-art performance .
in this paper , we consider the problem of recovering the scene outside of an indoor scene from a single video sequence . we consider the case where the scene consists of a single camera moving on a straight line , and a single camera moving on a straight line . we assume that the scene inside the scene is an indoor scene , and that the scene outside the scene is visible in the scene . we show that when the scene outside the scene is not visible , we can recover the scene outside the scene using only a single reference image . we show that if the scene outside the scene is visible , then we can recover the scene outside the scene outside the scene using only a single reference image . we show that if the scene outside the scene is visible , then we can recover the scene outside the scene outside the scene . we also show that when the scene outside the scene is not visible , we can recover the scene outside the scene outside the scene using only a single reference image . we also show that if the scene outside the scene is visible , we can recover the scene outside the scene outside the scene using only a single reference image . finally , we show that when the scene outside is not visible , we can recover the scene outside the scene outside the scene using only a single reference image . finally , we show how our approach can be used to recover the shadows from a single video sequence using a specially designed carefully designed carefully designed carefully designed carefully selected '' images .
in this paper , we present a novel approach for the detection of vehicles in airborne video sequences . the proposed approach is based on an em-based motion segmentation of a moving airborne platform . first , a background appearance model is used to detect vehicles in the airborne video sequences . then , a stabilization of the frames is used to detect gross affine background motion . finally , an optical flow algorithm is used to estimate the background appearance model . finally , a background appearance model is used to detect vehicles in the airborne video sequences . finally , the background appearance model is used to detect vehicles in the airborne video sequences . experimental results show that the proposed approach is capable of detecting vehicles in the airborne video sequences .
model-order selection criteria have been widely used in many applications , such as linear regression , to reduce the number of samples required for model-selection searches . in this paper , we propose a partial-model selection searching method for model-order selection . the partial-model selection searching method is based on a nested full-parameters-set searching procedure , where the model-order selection criteria are selected according to the objective function of the selected model-order selection criteria . the partial-model selection searching method is based on the assumption that the model-order selection criteria are independent of the number of samples . the partial-model selection searching method is based on the assumption that the model-order selection criteria are independent of the number of samples . the proposed partial-model selection searching method is evaluated by comparing partial-model selection searching method with other methods in terms of accuracies and low signal-to-noise ratios .
many real-world decision-theoretic planning problems can be formulated as continuous state and action spaces . in this paper , we propose a symbolic dynamic programming solution to the policy for csa-mdps . our symbolic dynamic programming solution is based on a continuous action maximization step , where the goal is to find a policy that maximizes a closed-form value function subject to unknown state parameters . we show that our symbolic dynamic programming solution can be used to approximate the policy for csa-mdps with piecewise linear dynamics , discrete noise , mul-tivariate continuous state and actions , and restricted piecewise quadratic -rrb- reward . we show that our symbolic dynamic programming solution can be used to approximate the policy for csa-mdps with unknown state parameters . we demonstrate the effectiveness of our symbolic dynamic programming solution through a didactic nonlinear planning example .
knowledge base completion -lrb- knowledge base completion -rrb- aims to infer knowledge bases such as freebase . in this paper , we consider the problem of knowledge base completion , i.e. , given a set of medium-confidence tuples , the goal is to infer the true held-out tuples of a knowledge base . we propose a bilinear model for tu-ples , based on an additive architecture . we show that our bilinear model outperforms several state-of-the-art neural network models , including neural network models . we also show that our bilinear model is competitive with the state of the art in knowledge base completion .
the acoustics of rooms and halls are known to be highly correlated with the acoustics of rooms and halls . in this paper , we present a method for aligning the acoustic intensity images captured by a real time audio camera . the central projection is based on a spherical microphone array beamformer , and the acoustical features of the audio and video images are computed using the visual and the audio camera images . the central projection is computed using a spherical microphone array beamformer , and the registration between the audio and video images is performed using the visual and the audio camera images . the experimental results show the effectiveness of the proposed method .
in this paper , we present a novel approach to spatial sound rendering based on the inverse of a real source . the method is based on the use of synthetic head-related transfer functions with spectral characteristics . the synthetic head-related transfer functions can be used in applications such as augmented and virtual reality , manufacturing and entertainment , distance learning , teleconferencing displays , etc. . the proposed method can be used in applications such as augmented and virtual reality , air traffic control , and distance learning . the proposed method can be used in applications such as spatial sound rendering , where virtual sound sources can be used in applications such as teleconferencing , pilot warning , air traffic control , etc. . it can also be used in applications such as augmented and virtual reality to synthesize sound fields .
in this paper , we propose an iterative reinforcement approach to extract summary and keywords from a single document . our iterative reinforcement approach is based on two steps : -lrb- 1 -rrb- a knowledge-based approach to extracting keywords from a single document , and -lrb- 2 -rrb- a knowledge-based approach to computing word semantics for keyword extraction and document summarization . the experimental results show that our iterative reinforcement approach outperforms the knowledge-based approach in terms of both summary and keywords .
brain-computer interfaces -lrb- brain-computer interfaces -rrb- are a promising approach to enhance the cognitive demands of brain-computer interfaces . in this paper , we propose to use eeg connectivity patterns to enhance the performance of brain-computer interfaces . the eeg connectivity patterns of the brain-computer interfaces are measured in the feature space of the brain-computer interfaces . the eeg connectivity patterns of the brain-computer interfaces are measured in terms of two connectivity features : beamforming and transfer entropy . the experimental results show that the proposed brain-computer interfaces can improve the performance of the brain-computer interfaces , especially in high frequency bands . furthermore , the proposed brain-computer interfaces is able to enhance the connectivity features of the brain-computer interfaces . furthermore , the experimental results show that the proposed brain-computer interfaces is more effective than the connectivity based bcis , especially in high frequency bands . furthermore , the proposed brain-computer interfaces is capable of capturing the eeg connectivity patterns in motor imagery .
bidirectional search is a powerful approach to symbolic bidirectional uniform-cost search in cost-optimal planning . in this paper , we show how abstraction heuristics can be used to guide symbolic bidirectional search in abstract state spaces and/or , and how these abstraction heuristics can be used to guide the search . we introduce ipc , a new algorithm for symbolic bidirectional search that uses heuristic functions to guide the search for an optimal policy in an abstract state spaces and/or . we show that ipc can be used to guide the search for an optimal policy , and that it can be used to guide the search for an optimal policy in an abstract state spaces and/or . we evaluate the performance of the algorithm on a variety of domains , and show that it can be used to guide the search for an optimal policy in a variety of domains . in particular , we show that the algorithm can be used to guide the search for a given problem instance , and that it can be used to guide the search for a given problem instance .
this paper presents an unsupervised algorithm for speech recognition based on acoustic pattern discovery , clustering , and temporal sequence learning . the unsupervised algorithm uses a combination of acoustic pattern discovery , clustering , and temporal sequence learning to determine the acoustic similarity between words in a speech signal . the unsupervised algorithm is based on the assumption that the raw input of the unsupervised algorithm is a set of word-like fragments , each of which is a set of acoustic phone models and a upfront defined lexicon . modelling constraints on the acoustic similarity between words in the speech signal and the acoustic phone models is performed . the unsupervised algorithm is evaluated on a large vocabulary continuous speech recognition -lrb- lvcsr -rrb- task , and is compared to mainstream asr approaches . the results show that the unsupervised algorithm is able to discover acoustic similarity between words in the speech signal , and that the unsupervised algorithm is able to discover acoustic similarity between words .
we present a method for predicting target order phrase-based machine translation based on a reordering grammar . our method is based on the idea of preordering , which is a latent variable for phrase reordering . our method is based on a transduction function and a hierarchical structure that is learned from word-aligned parallel corpora . unlike previous work , our method does not require any prior linguistic annotation . instead , we use permutation trees to learn reordering rules from word-aligned parallel corpora . we evaluate our method on english-japanese using preordering baselines , and show that our method improves the accuracy of bracketing labeling . we also show that our method improves the translation quality of phrase reordering , and that it improves the accuracy of previous preordering baselines for english-japanese .
in this paper , we propose a method for speech recognition of broadcast news commentary linguistic features of news a news commentary speech . the method is based on the combination of linguistic and acoustic features . the basic idea is to use word sequences for language model adaptation . the basic idea of this method is to use a decoder to map a given word sequence into a set of rules for language model adaptation . in our experiments , we used news commentary speech to construct a set of news programs . the experimental results showed that the proposed method achieved a word error rate of 4.2 % for read speech compared to the news commentary speech . furthermore , the proposed method achieved a word error rate of 34.2 % for read speech .
automatic extraction of speech lip features is an important problem in visual speech processing . in this paper , we propose a new method for extracting geometric lip features from natural lips . the proposed method is based on the 2-d discrete cosine transform , which is based on principal component analysis . the 2-d discrete cosine transform is then used to extract features from the image . the experimental results show that the proposed method can extract the lip aperture with high accuracy . moreover , the proposed method can extract the lip aperture with higher accuracy than the traditional pca .
descriptor learning plays an important role in computer vision . in this paper , we propose a novel supervised descriptor learning algorithm to learn discriminative and compact feature representation for multi-output regression . the proposed supervised descriptor learning algorithm is based on supervised manifold regularization to learn generalized low-rank approximations of matrices in a low-dimensional space . the proposed supervised descriptor learning algorithm is able to learn a discriminative and compact feature representation for multi-output regression without supervision of multivariate targets . the proposed supervised descriptor learning algorithm is evaluated on a benchmark pointing '04 dataset for head pose estimation . the experimental results show that the proposed supervised descriptor learning algorithm achieves better estimation accuracy than the state-of-the-art methods in multi-output regression tasks . in addition , the proposed supervised descriptor learning algorithm can also be applied to any representative multi-output regression task . the proposed supervised descriptor learning algorithm can also be applied to any other descriptor learning framework in computer vision .
birdsong is one of the most challenging problems in automatic recognition of simultaneous bird sounds . in this paper , we propose a segregation algorithm based on a markov renewal process model . in the proposed segregation algorithm , each birdsong is represented by a mixture of a set of parameters , each of which represents rapid pitch modulations . in the proposed segregation algorithm , a distribution derivative method is used to estimate the parameters of a <s> <s> <s> <s> in the proposed segregation algorithm . in the proposed segregation algorithm , the distribution derivative method is used to estimate the parameters of the proposed segregation algorithm . the experimental results show that the proposed segregation algorithm is effective in estimating the parameters of the proposed segregation algorithm .
in this paper , a group delay function , called spectral fm , is proposed for transient signals -lrb- castanets and stop consonants -rrb- and stop consonants . the group delay is defined as the fourier spectrum and the modulation structure of the signal . the group delay is characterized by the spectral zero-crossings of the spectral envelope and the spectral envelope of the signal . the group delay is characterized by the phase of the envelope and the phase of the signal , and the group delay is characterized by the phase of the fourier spectrum and the modulation structure of the signal . the group delay is characterized by the phase of the signal , and the phase of the signal is estimated by the spectral-domain amplitude-moduland frequency-modulated functions of the signal . it is shown that the proposed coherent demodulator is able to accurately estimate the spectral envelope and the phase of the signal in additive noise .
inference in mixed probabilistic and deterministic graphical models is an important problem in many real-world applications . in this paper , we present samplesearch , an importance sampling technique that combines the power of gibbs sampling with the efficiency of approximate weighting schemes . samplesearch is an importance sampling technique that combines the strengths of samplesearch and mc-sat . samplesearch can be viewed as an extension of sat/csp solvers to hard deterministic spaces . samplesearch can be viewed as an extension of belief propagation and mc-sat . samplesearch can be viewed as an extension of gibbs sampling to unweighted samples , which can be used for inference in hard deterministic spaces . we demonstrate the accuracy of samplesearch by applying samplesearch to inference in mixed probabilistic and deterministic graphical models .
we introduce recipes , a novel method for learning high dimensional representations of the shape of a scene from an observed image . recipes are a low-dimensional representation of the scene that is invariant to complex scene configurations and can be used as a basis for low-level vision . the shape of an object is represented by a set of regression coefficients computed from image data , which are then used to estimate the shape of an object in the image . we demonstrate the utility of the method on a variety of real-world scenes , and show that it is possible to learn high dimensional representations of the object in the presence of a bandpassed shape . we also show how to use stereo shape estimates to improve material segmentation .
in this paper , we describe a method for creating a virtual acoustic feedback instrument or sound source from pitched real-time input . the method is based on a musical tool and computational techniques . a nonlinear feedback oscillator is used to generate a virtual instrument from the acoustic feedback of the instrument or sound source . the output of the nonlinear feedback oscillator is a set of virtual acoustics and a set of virtual acoustics are used to represent the acoustic feedback effect of the instrument . the output of the nonlinear feedback oscillator is a set of virtual acoustic feedback that can be used to generate the desired acoustic feedback . the output of the nonlinear feedback oscillator is then used to generate the feedback effect of the acoustic feedback . the results show that the method can be used to create a virtual instrument with a small amount of acoustic feedback .
parsing plays an important role in many natural language processing applications , such as relation extraction and paraphrase acquisition . in this paper , we present a novel approach for domain adaptation of dependency parsing , which improves the accuracy of the dependency parser on the conll 2007 shared task . we also propose a method to adapt the dependency parser to the target domain . our experimental results show that the proposed method improves the accuracy of the dependency parser on the conll 2007 shared task .
deep convolutional neural networks -lrb- cnns -rrb- have been shown to achieve state-of-the-art performance on a variety of benchmark image datasets . however , the storage and computational requirements of these deep convolutional neural networks do not scale well to large datasets . in this paper , we propose a novel cnn compression approach , which is capable of efficiently transforming images into discrete cosine transform bases in the frequency domain . the proposed cnn compression approach is inspired by the observation that low-energy frequency coefficients can be used for high compression . the proposed cnn compression approach is based on the observation that images in the frequency domain have similar cluster centers to those in the training set . the convolution operations in the cnns are used to increase the accuracy of the cnn compression approach . the proposed cnn compression approach is evaluated on a variety of benchmark image datasets , and the experimental results show that the proposed cnn compression approach outperforms the state-of-the-art methods in terms of both compression and speed-up ratios .
in this paper , we consider the problem of transmit-reference ultra-wideband systems , where the transmitter is equipped with a signal processing at the transmitter and receiver algorithms . we assume that the transmitter is equipped with a finite number of antennas and the receiver is equipped with restrictive assumptions such as frame length . we propose a method to reduce the inter-frame interference in order to reduce the complexity of the signal processing . the proposed method is based on a data model , and it is shown that the proposed method is capable of reducing the inter-frame interference while maintaining the same performance as the receiver algorithms .
in this paper , we present a speech act framework for emotional expressions in student discussions . our speech act framework is based on the analysis of emotion patterns in student discussions and on the classification results of high certainty expressions in online dialogue analysis . the speech act framework is based on the assumption that the difficulty expressions in student discussions are more likely to have high certainty expressions than those in student discussions . in order to evaluate the effectiveness of our assessment tool , we conducted a series of classification experiments to evaluate the effectiveness of the proposed speech act framework . the results show that the proposed speech act framework can be used to identify emotional expressions in student discussions .
in this paper , we propose a novel translation model for constituency and dependency trees . our translation model uses phrasal nodes of constituency trees to represent head-dependents relations of dependency trees . our translation model is able to learn translation rules for both constituency and dependency trees . experiments on chinese-english nist test sets show that our translation model outperforms a state-of-the-art hierarchical phrase-based model . furthermore , our translation model achieves a significant improvement in bleu over the hierarchical phrase-based model .
in this paper , we present a environmental noise recognition system based on hidden markov models -lrb- hmm 's -rrb- . the environmental noise recognition system is based on time-frequency analysis of the acoustic signatures of the acoustic signatures , which are used for the automatic classification of environmental noise sources . the proposed environmental noise recognition system is evaluated on two types of noise events : moped , aircraft and tr, and a noise monitoring system . the results show that the hmm-based approach is able to improve the average spectrum of noise event compared to the classifiers based on the average spectrum of noise event . in a classification test , the proposed hmm-based approach is also shown to improve the performance of human listeners .
artic-ulatory features -lrb- afs -rrb- are an important part of an hmm-based asr system . in this paper , we propose a novel method to incorporate artic-ulatory features into the kullback-leibler divergence based hmm system . the afs are derived from posterior probabilities of phoneme probabilities , af probabilities , and phoneme probabilities . the afs are extracted from the posterior probabilities of phonemes , and the observation features are integrated into the kullback-leibler divergence based hmm system . the phoneme recognition accuracy of the proposed kullback-leibler divergence based hmm system is evaluated in the timit phoneme recognition task . the phoneme recognition accuracy of the proposed kullback-leibler divergence based hmm system is comparable to that of multilayer perceptrons .
in this paper , we consider the problem of learning lossy compact codes for high-dimensional vectors using a vector encoding scheme -lrb- tree quan-tization -rrb- . we propose a method to learn a coding tree structure that minimizes the image classification error . the coding tree structure is learned by integer programming-based optimization , and the vector encoding scheme -lrb- tree quan-tization -rrb- is applied to lossy compact codes . the proposed method is tested on three benchmark datasets : 1 -rrb- product quantization , 2 -rrb- fisher vectors , 3 -rrb- tree quantization , and 3 -rrb- neural codes , 4 -rrb- fast encoding , 4 -rrb- compression error , and 3 -rrb- compression error . experimental results show that the proposed method improves the retrieval performance of product quantization , and 3 -rrb- the accuracy of the learned codes is comparable to that of product quantization .
in this paper , we propose a novel approach to factor-and session variability modelling for speaker verification systems . the proposed approach is based on progressive svm-based classification and factor analysis -lrb- isv -rrb- . in the proposed approach , a progressive svm-based classification is performed on the basis of the gmm mean supervectors , and a progressive svm-based classification is performed on the basis of the confidence measures for continuous model adaptation . in the proposed approach , the gmm and svm configurations are estimated by adaptative score normalisation techniques . during the adaptation process , the gmm mean supervectors are estimated by the proposed approach . the proposed approach is evaluated on the nist 2005 sre corpus . experimental results show that the proposed approach is effective in improving the performance of the speaker verification systems .
in this paper , we propose a spectral-like representation based on synchrony effects in voiced parts of the speech signal . the spectral-like representation is derived from the frequency distribution of the band-pass filter bank . the spectrum of the band-pass filter bank is used to discriminate between voiced and unvoiced sounds . the proposed spectral-like representation is evaluated in the context of noisy speech recognition using the synchrony-based spectrum . the recognition performance of the proposed spectral-like representation is evaluated under various snr conditions in the high noise level case . the results show that the proposed spectral-like representation outperforms the mel cepstrum features , especially in the high noise level case .
in this paper , we consider the problem of localizing multiple faces in real images . we assume a known distribution on the target location and use a dyadic policy to estimate the target location . the posterior distribution of the target location is assumed to be known , and the distribution of the target location is known . we derive a constant factor approximation guarantee for the noisy setting , and use constant factor approximation guarantee to estimate the target location . we demonstrate the effectiveness of the proposed algorithm on simulated data .
in this paper , we present a method for estimating the 3-d pose of 3-d shape of 3-d shape , from images captured by an uncalibrated computed , and using a geometric transformation . the method is based on the estimation of error bounds on the degrees of freedom -lrb- rotation , translation , anisotropic scaling , etc. -rrb- and the degrees of freedom -lrb- rotation , and scale -rrb- of the imaging device . the method is based on the observation that the geometric transformation of the ct scan intrinsic parameters is invariant to noise and is invariant to noise . the proposed method is based on a combination of closed-form and numerical algorithms . the proposed method can be applied to images captured by a camera mounted on an uncalibrated computed , and can be used to reconstruct cross-sectional images . the proposed method has been tested on a variety of ct images captured by a single camera . the results show that the proposed method is robust to noise and can be used to estimate the 3-d pose of 3-d shape , even when the image data is corrupted by noise .
this paper investigates the use of different classification models for the professional normal-hearing cs speaker in the context of lip flow modeling . the aim of this study is to investigate the use of manual cs information in the context of lip flow modeling and classification models for french vowels . the reference models were trained on deaf data . the results show that the use of the reference models improves the classification performance of a professional normal-hearing cs speaker . the analysis also shows that the use of the reference models improves the classification performance of the male cs speaker .
we consider the problem of encoding preferences in decision theory with utility or value functions . we consider the problem of aggregation of preferences over preferences in a weighted logical setting , where preferences are expressed as logical propositions , and preferences are expressed as constraints on preferences . we consider the problem of possibilistic logic , where preferences are expressed as a utility function over preferences . we show that the problem of computing a logical representation of preferences can be formulated as a weighted logical setting , and we show that the problem of computing the expression modes is np-complete . we also show that the problem of computing the logical representation of preferences is np-complete , and that the problem of computing the expression modes is np-complete , even when the number of preferences is very large . we also show that the problem of computing the expression modes is np-complete , and that the problem of computing the logical propositions is np-complete . finally , we show that the problem of computing the logical representation of preferences is np-complete , and that the problem of computing the logical propositions is np-complete . finally , we show that the problem of computing the logical representation of preferences can be reduced to reasoning purposes .
in this paper , we propose a method to select the optimal linear transformation of the lda features to minimize the word error rate . the proposed method is based on minimizing the minimum bayes error between the class densities and the class densities . experimental results show that the proposed method can reduce the word error rate compared to the conventional cepstral features .
minimum mean-squared error estimation -lrb- mse -rrb- estimation is a fundamental problem in elds of signal processing . in this paper , we consider the problem of estimating the parameters of a restricted estimator from a given set of samples . we derive a closed form formula for the constrained estimation problems , and show that this closed form formula can be used to derive an estimator for the general case of constrained estimation problems . finally , we illustrate the performance of the proposed closed form formula for a wide class of problems .
in this paper , we propose a latent topic model to learn a context representation in a joint label-and-image space . given an input image , our latent topic model learns a semantic hierarchy of co-occurring patterns that describe the relationship between image features and their corresponding labels . given an input image , our latent topic model learns a context representation in the joint label-and-image space , where each image is represented by a latent topic model . the latent topic model learns a context representation that captures the relationship between image regions and their associated labels . the latent topic model can be used to learn a context representation in a joint label-and-image space , which can be used for image labeling . we evaluate our latent topic model on two real-world datasets and show that our latent topic model can effectively learn the context representation of images with specificity . furthermore , we show that our latent topic model can effectively learn the context representation for a variety of image regions with high accuracy .
the semiautomatic generation of human-machine dialog systems is important for many practical dialog applications such as confirmation handling , overanswering dialogs , overanswering dialogs , and overanswering dialogs . in this paper , we propose a method to reduce the amount of service data needed for such applications . the method is based on the use of a speech and web designer 's intervention , and uses a flow model and guided interaction to reduce the amount of service data needed for such applications . the effectiveness of the proposed method is demonstrated through a series of experiments .
we propose a non-parametric bayesian model for simultaneous image clustering , annotation , and object segmentation in image databases . our non-parametric bayesian model is based on the assumption that object types are spatially contiguous , and that object-feature mixture models -lrb- i.e. , objects -rrb- are spatially contiguous . we use variational bayesian analysis to perform inference on a set of image databases , where each image is represented by a heterogeneous mix of components , and a logistic stick-breaking process is used to infer the number of spatially contiguous objects in each image . we show that our non-parametric bayesian model is able to simultaneously cluster multiple image classes , and simultaneously cluster multiple image classes . we demonstrate the effectiveness of our non-parametric bayesian model on several challenging datasets .
the problem of estimating the phase of noisy phase monocomponent signals in additive noise is considered . the problem of estimating the phase of noisy phase monocomponent signals is considered . a maximum likelihood solution is derived for this problem . the maximum likelihood solution is derived for the case where the noise free phase is known . the performance of the proposed maximum likelihood solution is illustrated by simulations using real world applications in radar and communications .
in this paper , we consider the problem of single clock reference localization and synchronization in a wireless network . we propose a method to estimate the relative motion between a node in a static network . the proposed method is based on the estimation of the clock offsets and unknown clock skews relative radial velocities , initial pairwise distances , and clock offsets . the estimation of the clock offsets and relative radial velocities is performed by minimizing the proposed method . simulation results show that the proposed method is effective in estimating the clock offsets and clock offsets of a wireless network .
in this paper , we propose a generic temporal constraint for content summarization . our generic temporal constraint is based on the dominant motion assumption , i.e. , the dominant motion of a video sequence is characterized by a set of dominant motion and an image map . a compact description of a video sequence is obtained by combining the dominant motion and the image map . the temporal consistency of the proposed generic temporal constraint is exploited to improve the robustness of the motion model . the proposed generic temporal constraint is applied to various applications such as visual summarization , mosaicing , video browsing and retrieval . experimental results show that the proposed generic temporal constraint is effective in content summarization .
this paper proposes a random-walk based learning method for question answering . the proposed random-walk based learning method is based on recurrent neural networks to learn ranking metric network embedding from cqa data . in the proposed random-walk based learning method , a user model is first represented by question-answering activities , and then a user model is represented by a set of learned ranking metric embedding . in the proposed random-walk based learning method , each question is represented by a set of learned ranking metric network embedding . in the proposed random-walk based learning method , the proposed random-walk based learning method is applied to the problem of question routing in cqa data . the experimental results on a large-scale dataset show that the proposed random-walk based learning method can significantly improve the performance of question answering . moreover , the proposed random-walk based learning method can also improve the relative quality rank of question answering .
detecting deletions in asr output is a challenging classification task . we propose a deletion-informed confidence estimation approach , where the deletion confidence score is defined as the sequence structure of the deletion detection scores . we show that the deletion-informed confidence estimation approach can be viewed as an extension of conditional random field models to the problem of overall confidence estimation . we show that this deletion-informed confidence estimation approach can be used to improve the overall confidence estimation of the deletion confidence scores . we also show that the deletion-informed confidence estimation approach can be used to improve the performance of the conditional random field models .
in this paper , we present a new approach to inference graphs that combines natural deduction and subsumption reasoning . the approach is based on a logic of arbitrary and indefinite objects , and is able to deal with a large class of inference graphs . the approach has been implemented in a hybrid reasoning system , and has been successfully applied to a wide range of problems including subsumption reasoning and natural deduction .
we consider the problem of batch mode active learning , where the goal is to maximize the expected utility of the active learning . in this setting , the objective is to maximize the average reward of the active learning , subject to a natural diminishing returns condition . in this paper , we consider the problem of batch mode active learning , where the objective is to maximize the expected reward of the active learning , while maximizing the expected reward of the active learning . we propose two heuristics for batch-mode active learning , one based on adaptive submodularity , and the other based on the sequential strategy . the first one is a greedy strategy , and the second one is a sequential strategy . the second one is a sequential strategy , and the second one is a greedy strategy , which is guaranteed to find the optimal batch-mode policy . we empirically evaluate the proposed algorithms on multi-stage influence maximization in social networks .
detection and localization of general 3d object classes is an important problem in modeling and detection . in this paper , we propose a novel viewpoint invariant approach for modeling and detection of general 3d object classes . the proposed viewpoint invariant approach is based on the observation that the viewpoint invariant reference frame is a consistent geometrical interpretation of a 3d object class , and the viewpoint invariant reference frame is a consistent geometrical interpretation of the object class in a data-driven manner . the proposed viewpoint invariant approach is based on the observation that the viewpoint invariant representation of the object class is invariant to the viewpoint invariant reference frame , and can be learned in a data-driven manner by an iterative learning algorithm . the proposed viewpoint invariant approach is evaluated on the cmu profile database using a public color feret database , and the results show that the proposed viewpoint invariant approach outperforms the state-of-the-art methods in terms of both false positive detections and average precision . moreover , the proposed viewpoint invariant approach is also shown to be effective in both modeling and detection .
in this paper , we propose a new method to estimate the confusion matrices of a speaker 's confusion matrix from sparse data . the proposed method is based on non-negative matrix factorisation , where the mean confusion matrix of a speaker 's confusion matrix is replaced by a sparse subset of the confusion matrices . we show that the proposed method can be used to estimate the confusion matrices of a speaker 's confusion matrix . the accuracy of the proposed method is evaluated by comparing it with other state-of-the-art speech recognisers based on confusion matrices .
snack -lrb- snack -rrb- is an unstructured set of pictographic characters that contain both prime and nonprime numbers . snack is a popular method for learning concept embeddings from human supervision . snack is a low-dimensional concept embedding algorithm with human expertise and automatic machine similarity kernels . in this paper , we present deep-learned features for snack embeddings . we evaluate snack on the caltech ucsd birds dataset , and show that snack can be used to learn concept embeddings from a small set of training datasets . we also show that snack can be used to learn a variety of bird classifiers from a small set of training datasets . we also show that snack can be used to learn concept embeddings from a small set of training examples , and that snack can be used to learn from human insight . we also show that snack can be used to learn a set of bird classifiers from a small set of training datasets . we also show that snack can be used to learn a set of candidate concepts from a large set of training examples .
neural networks are a primary visual system that captures the temporal dynamics of spike interactions in the primary visual system . in this paper , we present a neural network simulation based on biologically realistic neu-rons with nontrivial single-cell dynamics . the neural network simulation is based on the biologically realistic neu-rons with nontrivial single-cell dynamics . we show that the structure of the neural network simulation can be learned from biological data , and that the structure of the neural network simulation can be used to predict the structure of the primary visual system in a computation-ally most demanding task .
rb ± atl -lrb- rb ± atl -rrb- is a symbolic implementation of rb ± atl . rb ± atl is an extension of rb ± atl , which uses a forward search of the state space . we show that rb ± atl can be viewed as a simple , symbolic , and that rb ± atl can be viewed as a simple and efficient , symbolic , and can be used to solve rb ± atl . we also show that rb ± atl can be viewed as a simple and efficient , and that rb ± atl can be solved efficiently by using a simple and efficient algorithm . in addition , we show that rb ± atl can be viewed as a simple and efficient , symbolic , and that rb ± atl can be solved efficiently by means of a simple and efficient algorithm .
error correcting output coding -lrb- error correcting output coding -rrb- is one of the most widely used methods to improve the accuracy of text classification tasks . in this paper , we propose to use error-correcting codes and random codes to improve the performance of text classifiers . we also propose a novel method to combine error-correcting codes with random codes . experiments on a real-world data set show that the proposed method can significantly improve the accuracy of text classification tasks .
this paper presents a single-step approach to acoustic source localization in a reverberant environment . the single-step approach to acoustic source localization is based on a two-step procedure that uses intermediate time-delay estimates to estimate the source location . particle filtering is used to estimate the source location , which is then used to estimate the source location . the proposed single-step approach is compared to steered beamforming , where the beamformer is based on the localization estimates of the source trajectory . the proposed single-step approach is shown to be effective in speech enhancement applications where reverberation is present .
in this paper , we propose a diagnosis scheme for diagnosis in the presence of periodic patterns in a track circuit . the diagnosis scheme is based on empirical mode decomposition and hilbert transform . empirical mode decomposition is used to decompose the measurement signal into a set of intrinsic mode functions , each of which represents the physical meaning of a track circuit . the intrinsic mode functions are decomposed into a set of intrinsic mode functions , each of which represents the physical meaning of a track circuit . the intrinsic mode functions are then decomposed into a set of intrinsic mode functions , each of which represents the instantaneous frequency of a measurement signal . the proposed diagnosis scheme has been tested on both simulated and experimental signals . the results show that the proposed diagnosis scheme is effective in track/vehicle transmission .
in this paper , we propose a voice morphing strategy to synthesize a continuum of accent transformations from parallel recordings of a foreign speaker . the transformation is performed in a pair-wise fashion by spectral morphing based on pulse density modulation and averaging pulses . the transformation is performed in a pair-wise fashion by modifying the spectral slope of a foreign speaker to a target speaker . the voice morphing strategy is applied to the speaker identity and foreign accent . the proposed voice morphing strategy is evaluated on a database of arctic speakers . the results show that the proposed voice morphing strategy is able to synthesize a foreign speaker with high acoustic quality .
in this paper , we study the problem context open problem in the hamming distance . we propose a novel algorithm for finding binary codes that maximize the hamming distance between the query and the query . our algorithm is based on the idea of multi-index hashing , which is a variant of the problem context open problem in the context of hamming distance . we show that our algorithm is competitive with the state of the art .
in this paper , we propose a new bit allocation strategy called max-bnlr scheme for mpeg-4 aac . max-bnlr scheme is an extension of the bit assignment algorithm in tb-anmr with low computational complexity . max-bnlr scheme is an extension of the standard mpeg-4 aac verification model . max-bnlr scheme is an extension of the standard mpeg-4 aac verification model . max-bnlr scheme can be viewed as a special case of the bit assignment algorithm in tb-anmr with a band-level . the performance of max-bnlr scheme is evaluated by comparing max-bnlr scheme with other frame-level bit assignment methods . the results show that max-bnlr scheme is superior to the mpeg-4 aac verification model in terms of performance .
hashing plays an important role in large-scale multimedia retrieval . supervised hashing methods have been widely used for image retrieval . however , most existing supervised hashing methods mainly focus on supervised hashing for hash coding . in this paper , we propose a deep quantization network architecture for efficient image representation for hash coding . specifically , deep quantization network architecture learns a dimension-reduced representation for hash coding by encoding the image representation into a sub-network with convolution-pooling layers in the sub-network . specifically , we propose a deep quantization network architecture to learn deep image representations by minimizing the product quantiza-tion loss and the pairwise cosine loss layer in the sub-network . the proposed deep quantization network architecture learns the image representation for hash coding by minimizing the quantization error between the data pairs and the hand-crafted or machine-learned features . the proposed deep quantization network architecture is evaluated on two image retrieval datasets , and the experimental results show that the proposed deep quantization network architecture outperforms the state-of-the-art hashing methods . moreover , the proposed deep quantization network architecture can achieve better hash coding with semantic similarity than the state-of-the-art hashing methods .
in this paper , we address the problem of recognizing objects and their articulated categories in real world images . our approach is based on a combination of scanning-windows part models and global appearance cues . bottom-up regions are detected using class-specific scores , which are then used for pixel classification . we evaluate our approach on the challenging pascal segmentation challenge , and show that it outperforms state-of-the-art region-based object detectors . we also show that our approach can be used to detect articulated objects in still images . finally , we show that our approach is competitive with state-of-the-art methods on the pascal segmentation challenge .
in this paper , we propose a low-power bit-serial viterbi decoder chip for next generation wide-band cdma mobile systems with wireless atm lans and wide-band cdma mobile systems . add-compare-select units are optimized using bit-serial arithmetic . the proposed low-power bit-serial viterbi decoder chip is capable of encoding 2mbps with high speed convolu-tional decoding , which is suitable for operation on wireless atm lans and wide-band cdma mobile systems . the proposed low-power bit-serial viterbi decoder chip is composed of two steps : -lrb- 1 -rrb- a power-efficient and power-efficient -lrb- 2 -rrb- an application-specific memory scheme to reduce the number of operations . the proposed low-power bit-serial viterbi decoder chip is implemented in real-time , and the proposed low-power bit-serial viterbi decoder chip is implemented in real-time . the experimental results show that the proposed low-power bit-serial viterbi decoder chip is capable of achieving a coding rate that is comparable to that of the conventional techniques .
short-time fourier transform based features , such as mfcc and acoustic features , have been shown to be effective in improving the performance of speech recognition systems . however , these short-time fourier transform based features have not been widely used in speech recognition systems . in this paper , we propose a novel approach to non-stationary signal analysis in the asr framework . the proposed acoustic features are derived from a pitch-adaptive gammatone filter bank , and the acoustic features are extracted from the basis of a pitch-adaptive gammatone filter bank . experimental results show that the proposed acoustic features outperform conventional mfcc and mfcc in terms of noise robustness .
this paper presents a learning based approach to automatic annotation of visually deformable objects from a single annotated frontal image . unlike traditional statistical approaches to non-rigid deformable models such as active appearance model , the proposed learning based approach allows for the automatic annotation of visually deformable objects from a single frontal image without the need for manual annotation of training images . the proposed learning based approach is capable of automatically annotating face images for fitting , tracking , and fitting to unseen images . the active appearance model is trained on a set of virtual images of unseen faces with arbitrary pose and pose . the landmark locations of the frontal image are then used to estimate the maximum range of the landmark locations in the reconstructed images . the proposed learning based approach is applied to the problem of automatic annotation of visually deformable objects from a single frontal image . the experimental results show that the proposed learning based approach is able to automatically annotating face images for both fitting and tracking .
in this paper , we propose a novel approach for facial age estimation based on ordinal discriminative feature learning . in our approach , each image is represented by a local manifold structure of facial images , and each image is represented by a set of ordinal information . in order to capture the redundant information in the aging process , we propose to use rank correlation and nonlinear correlation for feature selection . in order to capture the locality information in the face , we propose a novel method to learn the ordinal information for age estimation . the proposed method is evaluated on two public available images of groups dataset , and the experimental results show that the proposed method achieves better performance than the state-of-the-art methods . moreover , the proposed method is very effective for aging faces .
we present a new set covering machine in data-dependent half-spaces . the set covering machine is a generalization error of the support vector machine , which is a generalization error of the set covering machine in terms of data-dependent half-spaces . we show that the data-dependent balls can be interpreted as a generalization of the set covering machine in terms of data-dependent half-spaces . we also show that the data-dependent balls can be interpreted as a special case of the set covering machine , which we call data-dependent balls . experiments on several natural data sets show that the proposed set covering machine outperforms the existing data-dependent balls .
in this paper , we propose a new global learning scheme for speech models based on a distributed genetic algorithm . the global learning scheme is based on a speech-modeling algorithm , which is based on mel-scaled subband decomposition of the wavelet packet best basis decomposition . in the proposed global learning scheme , the wavelet topology of the wavelet packet best basis decomposition is used as a measure of similarity between the fitness value and the speech recognition performance . in the proposed global learning scheme , a '' priori '' reference is used as a measure of similarity between the fitness value and the speech recognition performance . in the proposed global learning scheme , the similarity between the fitness value and the speech recognition is measured by a neural network , which is used as a measure of similarity between the fitness value and the speech recognition models . the proposed global learning scheme is applied to the feature extraction module of a connectionist system based on the wavelet topology . the experimental results show that the proposed global learning scheme performs better than the reference system based on simulated fitness .
in this paper , we consider the problem of parameter estimation in a class of lters . the class of lters in the class of lters is assumed to be a volterra lter . we show that , in the class of lters partition r n can be expressed as a hy-per-rectangular lattice , a class of piecewise volterra filters can be expressed as a generalization of the threshold decomposition operator of multivariate polynomials . this class of lters can be interpreted as a linear problem of finding the partition boundaries in the class of multilinear tensor forms . this class of lters can be seen as a special case of piecewise volterra filters , which can be interpreted as a special case of piecewise volterra filters . this class of lters can be considered as a special case of piecewise volterra filters , which can be interpreted as a special case of the volterra lter . the class of lters in the class of lters can be expressed as a special case of piecewise volterra filters , which can be interpreted as a special case of the class of multilinear tensor forms . we show that piecewise volterra filters can be interpreted as a special case of piecewise volterra filters , and that piecewise volterra filters can be interpreted as a special case of piecewise volterra filters .
in this paper , we propose a max-margin framework for semi-supervised structured output learning using unlabeled data . our max-margin framework is motivated by recent developments in semi-supervised learning to learn a discriminative model from unlabeled data . in contrast to existing discrete optimization algorithms , our max-margin framework does not require any labeled data , nor does not require any labeled data . instead , our max-margin framework learns a discriminative model from the unlabeled data , which can be used for structured output problems with multi-dimensional outputs . our max-margin framework is based on posterior regulariza-tion , and can be applied to various image segmentation tasks , including the graph regularizer and the cardinality regularizer . our max-margin framework is general and can be applied to any number of image segmentation tasks , such as those with high order regular-izers . experimental results show that our max-margin framework is competitive with the state of the art in semi-supervised structured output learning .
in this paper , we address the problem of multiview sub-space clustering , where the affinity matrix is used for clustering , and the affinity matrix is used for clustering . in particular , we propose a low-rank tensor constraint to capture the complementary information among different subspace representations , and formulate the problem as a ten-sor nuclear norm minimization problem , which can be solved efficiently by solving a minimization problem with a low-rank constraint . the proposed low-rank tensor constraint is able to capture the high order correlations among different subspace representation matrices , which can be efficiently solved by solving the proposed ten-sor nuclear norm minimization problem . moreover , the proposed low-rank tensor constraint can be easily incorporated into the inference process . extensive experiments on benchmark image datasets show that the proposed lt-msc method outperforms the state-of-the-art methods in terms of both accuracy and efficiency .
planning landmarks have been shown to be useful in satisficing planning . in this paper , we propose a new approach to cost-optimal heuristic search based on landmarks . our approach is based on a best-first search procedure that combines heuristics with a set of multi-path dependent heuristics . we show that our approach can generate admissible heuristic estimates for cost-optimal planning , and that it can be used to guide the search for a solution plan . we empirically evaluate our approach on a variety of planning landmarks , and show that our approach can significantly improve the quality of planning landmarks in satisficing planning .
in this paper , we address the problem of blind separation of nonstationary sources in the underdetermined convolutive mixture case . the proposed blind separation of nonstationary sources is based on the subspace projection of the time-frequency distribution values in the tf domain . the proposed blind separation of nonstationary sources is based on the observation that the active sources are disjoint in the time-frequency domain . the proposed blind separation of nonstationary sources is based on the subspace projection of the tf point in the tf domain . the proposed blind separation of nonstationary sources is evaluated in the underdetermined convolutive mixture case . the experimental results show that the proposed blind separation of nonstationary sources is more effective than the conventional methods .
in this paper , we propose a novel rate control scheme for high efficiency video coding . the proposed rate control scheme is based on the idea that the region of interest quality can be approximated by a set of objective metrics . the proposed rate control scheme can control the global bit rate of the coding unit in order to control the region of interest quality . the proposed rate control scheme can control the tradeoff between the target bit rates and the global bit rate of the coding unit . in the proposed rate control scheme , the proposed rate control scheme can control the tradeoff between the objective metrics and the subjective quality evaluation . the proposed rate control scheme can also be used to control the tradeoff between the objective metrics and the subjective quality evaluation .
interactive image segmentation frameworks -lrb- interactive image segmentation frameworks -rrb- have become a popular interaction paradigm in recent years . however , most existing interactive image segmentation frameworks do not take into account the interaction paradigm . in this paper , we propose a novel topological prior on the bounding box prior , which is formulated as a global energy minimization framework with hard constraints . specifically , we formulate the topological prior as an np-hard integer program and propose a novel graph cut algorithm , called pinpointing , for solving the fractional lp solution . the proposed graph cut algorithm is based on a rounding method , which can be solved efficiently by a standalone heuristic . the proposed graph cut algorithm is evaluated on a publicly available dataset and compared with state-of-the-art thresholding-based rounding . the experimental results show that the proposed graph cut algorithm is competitive with the state-of-the-art . moreover , the proposed graph cut algorithm is also orders of magnitude faster than the thresholding-based rounding .
in this paper , we propose a new watermarking task using the sinusoidal model and frequency modulation of speech signals . the proposed watermarking task is based on the use of the sinusoidal model for audio/speech signals . the proposed watermarking task is based on the use of the sinusoidal model and the modulation of the sinusoidal model . the experimental results show that the proposed watermarking task can be successfully applied to speech signals .
in this paper , we propose a new method for color image enhancement based on the spatial information of a real blurred and noisy color image . the proposed method consists of two steps . first , a filter is used to enhance the enhancement capabilities of the color image enhancement . second , a weighted cost function is used to estimate the color image . finally , the enhancement capabilities of the proposed method are evaluated using the experimental results .
we consider the problem of function approximation in linear function approximation representations of q , where the state action value function can be approximated by a function approximation . we show that , under certain conditions , a bias term can be used to approximate the state action value function . in particular , we show that when the non-zero bias term is used to approximate the value of the state action value function , the reinforcement learning performance can be improved by minimizing the difference between the gradient estimates of q and q . in particular , we show that when the function approximation is used to approximate the state action value function , the reinforcement learning performance can be improved by minimizing the difference between the value of the basis functions and the value of the function approximation representation . in addition , we show that when the function approximation is used to approximate the linear function approximation representations of q , the reinforcement learning performance can be improved by minimizing the difference between the basis functions of q and q .
dialogue strategies play an important role in spoken dialogue systems for mutual understanding . in this paper , a cluster-based user simulation technique is proposed to simulate user simulations for dialogue management . the cluster-based user simulation technique uses a cluster-based technique to simulate user simulations in reinforcement learning . the proposed cluster-based user simulation technique is evaluated by comparing cluster-based user simulations with a random base-line . the results show that the cluster-based user simulation technique can achieve better performance than the random base-line . furthermore , the cluster-based user simulation technique can also be used to simulate user simulations with different clarification strategies for dialogue management .
in this paper , we investigate the effect of noise reduction and beamforming schemes on speaker diarisation on the performance of a digital mems microphone array . in particular , we investigate the effect of noise reduction on the performance of the diar-isation systems . in particular , we investigate the effect of noise reduction on the performance of the delay-sum beamformer on the diarisation error rate . in particular , we investigate the effect of the snr analogue on the performance of the delay-sum beamformer when the number of mems microphones is large . in particular , we investigate the effect of the snr analogue on the performance of the delay-sum beamformer when the number of mems microphones is large . we find that the amount of microphones used for speaker diarisation is less than 1 % when the number of mems microphones is larger than the number of microphones . in addition , we investigate the impact of the amount of microphones on the performance of the delay-sum beamformer when the number of mems microphones is larger than the number of microphones . finally , we investigate the effect of the amount of microphones on the performance of the delay-sum beamformer when the number of mems microphones is small . finally , we investigate the effect of the amount of audio signal degradation on the performance of the beamforming techniques .
temporal difference learning -lrb- lstd -rrb- algorithms are widely used to approximate the value function of a set of features in a high-dimensional energy allocation domain . in this paper , we propose an incremental low-rank lstd -lrb- -rrb- algorithm for policy evaluation in reinforcement learning . the proposed incremental low-rank lstd -lrb- -rrb- algorithm is based on a truncated low-rank approximation of the rank parameter of the least-squares temporal difference algorithms . the proposed incremental low-rank lstd -lrb- -rrb- algorithm has linear time complexity and computational complexity o -lrb- n 2 -rrb- , where n is the number of features and n is the rank parameter . the proposed incremental low-rank lstd -lrb- -rrb- algorithm has a bias-variance trade-off between computational efficiency and sample efficiency . the proposed incremental low-rank lstd -lrb- -rrb- algorithm has the same computation and storage complexity as lstd , but incremental low-rank lstd -lrb- -rrb- algorithm is much faster than lstd in terms of both computation and storage complexity . experimental results show that the proposed incremental low-rank lstd -lrb- -rrb- algorithm has superior performance in terms of both sample efficiency and computational efficiency .
this paper describes the application of explanation-based learning to the sri core language engine . the sri core language engine is based on explanation-based learning and machine learning technique . the machine learning technique is evaluated on the atis corpus . the total processing time of the machine learning technique and the machine learning technique of the sri core language engine are discussed . the results show that explanation-based learning can be used to improve the performance of the sri core language engine .
speech enhancement is one of the most important problems in auditory modeling . in this paper , we propose a novel method for speech enhancement in the time-frequency transform domain using fft processing . in the time-frequency transform domain , masking threshold constraints are used to reduce the speech coecients . in the time-frequency transform domain , a rough masking model is applied to the noisy signal and the quantization is performed on the basis of the wavelet packet transform algorithm . the experimental results show that the proposed method can improve the quality of speech enhancement in the presence of noise . moreover , the proposed method can improve the performance of the subtractive-type enhancement algorithm .
this paper presents an automatic speech recognition system for the bilingual mediaparl corpus . the automatic speech recognition system is based on bilingual deep neural networks trained with frequency domain linear prediction-based features . the tandem and hybrid acoustic modeling approaches are trained using frequency domain linear prediction-based features , and the entropy-based decoding-graph selection is performed . the automatic speech recognition system is evaluated on a large vocabulary continuous speech recognition -lrb- lvcsr -rrb- task . the automatic speech recognition system is trained on accented speech and reverberant recordings , and the automatic speech recognition system is shown to outperform the language-specific asr system . the automatic speech recognition system is also shown to be very effective for ac-cented speech .
in this paper , we propose a new quality measure for topic segmen-tation algorithms on large multimedia collections . the quality measure is based on the idea that speech recognition lattices can be used to improve the transcription quality of a spoken language . the quality measure can be used to evaluate the quality of a baseline one-best topic model in terms of a topic segmentation quality measure . the quality measure is based on the assumption that speech segments tend to have similar topic boundaries , and speech recognition lattices can be used to improve the transcription quality . the proposed quality measure is compared with the baseline one-best topic model in terms of the relative error reduction of the topic segmentation quality measure . the proposed quality measure is also compared with the baseline one-best topic model in terms of the topic segmentation quality measure . the experimental results show that our quality measure can be used to improve the performance of topic segmen-tation algorithms on large multimedia collections .
region identification in multiple images is a challenging problem due to the high intensity gradients in the intensity values . in this paper , we propose a new energy functional for region identification in multiple images . the energy functional is defined as a ratio form over a multi-dimensional space , and a polynomial time graph algorithm is used to find the global minimization of the energy functional . the energy functional is defined by minimizing the energy of the energy functional . the energy functional is defined by minimizing the sum of the energy of the energy functional , which is a function of the disparity map and the dense optical flow . the proposed polynomial time graph algorithm is compared with the state of the art , and the results show that the proposed polynomial time graph algorithm is robust to optical flow discontinuities .
assessing similarity between features is an important problem in many object recognition and scene categorization tasks . in this paper , we introduce a family of similarity functions that capture the distribution of distances between feature vectors . we show that the distribution of distances can be expressed as a function of the distance between two feature vectors , and that the distribution of distances can be expressed as a function of the distance between two feature vectors . we show that the distribution of distances can be expressed as a function of the distance between two feature vectors , which can be computed using l p-norms . we demonstrate the effectiveness of the family of similarity functions on two tasks : object recognition and scene categorization . in both cases , we show that the distribution of distances can be computed using the proposed similarity functions . in both cases , the distribution of distances can be learned from a large number of images , and the distribution of distances can be computed using the proposed similarity functions . we demonstrate the effectiveness of the proposed family by comparing feature extraction algorithms with other popular methods .
in this paper , we propose a new algorithm for computing upper bounds on the expected performance of a branch-and-bound search tree compilation language . the algorithm is based on a branch-and-bound solver which can be applied to functional e-the e-the sat problem . the algorithm is based on the idea of upper bounds on the expected performance of the algorithm . the algorithm is based on a combination of a map solver and a probabilistic and a recently proposed probabilistic and a branch-and-bound search tree compilation language . the experimental results show that the proposed algorithm is competitive with the state of the art algorithms for d-dnnf computing .
in this paper , we consider the problem of learning a piecewise-linear concave function from a polyhedral set . we consider the problem of learning a polyhe-dral set from a set of linear programs in closed form . we propose a novel k-median algorithm , which we call k-median training set correct-ness . the k-median algorithm is based on a bilinear program , where the polyhedral distance is defined as a bilinear function of the polyhedral set . we show that the k-median algorithm can be viewed as a fast nite k-median algorithm , and that k-median algorithm can be viewed as a variant of the fast nite k-median algorithm . we evaluate the k-median algorithm on the wisconsin diagnostic breast cancer database and compare k-median training set correct-ness to the k-median algorithm on several real-world databases .
time-frequency methods -lrb- time-frequency methods -rrb- have been widely used to analyze biological sequences . however , most of these time-frequency methods are based on highly-localized basis functions , which may not be suitable for pre-processing . in this paper , we propose a new approach for querying repetitive segments in a sub-sequence , based on a carefully accepted blast alignment approach . the key idea of our approach is to use the tf plane as a basis for gapped query-based alignment methods , and then use the tf plane as a basis for querying the entire sub-sequence . the proposed approach has been tested on several datasets , and it is shown that the proposed approach outperforms the existing querying approaches . moreover , it is shown that the proposed approach is able to find repetitive segments in low-complexity regions , and that it outperforms the existing methods . moreover , it is also shown that the proposed approach can be applied to a wide range of biological sequences .
recently , graph based visual saliency has attracted a lot of attention in recent years . however , it has been shown that the performance of state-of-the-art saliency algorithms can be improved by incorporating spatial biases into the saliency algorithm development , such as dynamic visual attention and information maximiza-tion . in this paper , we propose a novel shuffled roc metric to optimize roc metrics based on randomly sampled fixations . our shuffled roc metric is based on the idea of adaptive whitening saliency , which aims to reduce the bias caused by central fixations by the algorithm ranking . the proposed shuffled roc metric can be viewed as an extension of the popular saliency algorithm , which is called large-scale benchmarking . specifically , we show that the proposed shuffled roc metric satisfies the spatial bias of the original saliency algorithm , and thus can be used to improve the performance of existing saliency algorithms . we evaluate our shuffled roc metric on several datasets of human fixations , and show that the proposed shuffled roc metric is superior to the state-of-the-art methods .
in this paper , we present a novel approach to the problem of mobile robot motion coordination . the approach is based on a geometric based approach which uses a bounding box representation of the environment and uses a so-called coordination diagram to determine the set of possible robot paths . the geometric based approach is based on the concept of a bounding box representation of the environment . the approach has been tested on a variety of benchmarks and it is shown that the proposed approach outperforms the existing approaches .
in this paper , we propose a one-shot similarity measure for image representation . the one-shot similarity measure is a conditionally positive definite kernel , which is a generalization of the lda classifier . we show that the one-shot similarity measure can be seen as an extension of the one-shot similarity measure to the problem of face recognition . we show that this one-shot similarity measure can be seen as an extension of the one-shot score , which allows us to compute a one-shot similarity score for any given image representation . we demonstrate the effectiveness of our one-shot similarity measure in two applications : multi-class identification and descriptor generation .
multi-task learning is a fundamental problem in many applications . in this paper , we propose a novel transfer learning framework for multi-task learning , where the tasks are related to the source domain and the target domain are related to the target domain . the proposed transfer learning framework is based on the assumption that the tasks are related to the source domain and the target domain are related to the target domain . the proposed transfer learning framework is based on the assumption that the tasks are related to the target task and the target tasks are related to the target task and the target task is related to the target task . the proposed transfer learning framework is based on the assumption that the tasks are related to the target task and the target tasks are related to the target task and the target tasks respectively . the proposed transfer learning framework has two main advantages : -lrb- 1 -rrb- it does not require any smoothness assumptions on the source domain , and -lrb- 2 -rrb- it does not require any smoothness assumptions on the target domain ; -lrb- 3 -rrb- it does not require any knowledge of the source domain , and -lrb- 3 -rrb- it can be applied to multi-tel/transfer learning problems . experiments on both simulated and real data demonstrate the effectiveness of the proposed transfer learning framework .
in this paper , we introduce symmetry reduction techniques for nondeterministic planning . we show how structural symmetries and fond planning can be incorporated into classical planning using heuristic search . we show how these symmetry reduction techniques can be used to improve the efficiency of nondeterministic planning . we also show how these symmetry reduction techniques can be used to improve classical planning by exploiting symmetry reduction . finally , we show how these symmetry reduction techniques can be used to improve the efficiency of nondeterministic planning . we demonstrate the effectiveness of our new techniques on a variety of problems , including planning with a fast downward planner .
in this paper , we propose a low bitrate audio coding scheme for the loss of spatial image in coded channels with severe truncation of the side channel audio codecs code multi-channel sources . the low bitrate audio coding scheme is designed to minimize the loss of spatial image due to the redundancy present in the coded channels . the low bitrate coding method is designed to minimize the loss of higher frequencies due to the severe truncation of the side channel audio codecs code multi-channel sources . the low bitrate coding method is designed to minimize the distortion caused by the distortion in the side channel . the low bitrate coding method is designed to minimize the distortion in the coded channels with low decoder complexity . experimental results show that the proposed low bitrate coding method outperforms the conventional low bitrate coding methods for the audio codec .
in this paper , we propose a radius control strategy for sphere decoding . the radius control strategy is based on a lattice independent radius selection scheme , where the candidate lattice point is selected according to the distance between the query and the candidate lattice point . the complexity of the proposed radius control strategy is o -lrb- n 2 -rrb- , where n is the number of queries . the complexity of the proposed radius control strategy is o -lrb- n 2 -rrb- , where n is the number of queries . the complexity of the proposed radius control strategy is o -lrb- n 2 -rrb- , where n is the number of queries and n is the number of queries . the complexity of the proposed radius control strategy is o -lrb- n 2 -rrb- , where n is the number of queries . the proposed radius control strategy is evaluated on multiple-input and multiple-output channels . the results show that the proposed radius control strategy can achieve a negligible performance penalty compared to the existing sphere radius control strategy .
in this paper , we propose a new method for robust normalization of speech feature variations in speaker recognition . in the proposed method , phonetic information is integrated into the speaker eigenspace for speaker verification . in the speaker eigenspace , both dynamic and static features of the speech data are combined to form the speaker eigenspace for robust speaker verification . in the speaker eigenspace , phonetic information is combined with speaker information in the speech data for robust speaker verification . in the speaker verification method , the speaker verification method is based on the subspace method using principal component analysis . in the speaker verification method , the time difference between the speech features and the phonetic information is taken into account . experimental results show that the proposed method can achieve better performance than the conventional gmm and the speaker verification method .
in this paper , we present resolution-based approaches to the inference of logic programs . our resolution-based approaches is based on the notion of recursive denition , a covering technique that is able to represent a logic program in terms of a set of base clauses and recursive clauses . in particular , we focus on the problem of recursive denition , i.e. , inference of a logic program in terms of the number of base clauses and the number of recursive clauses . we show that the problem of recursive denition is np-complete , and that the problem of deciding whether a given logic program can be represented in terms of its resolution steps is np-complete . we also show that our resolution-based approaches can be used to solve the problem of -lrb- i -rrb- deciding whether a given logic program can be represented in terms of the set of resolvents , -lrb- ii -rrb- deciding whether a given set of base clauses can be represented in terms of their likelihood , and -lrb- iii -rrb- identify a subset of base clauses that can be represented in terms of their likelihood . finally , we show that our resolution-based approaches can be used to solve the problem of -lrb- i -rrb- and -lrb- ii -rrb- provide an algorithm for -lrb- i -rrb- learning a logic program in terms of their likelihood .
binary quadratic programs -lrb- binary quadratic programs -rrb- are widely used in many computer vision problems , such as registration , co-segmentation , image segmen-tation , and clustering . in this paper , we propose a novel sdp formulation for solving binary quadratic programs , which is significantly faster than spectral methods and semidefinite programming . the complexity of our sdp formulation is linear in the number of variables and is linear in the number of variables . we propose a dual optimization approach based on the sdp formulation , which can efficiently solve binary quadratic programs for large scale problems . we show that the proposed sdp formulation is much faster than the state-of-the-art sdp formulations , while the computational complexity of our sdp formulation is linear in the number of variables . moreover , we show that the proposed sdp formulation is much faster than the state-of-the-art sdp formulations for large-scale bqps . finally , we demonstrate the effectiveness of our sdp formulation in solving binary quadratic programs for several computer vision problems .
we present a vlsi network of integrate-and-fire neurons that learns complex patterns of mean firing rates . the network of integrate-and-fire neurons is composed of bistable synapses that are modulated by a local spike . the weights of these bistable synapses are determined by a perceptron learning rule . the weights of these bistable synapses are learned by minimizing the sum of the synaptic weights . the learning is performed by minimizing the sum of the weights of the neurons and the weights of the synaptic weights . we show that the network of integrate-and-fire neurons can learn complex patterns of mean firing rates in a network of integrate-and-fire neurons . we also show that the network of integrate-and-fire neurons can learn complex patterns of spiking neurons using bistable synapses . the network of integrate-and-fire neurons can learn complex patterns of spiking neurons by learning bistable synapses in the network of integrate-and-fire neurons .
in this paper , we present a method for recovering the geometry of the surface from apparent contours . the method is based on the epipolar parametrization of the apparent contours , which allows us to compute the spatio-temporal derivatives of the apparent contours . the method is based on a perspective projection of the apparent contours onto the surface geometry , such as gauss curvature , and the for-mulae . we show that this method can be used to recover the nonsingular apparent contours from apparent contours , without any assumptions about viewer motion . we also show that the method can be used to recover the apparent contours from their spatio-temporal derivatives .
hidden markov random fields -lrb- hidden markov random fields -rrb- are graphical models for image modelling . in this paper , we propose a variational bayesian framework for density estimation and inference in hidden markov random fields for image segmentation . the proposed variational bayesian framework is based on a variational approach for model selection and density estimation . the variational bayesian framework allows us to formulate the inference problems in the variational bayesian framework , which can be solved efficiently . the proposed variational bayesian framework is evaluated on real world images and compared with state-of-the-art hmrf-based segmentation methods . the results show that the proposed variational bayesian framework can effectively handle complex image models and model selection problems .
this paper presents a method for estimating 3-d structure from a single image . the 3-d reconstruction is formulated as a model fitting problem , where the ground-vertical boundary is represented as a continuous polyline and the ground plane is represented as chain graphs . the 3-d reconstruction is cast as a model fitting problem , where the ground plane and vertical walls are represented as conditional random field models . the model fitting problem allows us to estimate the 3-d reconstruction from a single image , without having to estimate the stepwise search of 3-d model parameters . the computational efficiency of the method is demonstrated on several challenging urban scenes .
in this paper , we propose a multi-view consensus clustering methodology to cluster multi-modal mri images into vectorial dissimilarity-spaces -lrb- dti-mr -rrb- , which can be used for classification and seg-mentation purposes . the proposed multi-view consensus clustering methodology is based on a manifold learning step , in which the geometric constrains of the data are represented by the high dimensional diffusion information of dissimilar imaging data . the proposed multi-view consensus clustering methodology is applied to multi-modal mri images to enhance the discrimination of a given mri modality . the proposed multi-view consensus clustering methodology is applied to the task of multi-modal mri images to improve the performance of dti-mr in classification and seg-mentation purposes . the proposed multi-view consensus clustering methodology is compared with dce-mri , which is based on cluster ensembles and un-supervised base segmentations . the experimental results show that dti-mr outperforms dce-mri and dce-mri , especially when the amount of dissimilar imaging data is limited .
we present parma , a novel algorithm for recognizing a cross-document , semantic predicate from text . parma consists of two components : -lrb- 1 -rrb- a discrimina-tive model that incorporates linguistic resources , and -lrb- 2 -rrb- a mechanism for textual entailment . we evaluate our algorithm on two tasks : -lrb- 1 -rrb- question answering , -lrb- 2 -rrb- textual entailment , and -lrb- 3 -rrb- textual entailment . our results show that our system achieves an f1 of 81.2 % , which is comparable to the state of the art , while being significantly faster .
in this paper , we propose a transition-based model for word segmentation , joint word segmentation , and pos tagging . the proposed transition-based model is trained on a large annotated corpus from microblogs , and achieves state-of-the-art segmentation accuracy on several text corpora . our transition-based model achieves state-of-the-art performance on three different text corpora . moreover , our transition-based model achieves an error reduction of 30 % over previous state-of-the-art methods . we also show that our transition-based model can be applied to other tasks such as text normalization , pos tagging , and joint word segmentation .
syntactic analyses play an important role in many nlp applications . in this paper , we present a novel approach to syntactic parsing based on statistical grammars . our approach is based on a log linear model of the input sentence and uses beam-search pruning parameters to prune the model space . we compare our approach with the berkeley parser on the charniak and berkeley parsers , and show that our approach achieves comparable or better accuracy than the berkeley parser using a grammar with a smaller number of parameters . we also show that coarse-to-fine pruning can reduce the number of parameters in the log linear model by a factor of three . we also show that our approach is much faster than the berkeley parser by a factor of 2 . finally , we show that our approach can be used to improve the accuracy of the parsing by a factor of 4 .
in this paper , we propose a pitch-synchronous timescale transformation for low bit coding of wide-band speech . the pitch-synchronous timescale transformation is based on a linear prediction narrow-band residual , where the shape of the glottal flow waveform is represented by a narrow-band signal . the pitch-synchronous timescale transformation can be used to reconstruct the speech from a narrow-band residual . the pitch-synchronous timescale transformation can be used to reconstruct the speech signal from its periodic characteristics , such as missing low or high frequency components . the pitch-synchronous timescale transformation does not require side information , and can be used for low bit coding of wide-band speech . the pitch-synchronous timescale transformation does not require any side information about the shape or the shape of the signal . the pitch-synchronous timescale transformation can be used to reconstruct the speech from a narrow-band residual . the proposed pitch-synchronous timescale transformation can also be used for bandwidth extension of speech .
the instruction scheduling problem can be formulated as a learning task and solved using supervised learning methods . in this paper , we present a heuristic algorithm for instruction scheduling , which is based on a combination of features of a compiler and a heuristic scheduling algorithm . our experimental results show that the execution speed of our heuristic algorithm is comparable to the state of the art in terms of execution speed and execution speed . we also show that our heuristic algorithm is competitive with the state of the art in solving the instruction scheduling problem in computer architectures .
we present a large-scale , structure-from-motion framework based on city-scale modeling . the large-scale , structure-from-motion framework is based on a streaming-based framework for connected component discovery . the augmented bag-of-words representation data is embedded into a single image crowd-sourced photo collection , where each image is represented by a set of images , and the image crowd-sourced photo collection is represented by a set of images , and the image crowd-sourced photo collection is represented by a set of images . the data compactness and scalability of the streaming-based framework are determined by the model completeness . the proposed large-scale , structure-from-motion framework is evaluated on a variety of datasets , and the results show that the proposed large-scale , structure-from-motion framework is competitive with the state of the art in terms of both model completeness and scalability .
neural networks have recently been shown to be a powerful tool in neurophysiology . however , neural circuits are based on a multi-layer perceptron , which has a universal computational power . in this paper , we show that neural circuits with a nonlinear unit can be represented as weighted sums of the input variables -lrb- linear -rrb- weighted sums of a boolean function . we show that the resulting computational unit is equivalent to a perceptron with a much smaller number of parameters than the perceptron . in particular , we show that for a large class of nonlinear units , neural circuits with a small number of weights can be represented by a quadratic function of the input variables . in particular , we show that for a large class of neural circuits with a small number of weights , neural circuits with a small number of weights can be implemented by a multi-layer perceptron with a small number of weights . in addition , we show that for a large class of neural networks with positive weights , neural circuits with a small number of weights can be implemented using microcircuits with a small number of weights . we also show that for a large class of nonlinear units , neural circuits with a small number of weights can be implemented with a small number of weights .
the predicate calculus is a full first order predicate calculus which has been widely used in many applications . in this paper , we propose a new classifier for the predicate calculus , which is based on the concept of subsumption computations . the classifier consists of dual representations , auto-soand auto-sothe dual representations . the classifier is based on the concept of cardinality , equality , scalar inequalities , and predicate variables . we show that the classifier is competitive with the description classifier , and that the classifier is competitive with the state of the art .
information extraction -lrb- ie -rrb- is the task of extracting information from text documents . most ie domains rely on newswire articles , which are expensive to acquire . in this paper , we present two learners for information extraction , namely , rote memorization , term-space text classiication , and relational rule induction . the first learners learn to extract information from texts , and then uses regression models to predict the probability of cor-rectness of a given document . the second learners learn to predict the probability of cor-rectness of a given set of pre-deened structured summaries . the third learner learns to predict the probability of cor-rectness of a given document . the third learner learns to predict the probability of cor-rectness of a document given its pre-deened structured summaries . we evaluate the performance of the two learners on two well-known ie domains : the web pages and the electronic bulletin board posts . our experiments show that the proposed learners significantly improve the extraction accuracy compared to the previous mul-tistrategy approaches , and that the latter uses a multistrat-egy approach .
in this paper , we propose an interactive tone mapping scheme for hdr video sequences . in our interactive tone mapping scheme , a scrib-ble/stroke based interface is adopted to preserve user input information in the hdr video sequence . first , a gaussian mixture model - based interactive tone mapping scheme is adopted to capture the local tone manipulation in the hdr video sequence . then , a scrib-ble/stroke based interface is adopted to preserve the local tone manipulation in the hdr video sequence . finally , the user input information is further enhanced by the proposed interactive tone mapping scheme . the experimental results show that the proposed interactive tone mapping scheme can significantly improve the quality of hdr image tone mapping . moreover , the proposed interactive tone mapping scheme can also be applied to other hdr video sequences , which can be used for post-production .
cooperative communications using spatial diversity in a wireless network has been shown to improve the performance of cooperative communications . in this paper , a software defined radio testbed is presented . the software defined radio testbed consists of two cooperative physical layer protocols : cooperative systems and maximum ratio combining technique . cooperative coded systems are implemented using hard decision decoding . the base station is equipped with multiple relay nodes and the destination receiver is designed to minimize the bit error rate . the simulation results show that the average bit error rate of the three-node cooperative communication system is reduced by up to 25 % compared to that of the cooperative systems using hard decision decoding .
owl dl -lrb- owl dl -rrb- is a typed logical representation language that has been widely used in many applications . owl dl is a lexicon model that has been widely used in many applications . in this paper , we propose a new approach to owl dl , which is based on a graph structure of the lexicon model . we show that this approach can be used to build a syntactically and semantically annotated salsa/tiger corpus , and that it can be used for consistency control in owl dl . we also show that our approach can be applied to xml-based query languages , and that it can also be used for consistency control in owl dl .
in this paper , we propose a locally-constrained region based approach for segmenting fiber bundles in diffusion-weighted magnetic resonance images . the proposed locally-constrained region based approach consists of two steps : -lrb- 1 -rrb- finding a full fiber bundle region for each fiber bundle ; -lrb- 2 -rrb- finding the optimal fiber bundle for each pair of voxels , and -lrb- 3 -rrb- finding the optimal fiber bundle for each pair of voxels . -lrb- 3 -rrb- finding the optimal fiber bundle for each pair of voxels in each pair of fiber bundles for each pair of fiber bundles . -lrb- 3 -rrb- finding the optimal fiber bundle for each pair of voxels in each pair of fiber bundles for each pair of voxels in each pair is a computationally expensive task . -lrb- 3 -rrb- finding the optimal fiber bundle for each pair of voxels in each pair is a challenging problem due to the high computational speed and ease-of-use . experimental results show that the proposed locally-constrained region based approach outperforms the state-of-the-art methods in terms of both computational speed and ease-of-use .
online cursive handwriting recognition is one of the most challenging problems in pattern recognition . in this paper , we present a novel framework for the spotting and segmentation of cursive scripts based on adaptive probabilistic acyclic automata . the adaptive probabilistic acyclic automata is built on a set of control sequences , each of which has a compact representation of the writing trajectory and a level language model . the stochastic automata are learned by a learning algorithm , and the stochastic automata are learned by matching the writing trajectories to discrete motor control symbols . the adaptive probabilistic acyclic automata can be interpreted as a dynamic encoding of the control sequences , which allows for more intelligible components than the original dynamic encoding . we compare the training and recognition algorithms with the conventional modeling methods and show that the proposed modeling methods are superior to the training and recognition algorithms .
in this paper , we propose buffer-constrained r-d optimized rate control for video coding . in the proposed buffer-constrained r-d optimized rate control , the quantization parameter of the r-d optimized macroblock level rate control is designed to minimize the total number of nonzero coefficients frame level bit allocation . the r-d data generation and viterbi algorithm are adopted to reduce the computational complexity of the r-d optimization . fast heuristics for r-d data generation and viterbi algorithm are proposed to reduce the computational complexity of the r-d data generation . the simulation results show that the proposed quality feedback scheme can improve the coding performance of the h. 264 video quality . the proposed quality feedback scheme is also applied to progressive and interlaced video coding . the experimental results show that the proposed quality feedback scheme can achieve better coding performance than the h. 264 standard in terms of the coding performance . the proposed quality feedback scheme is also shown to be very efficient in terms of coding performance .
in this paper , we propose a novel temporal filter design for automatic speech recognition . the proposed temporal filter design uses lda filters to extract modulation-spectral features from contextual frames . the proposed temporal filter design uses two preprocessing configurations : cepstral mean subtraction , delta calculation and rasta filtering . the first temporal filter design uses lda filters to extract modulation-spectral features , and the second temporal filter design uses a trained probability estimator . we evaluate the proposed temporal filter design on a large vocabulary continuous speech recognition -lrb- lvcsr -rrb- task , and show that the proposed temporal filter design outperforms the baseline system in terms of robustness against reverberation conditions . in addition , the proposed temporal filter design is shown to improve the performance of the baseline system in terms of phone classification and word recognition tests .
in this paper , we propose a co-training to learn a classifier for reference resolution . in particular , we use a co-training to learn a classifier for the task of reference resolution . our experiments show that our co-training significantly improves the performance of manual labeling .
recurrent neural networks -lrb- recurrent neural networks -rrb- have been shown to be very effective for extracting pre-dictors from digital electroencephalography for eeg data recording . in this paper , we propose a novel training strategy for recurrent neural networks , which reduces the computational cost of the recurrent neural predictor . the proposed training strategy is compared with the conventional dpcm scheme for eeg data recording . the experimental results show that the proposed training strategy can significantly reduce the computational cost of the recurrent neural predictor .
voice search -lrb- asr -rrb- recognition is an important component of many speech applications . in this paper , we propose a novel co-occurrence based approach to automatic transcription for voice queries . in the proposed co-occurrence based approach , the spoken queries are first converted into a sequence of words , and then the co-occurrence information is used to measure the similarity between the query and the spoken queries . in the proposed co-occurrence based approach , the co-occurrence level and the scoring function are defined as the syntactic and grammatical structure of the spoken queries . the experimental results show that the proposed co-occurrence based approach is effective in improving the accuracy of automatic transcription for voice queries . moreover , the proposed co-occurrence based approach can reduce the number of keywords and improve the accuracy of voice queries automatic transcription . the proposed co-occurrence based approach is applied to spoken queries in the mobile web , and the experimental results show that the proposed co-occurrence based approach is effective in improving the accuracy of voice queries automatic transcription .
we consider the problem of value function approximation in markov decision processes . in particular , we consider the problem of approximating the value function with respect to an infinite action spaces , given a finite set of observations and a set of observations . we consider the problem of approximating the value function with respect to a given set of observations , and show that under certain conditions , the approximate solution can be obtained by minimizing the bellman equation of the bellman equation . in particular , we show that under the smoothness assumption , the approximate solution can be obtained by minimizing the sum of the squared error of the approximate solution . in particular , we show that under certain conditions , the approximate solution can be obtained by minimizing an upper bound on the regret of the approximation architecture . in particular , we show that under certain conditions , the approximate solution can be obtained by minimizing an upper bound on the regret of the approximate solution . in particular , we show that under certain conditions , the approximate solution can be obtained by minimizing an upper bound on the regret of the approximate solution . finally , we show that under certain conditions , the approximate solution can be obtained by minimizing the regret of the approximate solution . finally , we show that the robustness of the proposed approximation architecture to noise can be improved by exploiting real world transitions .
this paper presents a computer simulation for mixed-initiative dialogues . the computer simulation consists of two main components : a restricted initiative model for mixed-initiative dialogues , and a restricted initiative model for unrestricted initiative . the restricted initiative model is used to compare two models : a restricted initiative model for mixed-initiative dialogues , and a restricted initiative model for mixed-initiative dialogues . the experimental results show that the proposed computer simulation achieves better solution quality than the restricted initiative model .
matrix filters have been widely used for passive sonar and localiza-tion and detection problems . in this paper , we consider the problem of estimating the number of unwanted components in measured sensor data . in particular , we consider the problem of estimating the sensor outputs from the measured sensor data . we formulate the problem as a convex optimization problem and propose a linear filtering operation based on the solution of the problem . the matrix filters are designed to minimize the minimal distortion in the measured sensor data . we demonstrate the effectiveness of the proposed matrix filters for localiza-tion and detection problems .
this paper addresses the problem of interference suppression in mainbeam jamming and coherent multi-path for terrain scattered interference . monopulse processing consists of a space-time processing followed by a space-time processing followed by a space-time processing followed by a space-time monopulse processor . monopulse processing consists of a space-time processing followed by a space-time processing followed by an array pattern . monopulse and spatially adaptive monopulse dis-tortionless spatial array patterns are estimated . the performance of monopulse radars is evaluated in a coherent interference scenario . the results show that both monopulse and spatially adaptive monopulse jamming are capable of spatially adaptive processing in the presence of mainbeam jamming , target angle estimation and mainbeam jamming . the performance of the space-time monopulse processor is comparable to that of monopulse radars in the presence of mainbeam jamming .
personal use of this material is permitted . however , permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists , or to reuse any copyrighted component of this work in other works must be obtained from the ieee . abstract in this paper , we propose a novel method for the recognition of the 3d surface of human faces using 3d facial depth maps . the method is based on summation invariants . the 3d facial depth map is obtained from a rectangular region , and the 3d facial depth map is obtained from the 3d facial depth maps . the proposed method is evaluated on the v1 .0 dataset . the experimental results show that the proposed method can improve the recognition of the 3d surface of human faces by more than 10 % compared to the baseline method . moreover , the proposed method can also be used for other works , such as the v1 .0 dataset .
in this paper , we propose a spectral conversion method to improve the converted speech . in the former voice conversion system , straight spectrum is divided into excitation-dependent and excitation-independent components . in the former voice conversion system , the straight spectrum is converted into a set of excitation-dependent and excitation-independent components . in the former voice conversion system , the prosodic characteristics of the source speaker 's voice are converted to the target speaker 's voice . in the former voice conversion system , the prosodic characteristics of the target speaker 's voice are converted by the prosodic conversion based on the proposed spectral representation . in the latter voice conversion system , the prosodic characteristics of the target speaker 's voice are converted by the proposed spectral conversion method . in the proposed spectral conversion method , the prosodic characteristics of the target speaker 's voice are converted by the proposed spectral representation based on the conventional formalizations of codebook mapping . experimental results show that the proposed spectral conversion method can improve the discrimination and speech quality of the converted speech .
in this paper , we propose a method for assessing the compatibility of a color distribution from realistic and unrealistic images . our method is based on the idea of classifying composite images and recoloring image regions for realistic com-positing . the distributions of colors in natural images are modeled as distributions of colors . the proposed method is evaluated on a set of realistic and unrealistic images . the experimental results show that the proposed method outperforms the state-of-the-art methods .
in this paper , a block sparse excitation sequence is proposed to estimate the all-pole filter from a speech signal . the proposed block sparse excitation sequence is a weighted linear combination of the generalized input sequence and the model parameters are estimated by a linear prediction approach . the proposed block sparse excitation sequence is a weighted linear combination of the generalized input sequence and the corresponding all-pole filter is estimated using the expectation-maximization based procedure . the proposed block sparse excitation sequence is evaluated in a speech modeling task , where the speech signal is corrupted by white noise . the experimental results show that the proposed block sparse excitation sequence is more effective than the conventional sparse bayesian learning methods in the estimation procedure .
pronunciation learning for probabilistic lexical mod-eling has been shown to be effective in improving the performance of automatic speech recognition systems . in this paper , we propose a novel approach to pronunciation learning for probabilistic lexical mod-eling , which is based on a phoneme-based asr system with a grapheme-to-phoneme converter . in contrast to previous g2p converters , our approach does not require any training hand or any acoustic and lexical resources . instead , it does not require any training hand crafted pronunciations for the asr system development . instead , it does not require a phoneme-based pronunciation lexicon . therefore , we propose to use the grapheme-to-phoneme converter to learn pronunciations for a phoneme-based asr system . the proposed approach is evaluated on lexical resource constrained asr tasks , and compared with a state-of-the-art stage approach . the results show that the proposed approach can significantly improve the asr system performance .
this paper presents a game-theoretic model of political communication . the game-theoretic model models the observed linguistic behavior in terms of a game-theoretic model of political communication . the modeling discourse is based on game theory , and a game-theoretic model is designed to simulate the observed linguistic behavior of the game-theoretic model . the game-theoretic model has been implemented in a simulation study , and its performance is compared to that of other models . the results show that the proposed game-theoretic model is able to capture the political communication in the real world , and that game-theoretic model is able to capture the political communication in the real world .
background subtraction algorithms have been widely used to reduce the temporal variability of pixel intensities in environmental monitoring applications . however , most of the existing background subtraction algorithms ignore the temporal variation of point statistics and the spatial variation of region statistics . in this paper , we propose a novel background modeling and subtraction scheme , which explicitly models the tex-tured background as intensity or color distributions . the proposed background modeling and subtraction scheme is based on the assumption that the intensity or color distributions are independent of the processing power of the foreground objects . the proposed background modeling and subtraction scheme is able to capture the temporal variation of intensity , which is important in many monitoring applications . the proposed background modeling and subtraction scheme is evaluated on three generic low-level detection metrics and application-dependent criteria . the experimental results show that the proposed background modeling and subtraction scheme is superior to the state-of-the-art methods in detecting foreground objects .
model-based object tracking using raw captures is a challenging problem due to the lack of fast or unpredictable motion . in this paper , we present a novel approach to model-based object tracking using a set of depth cameras . our approach is based on the phase-based time-of-flight sensing , which is able to track fast-moving objects using only a single off-the-shelf depth camera . in contrast to previous approaches , our approach does not require any prior knowledge of the depth or the depth of the object . instead , it does not require any prior knowledge of the object or the depth of the object . instead , it does not require any prior knowledge of the object or the depth of the object , instead it does not require any prior knowledge of the object or the background . instead , it does not require any prior knowledge of the object or the camera , and it is able to track the object using only a single low frame-rate depth image . we demonstrate the effectiveness of our approach by comparing it to several state-of-the-art algorithms in terms of tracking accuracy , robustness to active illumination , and efficiency . we also show that our approach is able to track fast-moving objects using only a small number of consumer depth cameras .
decision making in neural networks is a challenging problem due to the large number of possible decision thresholds . in this paper , we present williams ' reinforce method , a learning rule for threshold learning in neural networks . williams ' reinforce method learns a two-factor reward-modulated learning rule for neural networks . williams ' reinforce method learns a reward function for threshold learning based on a gaussian process , and applies bayesian optimization to the reward function . williams ' reinforce method learns a reward function that is optimal with respect to the wald 's cost function . we show that williams ' reinforce method is able to learn optimal decision thresholds for a variety of tasks , including competitive stochastic evidence accumulation , and a drift-diffusion model . we also show that williams ' reinforce method can learn optimal decision thresholds for a variety of tasks . we also show that williams ' reinforce method can learn optimal decision thresholds for a variety of tasks , and that williams ' reinforce method can learn a two-factor reward-modulated learning rule for a variety of acquisition behaviour .
the problem of active control of acoustic signals from multiple input multiple output systems is considered . a steepest descent iterative algorithm is used to estimate the parameters of the acoustic eld from measured data , and the 1-norm minimisation algorithm is used to recover the uniform nal noise eld from the measured data . the performance of the steepest descent iterative algorithm is compared to the performance of the algorithm .
in this paper , we address the problem of recognizing and recognizing objects in arbitrary views of a smoothly moving camera . we propose a novel approach to recognize objects in arbitrary views based on 2d image information obtained by 3d reconstruction . the proposed approach is based on an exemplar-based hmm , where the image projections are represented by latent variables . during the recognition phase , a temporal markov dependency between the view parameters and the image projections is learned by the parameters of the exemplar-based hmm . during the recognition process , the latent variables are used to infer the relative orienta-tions of the objects in the scene . the proposed approach is evaluated on three real datasets and is shown to perform better than the state of the art in terms of recognition performance . furthermore , the proposed approach can be applied to other recognition scenarios where prior knowledge is not available .
in this paper , we consider the problem of source separation in the presence of indeterminacies , non-negative sources , and non-negative mixing coefficients . we show that the problem of source separation can be formulated as finding an optimal solution in the presence of ordering and scale ambiguities . in particular , we show that the problem of finding an optimal solution in the presence of inde-terminacies can be formulated as finding an optimal solution in the presence of scale ambiguities . in particular , we show that the problem of finding an optimal solution in the presence of indeterminacies can be formulated as finding an optimal solution in the presence of inde-terminacies .
in this paper , we propose a computational system of object categorization that combines multiple decomposed visual cues for object categorization . the multiple decomposed visual cues are combined with low level cues of contour to form a conditional random field for learning discrimina-tive cues . the multiple decomposed visual cues are combined to form a single conditional random field for object categorization . the multiple decomposed visual cues are then combined to form a set of single-layer random fields for model learning . experimental results on natural images show that the proposed computational system is able to effectively combine multiple decomposed visual cues for object categorization .
the primary goal of this work is to develop a network model of complex cell responses , based on recurrent cortical circuitry . the network model is based on the assumption that the output of the network is a recurrent amplification of feedforward input , and that the output of the network model depends on the output of the recurrent cortical circuitry . the network model is based on the assumption that the output of the network model is a function of the input and the output of the network model . the primary goal of this paper is to show that the output of the network model is a function of the output of the network model and the output of the network model in terms of the amplification of the output of the network model . the network model is based on the assumption that the output of the network model is a function of the output of the network model and the output of the network model . we show that the network model can be used to generate complex cell responses in a visual processing pathway , and that the output of the network model is a function of the output of the network model .
multi-armed bandits -lrb- multi-armed bandits -rrb- are a popular monte-carlo tree search algorithms for sequential decision problems . in this paper , we introduce discriminative bucketing , a family of non-interruptible strategies that are guaranteed to have a conservative uniform sampling . we show that discriminative bucketing can be viewed as a generalization of multi-armed bandits to the interruptible setting , and that discriminative bucketing can be viewed as a special case of conservative uniform sampling . we also show that discriminative bucketing can be viewed as a special case of multi-armed bandits . finally , we show that discriminative bucketing can be viewed as a special case of multi-armed bandits , and that discriminative bucketing can be viewed as a special case of the interruptible setting .
in this paper , we propose flexible semiparametric models of gaze control in which the aggregate features of eye movements are modeled as a parametric distribution family . the proposed flexible semiparametric models are able to capture the characteristic gaze patterns of a user 's eye , which are modeled by a gaussian process . the proposed flexible semiparametric models can be used to infer the location and location of the reader 's eye movements . we demonstrate the effectiveness of the proposed flexible semiparametric models on two tasks : word fixation durations and saccade amplitudes . the experimental results show that the proposed flexible semiparametric models are effective in identifying the location and location of the reader 's eye movements .
in this paper , we propose a bilingual lexical cohesion trigger model to capture lexical cohesion for document-level machine translation . the bilingual lexical cohesion trigger model is a generalization of the bilingual lexical cohesion trigger model to hierarchical phrase-based machine translation . experimental results on nist chinese-english test sets show that our bilingual lexical cohesion trigger model can significantly improve the translation performance of document-level machine translation .
in this paper , we propose an unsupervised approach to the sequential organization of speech . in contrast to model-based methods that rely on pretrained speaker models , our unsupervised approach is able to segregate unvoiced speech from segregated voiced speech . in contrast to previous model-based methods , our unsupervised approach does not require any prior knowledge of the number of speakers or the number of speakers . instead , we assume that the number of speakers is unknown and the number of speakers is unknown . the proposed unsupervised approach consists of two stages : -lrb- 1 -rrb- a set of time-frequency segments is extracted from each time-frequency segment , and -lrb- 2 -rrb- a set of cepstral features is extracted from each time-frequency segment . -lrb- 3 -rrb- an onand offset based analysis is used to determine the number of time-frequency segments and the number of within-group concurrent pitches in each segment . experimental results show that the proposed unsupervised approach outperforms the conventional model-based method in terms of speech segregation .
context decision trees -lrb- context decision trees -rrb- have been widely used in the speech recognition community . in this paper , we propose to use context decision trees to improve the performance of the speech recognition community . in particular , we propose to use context decision trees to represent the modality questions in a spoken utterance . we show that the use of context decision trees leads to significant reductions in the speaking rate . furthermore , we show that the use of context decision trees in combination with the speaking rate leads to significant reductions in the speaker 's dialect .
in this paper , we propose a novel classification algorithm based on symmetric maximized minimal distance . the novelty of the proposed classification algorithm lies in the fact that the feature space of a test sample is a symmetric maximized minimal distance , i.e. , the distance between the test sample and the test sample is bounded by the distance between the test sample and the test sample . in the proposed classification algorithm , the test sample is classified into two classes : -lrb- 1 -rrb- the distance between the test sample and the test sample is measured by the distance between the test sample and the test sample , and -lrb- 2 -rrb- the distance between the test sample and the test sample is measured by the distance between the test sample and the test sample . the optimality of the proposed classification algorithm is evaluated by comparing the proposed classification algorithm with support vector machines -lrb- smms -rrb- . the experimental results show that the proposed classification algorithm is effective in face authentication , especially when the imposter samples are not available .
this paper presents a study on the identification ability of french -lrb- native speakers -rrb- in a contextual environment , such as sport commentary speech , political speech , and sport commentary speech . the aim of this study is to investigate the perceptual similarity between the two discourse genres in french -lrb- native speakers -rrb- and french -lrb- native speakers -rrb- . the results show that the prosodic cues of the two genres are important for speaking style speech synthesis , and that the prosodic cues of the two genres differ in their perceptual similarity between the two genres . the results also show that the identification ability of the two discourse genres depends on the type of language .
in this paper , we propose a voice conversion technique based on deep belief nets . in the proposed voice conversion technique , speaker individuality abstractions are represented by neural networks , and the inverse process of the neural networks is transformed into high-order eigen spaces . in the proposed voice conversion technique , a deep architecture is adopted to map the phonologi-cal information in the cepstrum space to high-order eigen spaces . in the proposed voice conversion technique , a deep architecture is adopted to map the patterns of the abstractions in the cepstrum space . the experimental results show that the proposed voice conversion technique outperforms the gaussian mixture model-based method in terms of both subjective and objective criteria .
in this paper , we propose a bayesian approach to the distribution determination technique for hmm-based speech recognition . the distribution determination technique is a statistical technique for estimating the predictive distributions of the model structure . the distribution determination technique uses cross validation to estimate the model parameters for speech recognition . the prior distribution determination technique is based on the assumption that the prior distributions of the model parameters are known to be independent of the model structure . in order to estimate the model parameters for model selection and posterior distributions , we propose an approximate version of the prior distribution determination technique . in the proposed bayesian approach , the prior distribution determination technique is used to estimate the model parameters for speech recognition . in the proposed variational bayesian method , the prior distribution determination technique is used to estimate the predictive distributions of the model structure . the experimental results show that the proposed variational bayesian method can achieve better speech recognition performance than the conventional variational bayesian method .
gaussian mixtures are commonly used in observation probability density functions in hmm-based speech recognition systems . in this paper , we propose a novel approach to learning factored sparse inverse covariance matrices , where the inverse covariance matrix is represented by a set of linear regressive coefficients . the proposed approach is based on the observation probability density functions of factored sparse inverse covariance gaussians , where the covariance matrices of the full-covariance gaussians are learned by minimizing the conditional independence properties of the inverse covariance matrices . we derive non-linear em update equations for the proposed approach . the experimental results show that the proposed approach is able to learn sparse patterns in real time . furthermore , it is shown that the proposed approach is able to learn sparse patterns in real time .
in this paper , we propose a novel subspace projection technique for wall clutter mitigation in compressed sensing , which is a single-signal compressed sensing model . the proposed subspace projection technique is based on a joint bayesian sparse approximation framework , where the sparsity of the antenna signal is exploited to improve the reconstruction accuracy of high-quality images . the proposed subspace projection technique is motivated by the observation that the signal sparsity of the received signal lies in the same antenna location , and the sparsity of the received signal is exploited to improve the reconstruction accuracy . the proposed subspace projection technique is applied to wall clutter mitigation in compressed sensing , where the sparse signal recovery is performed by a sparsifying wavelet dictionary . the experimental results show that the proposed subspace projection technique is effective for image formation .
in this paper , we propose a novel plda-based acoustic model based on prob-abilistic linear discriminant analysis . the plda-based acoustic model uses two dimensional acoustic features to capture intra-frame feature correlations . the first plda-based acoustic model uses a deep neural network to extract bottleneck features from a large vocabulary conversational telephone speech corpus . the second plda-based acoustic model uses gaussian mixture models and mixture models to combine the two dimensional acoustic features . the third plda-based acoustic model uses a deep neural network to combine the two dimensional acoustic features . we compare the proposed plda-based acoustic model with plda , hybrid deep neural networks , subspace gmms , and plda . the proposed plda-based acoustic model is evaluated on the switchboard dataset and achieves a word error reduction of 11.5 % on the switchboard dataset .
in this paper , we address the problem of anomaly detection setting in complex videos , where the training data and early context assumptions are unknown . we propose a classical density estimation approach to tackle the anomaly detection setting , where the temporal ordering of anomalies is unknown . the key idea of our classical density estimation approach is to use discriminative learning with classical density estimation to estimate the probability of anomalies in a video . the proposed classical density estimation approach is based on the assumption that the training sequences have been corrupted by low-probability events , and can be used to estimate the probability of anomalies in a video . we demonstrate the effectiveness of our classical density estimation approach in a challenging anomaly detection setting , where the number of anomalies is very large and the number of training sequences is very large .
this paper presents a pairwise neural network architecture for the answer ranking problem in community forums . the pairwise neural network architecture uses lexical matching , syntactic and semantic embeddings , domain-specific features , and lexical similarity features . the pairwise neural network architecture makes use of multiple feature types to represent the input components of the pairwise neural network architecture . the pairwise neural network architecture makes use of multiple types of relatedness between the input components and the output of the pairwise neural network architecture . we evaluate the proposed pairwise neural network architecture on the task of answer ranking problem in community forums . the results show that the proposed pairwise neural network architecture achieves better performance than the state-of-the-art methods .
finite-state modeling techniques have been successfully applied to language modeling in automatic speech recognition systems . in this paper , we present written-domain language modeling approaches to language modeling in the verbal domain , where lexical and non-lexical entities are expressed in the written domain . our written-domain language modeling approaches is based on a newly proposed formalal-domain language model , which is designed to deal with data sparsity problems in the written domain . the proposed written-domain language modeling approaches is based on a novel decomposition -- recomposition approach to deal with out-of-vocabulary and non-lexical entities such as dollar amounts , phone numbers , and e-mail addresses . the proposed written-domain language modeling approaches is evaluated in terms of speech recognition performance and asr transcript rendering accuracy . the results show that the proposed written-domain language modeling approaches is effective in improving speech recognition performance in the written domain , and that the proposed written-domain language modeling approaches can also be applied to other domains , such as en-glish .
in this paper , we consider the extraction of camera matrices from a single image . we propose a non-iterative linear algorithm and iterative algorithms to compute the algebraic error . the non-iterative linear algorithm is based on the concept of algebraic , and non-iterative linear algorithm is applied to the problem of projective scene reconstruction . the iterative methods are tested on synthetic data and the results show that the proposed non-iterative linear algorithm outperforms the existing methods in terms of accuracy and stability .
in this paper , we propose a sparsity-based spatial spectrum estimation technique using co-prime arrays for direction-of-arrival estimation . the proposed sparsity-based spatial spectrum estimation technique exploits the co-prime array structure of the co-array aperture to estimate the direction-of-arrival of a virtual aperture . the proposed sparsity-based spatial spectrum estimation technique exploits the co-prime array structure of the co-array aperture to improve the doa estimation performance . simulation results show that the proposed sparsity-based spatial spectrum estimation technique can significantly improve the doa estimation performance .
in this paper , we propose a bayesian model averaging over feature selection , which is a generalization of naive bayes globally optimal feature subset . the proposed bayesian model is a generalization of the naive bayes globally optimal feature subset , and can be used as a classifier for a wide range of feature selection methods . we show that the proposed bayesian model is superior to bma and other popular classifiers such as svms . in addition , we show that the proposed feature selection can be viewed as a special case of the proposed bayesian model , and that feature selection can be viewed as a special case of the proposed bayesian model . furthermore , we show that the proposed feature selection can be viewed as a special case of the bma-nb classifier , and that the proposed feature selection can be viewed as a special case of the proposed bayesian model . moreover , we show that the proposed feature selection can be viewed as a special case of the proposed bayesian model , and that feature selection can be viewed as a special case of the proposed bayesian model . finally , we show that the proposed feature selection can be implemented efficiently using the proposed bayesian model . finally , we show that the proposed feature selection method can be applied to other predictor models .
voice morphing is the process of producing high spectral variance of unvoiced sounds . in this paper , we propose a voice morphing system to synthesize high quality voice morphing . the voice morphing system is based on a linear transformation for voice morphing . the prosody is generated by pitch scaling , spectral envelope , and phase incoherence . the quality of the voice morphing system is evaluated by listening tests . the results show that the proposed voice morphing system can generate high quality voice morphing with high quality , high quality , and speaker identification scores . the proposed voice morphing system can generate high quality voice morphing with high quality , high quality , and high quality audio quality .
in this paper , we present a mathematical framework to detect occlusions in deforming scenes . the mathematical framework is based on matching and spatio-temporal derivatives , which are invariant to occlusions in the 3d structure of man-made and natural scenes . a deforming 3d scene is represented by a set of well-defined local rec-ogni-cal invariants , which are invariant to occlusions . the mathematical representation of the image sequences of natural scenes is used to define an occlusion detector , which is invariant to color variation , and is invariant to occlusions . the proposed mathematical framework is able to detect occlusions in deforming scenes with bounded deformations , i.e. , deforming cloth and hand motions with zero false positive rate . the proposed mathematical framework is applied to detect occlusions in deforming scenes . the experimental results show that the proposed mathematical framework can accurately detect occlusions in deforming scenes .
in this paper , we propose a new approach to lm adaptation based on the k-means algorithm for text classification . the background lm is estimated by linear interpolation of the background lm and the domain lms . the background lm and the domain lms are then adapted by the k-means algorithm for text classification . the experimental results show that the proposed approach can achieve relative word error rate reductions of up to 30 % over the pruned background lm .
we consider the problem of learning control policies based on trajectory preference queries . we assume that the rewards are generated by a bayesian model of the target policy , and assume that the target policy is generated by a querying process . we assume that the target policy is generated by a latent target policy , and that the target policy is generated by a bayesian model of the target policy . we show that active query selection performs better than random selection , and that active query selection improves upon random selection .
in this paper , we present a new program generation system spiral based on the pruned fft algorithm . the program generation system spiral is based on kronecker product notation and uses the structure of the fft to reduce the problem size . we show that the pruned fft algorithm can be used to implement the program generation system spiral . we show that the structure of the program generation system spiral can be used to generate fft implementations with unused inputs , and that the structure of the program generation system spiral can be used to speed up the computation of the pruned fft algorithm . we present experimental results that show that the pruned fft algorithm can be used to speed up the program generation system spiral , and that the performance of the pruned fft algorithm is comparable to that of the original program generation system spiral . we also show that the performance of the pruned fft algorithm is comparable to that of the original program generation system spiral in terms of problem size , and that the performance of the pruned fft algorithm is comparable to that of the original algorithm . finally , we show that the performance of the pruned fft algorithm is comparable to that of the original program generation system spiral in terms of problem size .
supertag information is an important factor in the dependency parser of german . in this paper , we present a novel approach to incorporating supertag information into the dependency parser of german . our approach is based on a decision process that takes into account weighted constraints between supertags and supertags . experiments show that our approach improves the parsing accuracy by up to 1.4 % . we also show that our approach improves the accuracy of the models of su-pertags .
intent prediction -lrb- intent prediction -rrb- and slot detection are two important slu tasks . in this paper , we consider the task of intent prediction in discourse , where the goal is to predict the intent of an utterance given its context . we formulate intent prediction as a sequential tagging problem , where the goal is to predict the intent of an utterance given its intra-session utterances . we propose a novel svm feature , which is based on the observation that the predicted per-utterance is likely to have the same context . we show that the proposed svm feature can be used to predict the intent of an utterance given its context . in addition , we show that the proposed svm feature can be used to predict the intent of an utterance given its context . in addition , we show that the proposed svm feature can be used to predict the intent of an utterance given its context . in addition , we show that the proposed svm feature can be used to predict the intent of an utterance given its context , and that the proposed svm feature can be used to predict the intent of an utterance given its context . our experiments show that the proposed svm feature can reduce the error rate reductions of the slot detection and intent prediction significantly , especially when the amount of training data is limited .
in this paper , we propose a novel approach to factoid annotation based on the analysis of shared atomic information units . the proposed approach is based on a weighted factoid score for stable system rankings . the weighted factoid score is then used to measure the similarity between words in a system summary and a set of string similarity . the proposed approach is evaluated on a set of datasets and compared against two state of the art systems : unigrams and the duc information overlap measure . the results show that the proposed approach achieves better performance than the state of the art in intrinsic summary evaluation .
in this paper , we present a study on the '' information synthesis '' task , where the task is to predict whether two sentences belong to the same event or not . we define a '' information synthesis testbed '' , where the task is to predict whether two sentences belong to the same event or not . we show that this '' information synthesis '' task is related to n-gram overlap , such as sentence overlap , and that it is related to similarity metrics between words . we also show that the '' information synthesis testbed '' can be used to predict whether two sentences belong to the same event or not .
in this paper , we present a '' brute-force '' approach to 3d object recognition datasets . we use a forward synthesis model to generate visual templates that are invariant to the geometric interpretations of the world . the forward synthesis model is trained on a set of invariant features that capture measured visual evidence . the forward synthesis model is then used to generate candidate reconstructions . the forward synthesis model is then used to generate a set of visual templates for inverse estimation . inference in the forward synthesis model is performed on the basis of a set of candidate reconstructions , which are then used to guide the generation of candidate reconstructions . we demonstrate the effectiveness of the proposed '' brute-force '' approach on several challenging 3d object recognition datasets .
we present a domain-independent binary classifier that learns to predict the asr hypothesis for a test domain . the domain-independent binary classifier is trained on a large set of training data , and is then used to train a single-classifier . the domain-independent binary classifier is shown to outperform both cluster-specific classifiers and cluster-specific classifiers in terms of cluster purity and normalized mutual information . the domain-independent binary classifier is also shown to be very effective when training data is scarce for across-domain clusters . the domain-independent binary classifier is also shown to be very effective when training data is scarce for the cluster-specific classifiers .
in this paper , we propose a novel approach to visual speech synthesis based on the idea that the atomic units of speech can be synthesized with the audiovisual coherence of the synthetic speech . the proposed approach is based on the idea that the audiovisual coherence of the synthetic speech can be used for synthesis optimization . the proposed method is based on the idea that the visual speech information of the synthetic speech can be represented by a many-to-one -lrb- standardized -rrb- mapping . the proposed method is evaluated on mpeg-4 , and the results show that the proposed method can achieve better perceived synthesis quality than the state-of-the-art phoneme-based and the audiovisual speech synthesis techniques .
in text-to speech systems , it is important to understand how stress affects the quality of prosody prediction . in this paper , we propose a method for identifying stress marking in catalan text-to-speech conversion based on linguistically rule-based automatic algorithms such as word stress marker , orthographic syllabification algorithm , and phonological syllabification algorithm . the basic idea of our method is to use grapheme-to-phoneme conversion rules to determine whether a syllable is a syllable or a syllable . the basic idea of our method is to use the stress marker algorithm and the orthographic syllabification algorithm to determine whether a syllable is a syllable or a syllable . the results show that the proposed method is able to distinguish between syllables and syllables with high word accuracy rates , and that the synthetic intelligibility of catalan text-to-speech conversion can be improved by using the proposed method .
in this paper , we present a method for automatically retrieved commonsense utterances based on common knowledge about the user 's behavior . the method is based on random text-mining , and uses a word-spotting method to retrieve keywords from the output of a holistic system . the holistic system consists of two steps : -lrb- 1 -rrb- commonsense processing and affective computing , and -lrb- 2 -rrb- affective computing . the holistic system consists of two steps : -lrb- 1 -rrb- extracting information from the output of the holistic system ; -lrb- 3 -rrb- extracting information from the output of the holistic system ; -lrb- 3 -rrb- extracting information from the output of the holistic system ; -lrb- 3 -rrb- extracting information from the output of the holistic system ; -lrb- 3 -rrb- extracting information from the output of the holistic system ; -lrb- 3 -rrb- extracting information from the output of the holistic system ; -lrb- 4 -rrb- extracting information from the output of the holistic system ; -lrb- 4 -rrb- extracting information from the output of the holistic system ; -lrb- 4 -rrb- extracting information from the output of the holistic system ; -lrb- 4 -rrb- extracting information from the output of the holistic system ; -lrb- 4 -rrb- extracting information from the output of the holistic system ; -lrb- 4 -rrb- extracting information from the output of the holistic system ; -lrb- 4 -rrb- extracting information from the output of the holistic system ; -lrb- 4 -rrb- extracting information from the output of the holistic system ; -lrb- 4 -rrb- extracting information from the output from the output of the holistic system ; -lrb- 4 -rrb- extracting information from the output of the user 's behavior ; -lrb- 4 -rrb- extracting information from the output from the output of the holistic system .
in this paper , we propose a novel elliptical arc detector . the detected elliptical features are extracted by a non-iterative ellipse fitting technique . the accuracy of the proposed elliptical arc detector is evaluated by comparing the speed of the line segment and the gradient orientation of the detected elliptical features with that of the conventional line segment . the proposed elliptical arc detector is evaluated on both natural images and computer-generated images . the experimental results show that the proposed elliptical arc detector outperforms the conventional line segment and the elliptical arc detector in terms of parameter tuning .
in this paper , we present a closed form solution for tracking non-rigid objects with dramatic appearance changes . the proposed closed form solution is based on the spatial-appearance model , which is a generalization of the maximum likelihood matching criterion . the proposed closed form solution is based on the spatial-appearance model , which has two main advantages : -lrb- 1 -rrb- the matching criterion for image regions is invariant to dramatic appearance changes ; -lrb- 2 -rrb- the matching criterion is invariant to local appearances variations and global spatial structures ; -lrb- 3 -rrb- the matching criterion is invariant to changes in appearance changes ; -lrb- 3 -rrb- the matching criterion is invariant to local non-rigidity ; -lrb- 3 -rrb- the matching criterion is robust to changes in appearance changes ; and -lrb- 3 -rrb- the matching criterion is robust to changes in appearance changes . the proposed closed form solution is applied to tracking non-rigid objects with dramatic appearance deformations , large object scale changes , and partial occlusions . the proposed closed form solution is applied to the recovery of all motion parameters , and the experimental results show that the proposed closed form solution is robust to appearance variations .
voip is one of the most important applications in internet telephony . voip is a digital mobile system . in this paper , a wavelet based bark coherence function is proposed for variable delay . wavelet based bark coherence function is a cognition module , which consists of the bark coherence function and the loudness speech . wavelet series expansion is used to measure the similarity coefficients of the bark coherence function . wavelet based bark coherence function is used to measure the variable delay . wavelet based bark coherence function is compared with the psqm . the experimental results show that the proposed wavelet based bark coherence function is more robust to linear distortions than the conventional psqm . the time synchronization is also achieved using voip speech data .
in this paper , we present a novel approach to constructing long-range language models using log-linear interpolation . in contrast to previous grammar-based approaches , our approach does not require a smoothed 4-gram language model . instead , we use log-linear interpolation to generate long-range language models . we evaluate our approach on a medium-sized vocabulary wall street journal task and show that our model combinations outperform distance word and class models on the penn treebank . furthermore , we show that log-linear interpolation can be used to improve the performance of rescoring word lattices .
this paper describes the development of a large vocabulary speech recognition system for broadcast news transcription . the large vocabulary speech recognition system is designed for both clean and noisy read speech tasks . unsupervised model adaptation is performed using maximum likelihood linear regression , and maximum likelihood linear regression is used to adapt the parameters of the htk large vocabulary systems with various features such as decoder-guided segmentation , segment clustering , and language modelling . the resulting large vocabulary speech recognition system is evaluated on the h4 evaluation . the results show that the proposed large vocabulary speech recognition system is very competitive with the state of the art in both clean and noisy read speech tasks . dierent front-end analyses of the large vocabulary speech recognition system are also presented .
in this paper , we propose a two-step fast algorithm to minimize the power consumption of multiuser video transmission over cdma cell . the proposed two-step fast algorithm consists of two steps : signal processing , transmitter power , and video compression complexity . the first step is to reduce the computation burden while the second step is to reduce the complexity of the full search . the second step uses a two-step fast algorithm to reduce the complexity of the transmitter power ¡ . simulation results show that the proposed two-step fast algorithm is capable of reducing the power consumption of the cdma cell while maintaining the same quality as the full search .
co-clustering is the problem of finding a small number of clusters in a given dataset . in this paper , we propose a novel proximal alternating linearized minimization algorithm for co-clustering . the proposed proximal alternating linearized minimization algorithm aims at finding a set of hypothesized clusters , each of which is a sparse row of the original dataset . the proposed proximal alternating linearized minimization algorithm is a proximal alternating linearized minimization algorithm that aims at finding a small number of clusters in the dataset . the proposed proximal alternating linearized minimization algorithm is evaluated on benchmark datasets and compared with several state-of-the-art multi-view co-clustering methods . the experimental results show that the proposed proximal alternating linearized minimization algorithm significantly outperforms the state-of-the-art methods . moreover , proximal alternating linearized minimization algorithm is much faster than the state-of-the-art methods in terms of both efficiency and efficiency .
in this paper , we address the problem of model-free markerless motion capture of articulated kinematic structures in volume sequences . we propose a kinematic model to represent the volume sequence as a collection of skeleton curves . the kinematic model is composed of two parts : -lrb- i -rrb- a skeleton curve , -lrb- ii -rrb- a skeleton curve , and -lrb- iii -rrb- an arbitrary kinematic topology for synthetically generated volume sequences . -lrb- iii -rrb- a skeleton curve is defined as the sum of nonlinear axes of the captured volume sequence , and -lrb- iv -rrb- a skeleton curve is defined as the sum of the joint angles of the kinematic postures . the proposed kinematic model is applied to human volume sequences . experimental results show that the proposed kinematic model is able to capture the motion sequence with high accuracy .
introduction in natural language understanding , speech acts play an important role in natural language generation . in this paper , we present a method for incorporating socio-pragmatic knowledge into the parse of a sentence to guide the generation of a sentence . the method is based on a parser and a domain independent grammar , and uses pragmatic knowledge to guide the search space . in contrast to previous work , our method does not require syntactic knowledge . instead , it does not require explicit syntactic knowledge about the meaning of a sentence , and it does not require any prior knowledge about the meaning of a sentence . we show that our method can significantly improve the performance of a parser trained with pragmatic knowledge .
we introduce the ying-yang machine , a bayesian-kullback learning scheme for analyzing major supervised and unsu-pervised learnings , such as least square learning , maximum information preservation , em & em algorithm , geometry , and helmholtz machine . the ying-yang machine is a generalization of the ying-yang machine , which is a bayesian-kullback learning scheme for learning the joint density , kullback divergence , and a set of bayesian representations for the joint density and the kullback divergence .
in this paper , we propose a suboptimal hiding algorithm for binary data with low complexity -lrb- wae -rrb- . the proposed suboptimal hiding algorithm is based on weight approximation embedding of the parity check matrix of the target vector . the proposed suboptimal hiding algorithm is based on the embedding procedure of the parity check matrix of the linear embedding code . the embedding complexity of the proposed suboptimal hiding algorithm is independent of the embedding distortion and is independent of the embedding complexity of the target vector . the proposed suboptimal hiding algorithm can be applied to any binary embedding with low complexity -lrb- wae -rrb- . the proposed suboptimal hiding algorithm can be applied to any binary data with low complexity . simulation results show that the proposed suboptimal hiding algorithm can achieve better embedding performance than the existing algorithms in terms of embedding complexity .
in this paper , we present a data-driven method for the problem of content selection in the atis domain . our data-driven method is based on the observation that non-linguistic input can be represented by a set of local and global features , and a hyper-graph structure is extracted from a corpus of database records . a probabilistic context-free grammar is generated by a weighted hypergraph , and a decoding algorithm is used for scoring derivation . we evaluate our data-driven method on a corpus of database records from the atis domain , and show that our data-driven method outperforms a state-of-the-art discriminative system in terms of bleu and judgment elicitation study .
in this paper , we propose a layered self-adjusting decoding graph , which is a general re-entrant decoding network with a scaolding layer for fast network expansion . the scaolding layer is composed of two parts : 1 -rrb- dynamic decoding of the decoder , 2 -rrb- dynamic decoding of the decoder , and 3 -rrb- dynamic decoding of the decoder . in order to improve the self-adjusting capability of the decoder , we propose a two level hashing structure . the experimental results show that the ecient decoding can reduce the recognition resources by up to 30 % .
track-and-hold circuits are important for high-speed high-resolution analog-to-digital converters . in this paper , we propose a digital post compensation method to compensate for the errors caused by sampling instant error in the adc . the proposed digital post compensation method is based on an energy-free method for the background calibration configuration . the proposed digital post compensation method does not require any knowledge of the input signal or the nonlinear behavior of the adc . therefore , the proposed digital post compensation method does not require any knowledge of the sampling instant error . the proposed digital post compensation method is evaluated on a nonlinear th model of the adc and the experimental results show that the proposed digital post compensation method is effective in reducing the spurious free dynamic range of the input signal . moreover , the proposed digital post compensation method can reduce the spurious free dynamic range by more than 30 % compared with the conventional methods .
belief revision is a widely used belief revision strategy for theory bases . in this paper , we extend the agm paradigm to handle belief revision systems . we introduce a new belief revision strategy , namely , the standard belief revision module and the anytime decision procedure . the new belief revision strategy combines the belief revision module and the anytime decision procedure . we show that the new belief revision strategy has the same complexity as the standard agm paradigm for belief revision systems , but with minimal change . we also show that the new belief revision strategy has the following advantages : -lrb- i -rrb- the new belief revision strategy has the following benefits : -lrb- ii -rrb- the new belief revision strategy has the following advantages : -lrb- i -rrb- the new belief revision strategy can be extended to new theory bases , -lrb- ii -rrb- the new belief revision strategy can be extended to new theory bases , and -lrb- iii -rrb- the new belief revision strategy can be extended to new theory bases . -lrb- iii -rrb- the new belief revision strategy has the following benefits : -lrb- i -rrb- the new belief revision strategy can be extended to new theory bases , -lrb- iii -rrb- the new belief revision strategy can be extended to new theory bases , and -lrb- iii -rrb- the new belief revision strategy can be extended to new theory bases . -lrb- iv -rrb- the new belief revision strategy has the following benefits : -lrb- i -rrb- the new belief revision strategy can be extended to new theory bases with minimal change , and -lrb- iii -rrb- the new belief revision architectures can be extended to new ones . -lrb- iii -rrb- the new belief revision strategy can also be extended with standard guidelines for belief revision . -lrb- iv -rrb- the new belief revision strategy is implemented in the cin project .
motion search for video sequences is a challenging problem . in this paper , we propose a novel method for r-d optimal motion search in video sequences . the proposed method is based on channel optimal mode selection and uses a lagrange multiplier to find the optimal mode for each video sequence . we show that the proposed method outperforms the nominal method in terms of both distortion rate and constant bit rate .
computing semantic equivalence and syntactic substitutability is an important task in many natural language processing tasks . in this paper , we propose a novel approach to computing the syntactic variants of predicate phrases . our approach is based on a large-scale knowledge-base of paraphrases , which are automatically extracted from web snippets . we formulate the data sparseness problem as a data sparseness problem based on web snippets , which can be efficiently solved by distributional similarity measures . experimental results show that our approach can significantly improve the performance of existing methods .
we consider the problem of sparse recovery of signals in the presence of linear constraints . we consider the problem of learning a nearest neighbor from a set of stored vectors , where each entry corresponds to a super-polynomial or exponential number of n-length vectors . the nearest neighbor is formulated as a sparse recovery problem , where the number of stored vectors is proportional to the near-linear number of coordinates , and the number of stored vectors is proportional to the dimension of the vector . we propose an iterative algorithm to solve this problem . the iterative algorithm is based on the assumption that the structure of the vector can be represented by a small number of linear constraints . we prove that the proposed algorithm converges to the optimal solution of the sparse recovery problem for a wide class of binary -lrb- or q-ary -rrb- <s> <s> <s> we show that the proposed algorithm converges to the optimal solution in o -lrb- n log -lrb- n -rrb- -rrb- , where n is the number of dimensions of the vector and n is the dimension of the vector . we demonstrate the effectiveness of the proposed algorithm by applying it to the problem of learning generic random models for the super-polynomial or exponential number of n-length vectors .
in this paper , we propose a class-based variable memory length markov model based on a class-based probabilistic suffix tree . the class-based variable memory length markov model is a generalization of the word-based variable memory length markov model in which nodes are represented by a word-class relation . the class-based variable memory length markov model can be seen as a generalization of the word-based tri-gram model to a variable memory length markov model . the class-based variable memory length markov model can be seen as a special case of the class-based probabilistic suffix tree and can be seen as a special case of the learning algorithm . the class-based variable memory length markov model can be seen as a special case of the class-based probabilistic suffix tree and can be seen as a special case of the class-based variable memory length markov model . the experimental results show that the class-based variable memory length markov model can achieve better performance than the word-based bi-gram model .
ambiguity plane features are commonly used in dynamic statistical models for classification problems . in this paper , we present a novel approach to modeling uncertainty in sparsely labeled training data using explicit modeling of long-term context . the approach is based on a hidden markov model state , where the hidden markov model state corresponds to the shorter-term context of ambiguity plane features . we show how to use ambiguity plane features to improve the performance of dynamic statistical models in classification problems . we demonstrate the effectiveness of our approach by comparing it to static classification techniques . we also show that it is possible to improve the performance of acoustically monitoring cutter and that it is possible to improve the performance of static classification techniques .
acoustic units concatenation-based systems for text-to-speech synthesis are often used to model variable-length phonetic descriptions . in this paper , we propose a new approach to constructing acoustic units concatenation-based systems for text-to-speech synthesis . the proposed approach is based on modeling the acoustic message as a sequence of variable-length acoustic units . in the proposed approach , each acoustic message is represented by a set of variable-length phonetic descriptions , and the resulting acoustic units are then used to generate the final synthesis result . the experimental results show that the proposed acoustic units concatenation-based systems can produce better synthesis results than conventional methods .
digital matched filters -lrb- dmf -rrb- are widely used in direct sequence spread spectrum systems . in this paper , we propose a hybrid structure based on direct-form structure and transposed-form structure for direct sequence spread spectrum systems . the proposed low-power approaches are able to reduce the area overhead by a factor of 2 . simulation results show that the proposed low-power approaches can achieve comparable performance to that of the direct sequence spread spectrum systems while maintaining the same performance as the 128-tap dmf .
in this paper , we study the knowledge compilation form of tree-of-bdds -lrb- d-dnnf compilation -rrb- , which is a decomposition heuris-tic of cnf and cnf . we study the complexity of d-dnnf compilation for tree-of-bdds -lrb- d-dnnf compilation -rrb- , and show that d-dnnf compilation is significantly more efficient than the matching tob compilations . we also show that d-dnnf compilation has a lower bound on tree width than the matching tob compilations . finally , we show that d-dnnf compilation can be viewed as a special case of the knowledge compilation form , and that d-dnnf compilation can be seen as a special case of cnf and cnf . finally , we show that d-dnnf compilation can be viewed as a special case of cnf and cnf .
in this paper , we investigate the use of real-time multimedia data streams in order to improve the non-guaranteed quality of service networks . in particular , we focus on the design of networked multimedia services over the internet protocol . we focus on the design of network protocols and the design of architectural elements for real-time data transmission . in particular , we focus on signal compression applications and discuss the design of the coding systems and the design of the network protocols . we discuss the design and implementation of the network protocols .
this paper presents a method for automatic identification of the learners ' l1 background in czech . the method is based on the use of non-content based features extracted from highly inflectional data . the binary classification is performed using an svm classifier , and the binary classification is performed on the written data . the results show that the proposed method is robust against orthography and can be used to detect learners ' language background in the writing of inflectional czech . the proposed method has been evaluated on the basis of a set of features that have been used for the evaluation of the automatic identification of the learners ' l1 background . the results show that the proposed method has a high precision and recall , and that the proposed method can be used to detect learners ' l1 background in the writing of czech .
in this paper , we propose a new class of lifting wavelet transform for losslessness of specific signals . the lifting wavelet transform is designed to preserve the losslessness of specific signals . the wavelet transform is designed to minimize the sum of white balance signals and the scaling coefficient values and rounding of signal values . the wavelet transform is designed to minimize the sum of the sum of the scaling coefficient values and the rounding of signal values . the wavelet transform is applied to the white balance signals , and the lossless coding performance is evaluated by comparing the performance of the proposed transform with the conventional lsi processors . the results show that the proposed lifting wavelet transform can achieve the lossless coding performance .
we propose a new energy minimization algorithm for functions defined on 4-connected lattices . the energy minimization algorithm is based on a elimination algorithm , which is a generalization of the alpha-expansion for multilabel problems . the energy minimization algorithm is based on the idea of back-substitution max-flow , which is a natural extension of the alpha-expansion for multilabel problems . we show that the energy minimization algorithm can be applied to submodular problems on 4-connected lattices , and that energy minimization algorithm can be applied to any binary problem on graphs . we show that the energy minimization algorithm can be used to find functions that are submodular with respect to the number of nodes in the graph . we also show that the energy minimization algorithm can be used to find functions that are submodular with respect to the number of nodes in the graph . we also show that the energy minimization algorithm can be applied to submodular problems using 4-connected lattices .
we propose a novel sparse random features algorithm for learning a sparse non-linear predictor in hilbert space . the proposed sparse random features algorithm is based on randomized coordinate descent , where each kernel function is represented by a ℓ 1-regularized objective function . the proposed sparse random features algorithm can be viewed as an approximate solver for the infinite-dimensional ℓ 1-regularized problem , which can be solved by a greedy boosting step . the proposed sparse random features algorithm can be viewed as an efficient kernel method , which can be solved by solving an infinite-dimensional ℓ 1-regularized objective function . we prove that the proposed sparse random features algorithm converges to the optimal sparse non-linear predictor in o -lrb- 1 / , 2 -rrb- convergence for the proposed sparse random features algorithm , and the proposed sparse random features algorithm converges to the optimal sparse non-linear predictor in o -lrb- 1 / , 2 -rrb- for both regression and classification tasks . compared with the state-of-the-art boosting approach , our sparse random features algorithm is more efficient and has memory and prediction time comparable to the state-of-the-art approaches .
deep neural networks have been widely used in many computer vision tasks . however , the performance of common image processing , such as compression , rescaling , and compression , is still far from satisfactory . in this paper , we propose a general stability training method for deep neural networks , which is capable of dealing with small input distortions and small perturbations . specifically , we propose a novel inception architecture , where feature embeddings in a neural network are learned by minimizing the difference between the loss of visual input and the loss of visual input . specifically , we design a general stability training method to minimize the difference between the loss of visual input and the loss caused by small perturbations . the proposed general stability training method is evaluated on three noisy datasets , similar-image ranking , and large-scale near-duplicate detection . the experimental results show that the proposed general stability training method can significantly improve the performance of deep architectures .
zero-shot learning -lrb- zero-shot learning -rrb- aims at learning fine-grained visual categories from a single image . in this paper , we propose a novel approach for zero-shot learning , where the goal is to learn a modality for training data from a human pose dataset . our approach is based on visual abstraction , which allows us to learn a modality for a new image using only a small amount of training data . we show that our approach is able to generalize to new classes of visual concepts , such as gaze concepts , to new classes . furthermore , we show that our approach is able to generalize to new classes , and that it is able to generalize to new classes . we demonstrate the effectiveness of our approach on two challenging datasets : -lrb- 1 -rrb- we show that our approach outperforms the state of the art in zero-shot learning , and -lrb- 2 -rrb- we also show that our approach is able to generalize to new classes .
recommender systems -lrb- recommender systems -rrb- rely on similarity-based retrieval . in this paper , we propose a novel approach to similarity-based retrieval for recommender systems . the approach is based on the idea that the retrieval set is ordered according to the similarity between the recommender systems and the retrieval set . we show that the proposed approach can be used to improve the performance of recommender systems .
in this paper , we consider the nonconvex spectral unmixing problem , where large-size signals are naturally embedded into the optimization problems . we consider the nonconvex spectral unmixing problem , where the goal is to minimize a lipschitz differen-tiable function subject to a non necessarily smooth function . we propose a forward-backward algorithm to solve the resulting optimization problem . the forward-backward algorithm is based on the forward-backward algorithm , which can be used to solve the resulting optimization problem efficiently . we also propose an alternating minimization strategy to solve the resulting optimization problem . the effectiveness of the proposed forward-backward algorithm is demonstrated on several inverse problems .
in this paper , we propose a new model based sparse principal component analysis method . the proposed model based sparse principal component analysis method is based on the l 0 penalty , which is an associated model selection method . the proposed estimation method is based on the iterative hard thresholding and the generalized em algorithm . the proposed estimation method has been tested on simulated data and dna microarray data . the experimental results show that the proposed estimation method outperforms the conventional sparse pca method .
stretched deep convolutional networks -lrb- stretched deep convolutional networks -rrb- have been shown to be very effective for object recognition tasks . however , the performance of these stretched deep convolutional networks depends on the accuracy of the learned deep convolutional architectures in an iterative manner . in this paper , we propose a general framework to learn deep convolutional architectures in an iterative manner . our approach is based on the idea of backpropagation , which allows us to learn the weight matrix of a deep convolutional architectures by minimizing the difference between the learned deep architectures and the learned deep architectures . we show that the stretching can be used to learn the weights of a fixed network architecture and that the learned weights can be used to improve the learning performance of deep architectures . we present tractable algorithms for stretching , and demonstrate the effectiveness of our approach on two ai tasks .
in this paper , we propose a method for determining the optimal embedding parameters of a signal using differential entropy . the proposed method is based on a phase space representation of the signal . it is shown that the differential entropy can be used to determine the optimal embedding dimension , time lag , and the optimal embedding dimension . the proposed method is applied to a synthetic time series phase space representation of a time-delay neural network and an adaptive filter .
empirical mode decomposition -lrb- empirical mode decomposition -rrb- is an adaptive method for nonlinear and nonstationary signal processing . empirical mode decomposition is an extension of empirical mode decomposition to the tone separation problem . empirical mode decomposition has been shown to be effective in nonlinear and nonstationary signal processing . in this paper , we propose a method to separate the initial phase and the frequency ratio from the transition region . the proposed method is based on the analysis of the amplitude ratio of the initial phase and the frequency ratio of the transition region . the experimental results show that the proposed method can separate the initial phase and the frequency ratio from the theoretical background .
in this paper , we propose two feature weighting schemes based on information retrieval for sentiment analysis . the first feature weighting schemes is a sublinear function for term frequency weights and document frequency smoothing . the second feature weighting schemes is based on the binary unigram weights of the support vector machines classifier . the proposed feature weighting schemes is evaluated on two different data sets . the experimental results show that the proposed feature weighting schemes improve the classification accuracy by up to 20 % in terms of accuracy , while the tf.and the other two feature weighting schemes improve the accuracy of the former feature weighting schemes .
in this paper , we propose a novel approach to binaural speech segregation based on deep neural networks -lrb- dnn -rrb- classification . the proposed approach is able to improve the robustness of binaural speech segregation in noisy and reverberant environments by using binary classification . the proposed approach is evaluated in two different scenarios : -lrb- 1 -rrb- in both multisource and reverberant conditions , the proposed method outperforms conventional speech segregation algorithms , -lrb- 2 -rrb- in both multisource and reverberant conditions , and -lrb- 3 -rrb- in human listening , the proposed method improves the performance of binaural speech segregation when compared to dnn based binaural classification .
active appearance active appearance models -lrb- active appearance models -rrb- are statistical models of shape and texture , but active appearance models are not well suited for generic fitting scenarios . in this paper , we present a bayesian formulation of shape and texture active appearance models , which we call active appearance models . we derive a cost function for the shape parameters of active appearance models and derive simultaneous algorithms for the calculation of texture parameters in the latent texture space and the gaussian prior in the latent texture space . we also present a probabilistic model for texture generation that incorporates both gaussian noise and the gaussian prior in a principled manner . we demonstrate the effectiveness of our bayesian formulation by comparing active appearance models with the state of the art .
this paper presents a novel error mining technique for automatically detecting errors in parsing systems . the error mining technique is based on a combination of a pre-parsing processing chain and a syntactic lexicon . we show that the error mining technique can be used to improve the performance of parsing systems by exploiting missing and erroneous information .
in this paper , we study differential privacy mechanisms for model inversion attacks . we propose a differential privacy preserving regression model , which is based on sensitive and non-sensitive attributes . the differential privacy preserving regression model is based on a polynomial representation of the objective function , which is a functional mechanism of the attribute privacy model . we show that the differential privacy preserving regression model can be viewed as a combination of sensitive and non-sensitive attributes , where the utility model efficacy is controlled by the privacy budget . we provide a theoretical analysis of the differential privacy preserving regression models , and show that the differential privacy preserving regression model is stable under the privacy budget , and that the differential privacy preserving regression model is stable under the privacy budget .
image semantic segmentation -lrb- image semantic segmentation -rrb- is a challenging problem due to the lack of a divide-and-conquer strategy . in this paper , we propose a novel framework for image semantic segmentation based on multiple graphs . specifically , we first construct a multi-view affinity graph from the semantic space , and then learn a label-confidence matrix and an affinity matrix from the unlabeled images . the affinity matrix is obtained by optimization over the affinity matrix and a label-confidence matrix , which can be efficiently solved by finding the pairwise potential for dissimilar superpixels . moreover , we propose an efficient algorithm to solve the optimization for the learning affinity matrix . experimental results on two real-world image datasets show that the proposed method significantly outperforms the state-of-the-art methods .
in this paper , we propose a novel image processing system for detecting mouse preterm labor based on second harmonic generation microscopy images . the image processing system first extracts texture features for shg microscopy , and then extracts texture features for image processing . these texture features are then used to extract features for shg microscopy . the proposed image processing system is composed of two steps : -lrb- 1 -rrb- a normal pregnant cervix and -lrb- 2 -rrb- a normal pregnant cervix . the proposed image processing system is composed of three steps : -lrb- 1 -rrb- an image processing system for detecting mouse preterm labor based on second harmonic generation microscopy images , and -lrb- 3 -rrb- an image processing system for detecting mouse preterm labor . the experimental results show that the proposed image processing system is effective in detecting mouse preterm labor in images with high detection rates .
we consider the problem of map inference in randomly perturbed models , where the partition function is defined as the sum of the ragged energy landscapes of the variables . we consider the problem of finding the partition function that minimizes the max-statistics of random variables . we show that this problem can be solved efficiently using standard map solvers such as graph-cuts . we also show that it is possible to efficiently compute the partition function using a small number of randomly perturbed models .
in this paper , we consider the problem of decision-theoretic online learning , where the learning rate is unknown . we consider a probabilistic setting where the parameter is unknown and the learning rate is unknown . we provide a simulation study where the learning rate is unknown and the parameter is unknown . we show that , in some cases , the learning rate is unknown , and that the learning rate is unknown .
in this paper , we propose a method for estimating the source and vocal tract characteristics of voiced speech using a multi-frame analysis method . the proposed method is based on an iterative approximation of the source-filter separation of the source and the transfer function in signal processing . the proposed method consists of two steps . first , the estimation of the source and the transfer function is performed using oversimplified models of the source and the transfer function . second , the estimation of the source and the transfer function is performed using the iterative approximation of the harmonic structure of the source and the transfer function . experimental results show that the proposed method is effective in estimating the source and vocal tract characteristics of voiced speech .
in this paper , we consider the problem of target classification using distributed sensor arrays . we propose a data fusion algorithm for distributed sensor arrays that exploits the non-stationarity of target signatures to improve the accuracy of target classification . the proposed data fusion algorithm is based on the assumption that the source signals are distributed with respect to the source and target signatures . the proposed data fusion algorithm can be applied to distributed sensor arrays to improve the accuracy of target classification . simulation results demonstrate the effectiveness of the proposed distributed sensor arrays .
in this paper , we propose a new pruning method for modified kneser-ney smoothing . the pruning method is based on weighted-difference pruning and a smoothing method . the experimental results show that the proposed pruning method outperforms the conventional selection method in terms of perplexity and model size . we also show that the proposed pruning method is very effective in reducing model size and perplexity . we also show that the proposed pruning method can be applied to modified kneser-ney smoothing , and that the proposed pruning method can be applied to other smoothing methods such as absolute discounting , katz back-off and absolute discounting .
we introduce fastest-cut-first search heuristics for finding minimum proof graphs in arbitrary dag inputs . these fastest-cut-first search heuristics are a game tree , such as a branching factor , and the goal is to find a minimum proof graph that maximizes the expected number of nodes in the minimum game tree . our fastest-cut-first search heuristics are based on approximations of sub-dag values , which can be computed in linear time in the number of interior nodes of the game tree . our goal is to find a minimum game tree that minimizes the expected number of nodes in the tree , and to minimize the expected number of nodes in the tree . our fastest-cut-first search heuristics can be used to find a minimum proof graphs that minimize the expected number of nodes in the graph . we provide a heuristic evaluation time of our fastest-cut-first search heuristics , and show that our fastest-cut-first search heuristics can be used to find a minimum proof graphs in arbitrary dag inputs .
we present a wrapper approach to feature selection in the context of bayesian estimation with conjugate priors . the leave-one-out estimate estimates of posterior probabilities are used to estimate the error count and to estimate the classification error . we show that the bias in the leave-one-out estimate can be used to estimate the error estimate . we show that the bias in the leave-one-out error estimate can be used to estimate the true error estimate . we also show that the bias in the bayesian estimators can be used to estimate the variance of the error estimate . we demonstrate the usefulness of the proposed wrapper approach for feature selection in the context of bayesian estimation with conjugate priors .
in this paper , we present a global algorithm for vectorizing line drawings . the global algorithm is based on the idea that the raster image can be transformed into a graphic entity , and the raster image can be transformed to a graphic entity . the basic idea of the proposed global algorithm is to use a global algorithm for vectorizing line drawings . the global algorithm is based on a theoretical analysis of the degradation of image quality . the theoretical analysis shows that the proposed global algorithm is robust to entity noise , and can be applied to any type of postprocessing . the experimental results show that the proposed global algorithm is very robust to entity noise , and the global algorithm is robust to the degradation of image quality .
speaker recognition systems use short-term acoustic vectors derived from ergodic hidden markov models and gaussian mixture models to model the speaker 's identity . in this paper , we propose a statistical approach based on pitch-dependent gmms to model the long-term prosodic features of a speaker . the proposed statistical approach is based on the use of pitch-dependent gmms to model the relationship between the speaker 's identity and the speaker 's identity . the proposed statistical approach is evaluated on the nist speaker recognition evaluation -lrb- sre -rrb- speaker recognition evaluation -lrb- sre -rrb- database . the results show that the proposed statistical approach performs better than the baseline system .
dimensionality reduction is an important problem in many machine learning problems with many features . in this paper , we present a novel approach to dimensionality reduction based on singular value decomposition . the approach is based on a classification algorithm that learns a classifier from a small number of examples . we compare our approach with other two-phase approaches , and show that lower-dimensional representations are better than those of other two-phase approaches . we also show that our approach can be applied to a variety of machine learning problems with different features .
in this paper , we propose a novel 3d face recognition method based on the evolution of iso-geodesic distance curves . the evolution angle function is a one-dimensional function which is invariant to euclidean invariant . the evolution angle functions of the iso-geodesic distance curves are used to define a weight function for the evolution of iso-geodesic distance curves . the proposed 3d face recognition method is tested on a non-neutral face database with neutral faces and non-neutral faces . the experimental results show that the proposed 3d face recognition method can recognize the 3d face with high accuracy . the proposed 3d face recognition method can recognize the 3d face with high accuracy .
in this paper , we propose a new speech pitch estimator , called '' the '' the speech pitch estimator '' , which is designed for all-voiced speech in additive white noise . the proposed speech pitch estimator is based on the idea of two-dimensional processing , where the spectrogram is represented by a set of harmonically-related signal components in the time-frequency plane . the 2-d transformation maps of the narrowband spectrogram are computed by comparing the magnitude two-dimensional processing of the two-dimensional fourier transform magnitude with the well-known short-space 2-d fourier transform . the two-dimensional processing of the two-dimensional plane is then applied to the spectrogram of the input signal . the proposed speech pitch estimator is compared with the gct-based pitch estimator , and the results show that the proposed speech pitch estimator is able to accurately estimate the pitch of the all-voiced speech in additive white noise . the results also show that the proposed speech pitch estimator is able to accurately estimate the pitch of the speech signal even in the presence of noise . in the case of two-speaker pitch estimation , it is also shown that the proposed speech pitch estimator outperforms the gct-based pitch estimator .
in this paper , we study the feasibility problem in multiuser miso systems with bounded uncertainties . we assume that the channel state information is available at the transmitter and the receiver has a non-saturating max-min rate . we propose a rate-splitting strategy to minimize the max-min degrees of freedom subject to a rate constraint for power minimization and transmit power constraint . we show that max-min degrees of freedom can be viewed as a generalization of max-min degrees of freedom to the power minimization problem under a rate constraint . we show that max-min degrees of freedom can be used to design rs-based designs for uncertainty regions with multiuser interference . furthermore , we show that max-min degrees of freedom can be used to design rs-based designs for uncertainty regions with multiuser interference . we also show that max-min degrees of freedom can be used to design optimal rs-based designs for the uncertainty regions with perfect channel state information . simulation results show that max-min degrees of freedom can achieve the same performance as max-min degrees of freedom , while max-min degrees of freedom can achieve the same level of snr as max-min degrees of freedom .
predicting physiological score in post-traumatic stress disorder -lrb- ptsd -rrb- is a challenging task , especially for peripheral physiology in virtual reality videos and for ptsd diagnosis . in this paper , we propose a novel approach for learning a physiological ptsd score for patients with a post-traumatic stress disorder . the proposed approach is based on sparse combined , an automated physiology-based objective diagnostic method that learns a physiological diagnostic score for patients with a physiological ptsd score . in the learning formulation , a cost function based on classification is proposed to learn a physiological diagnostic score for patients with different mental pathologies . in the learning formulation , a physiological ptsd score is learned by comparing the learned physiological ptsd score with the learned physiological ptsd score . the experimental results show that the proposed approach outperforms the generic learning approaches in terms of diagnostic score validity , generalizability learning , and virtual reality videos . in addition , the proposed approach can learn binary diagnostic decisions using peripheral physiology measures .
analysis of anomalies in video surveillance applications requires the recovery of video anomalies from a stationary background . in this paper , we propose a method for video anomaly recovery from spectrally compressed video frames . the proposed method is based on principal component pursuit , which is a 3-channel spectral video system . the proposed method consists of two steps . first , a 3-d data cube with 2-d spatial information and spectral information is extracted from spectrally compressed video . second , the 3-d data cube is extracted from the cassi system , and a sparse matrix is extracted from the g g g g g g g g g g . finally , the spectral signatures are recovered from spectrally compressed video . the experimental results show that the proposed method is effective in the recovery of anomalies in video .
in this paper , we propose a novel shape derivative approach to image segmentation . the proposed shape derivative approach is based on the minimization of the distance between two histograms of the image features . the minimization of the distance between two histograms is formulated as the minimization of the distance between the image features and the image features . the minimization of the distance between two histograms is solved using a theoretical framework , which is based on the classical calculus of variation . the evolution equation of the gradient of the derivative of the gradient of the gradient of the gradient of the gradient of the gradient of the gradient of the gradient of the gradient of the gradient of the gradient of the gradient of the gradient of the gradient of the gradient of the gradient of the gradient of the gradient of the gradient of the gradient of the gradient of the gradient of the gradient of the gradient of the intensity of the active contour . the proposed shape derivative approach has been applied to the problem of image segmentation on video sequences , and the results show that the proposed shape derivative approach is superior to the state of the art in image segmentation .
unit selection based text-to-speech synthesis -lrb- hts -rrb- is a widely used unit selection scheme in many applications . in this paper , we propose a hybrid statistical unit selection tts system for agglutinative languages . the proposed hybrid statistical unit selection tts system is based on a hybrid statistical unit selection tts system for agglutinative languages . the proposed hybrid statistical unit selection tts system has a memory footprint of o -lrb- n 2 -rrb- , where n is the number of embedded devices . the proposed hybrid statistical unit selection tts system is evaluated by comparing the baseline hts system with the baseline hts system based on a/b preference tests . the results show that the proposed hybrid statistical unit selection tts system outperforms the baseline hts system in terms of intelligi-bility and quality scores . moreover , the proposed hybrid statistical unit selection tts system can be easily applied to agglutinative languages , which can be used for embedded devices .
in this paper , we propose an active learning approach to automatically learn geometric priors for the segmentation classifier in natural 2d images . the proposed active learning approach is motivated by the observation that a 2d planar patch can be represented by a small number of 3d image volumes . the proposed active learning approach is motivated by the observation that the annotation process is based on a small set of geometric priors learned from training data . the proposed active learning approach is evaluated on electron microscopy and magnetic resonance image volumes . the experimental results show that the proposed active learning approach is able to significantly improve the performance of the segmentation classifier in comparison to the state-of-the-art methods .
template protection is an important component of biometric recognition systems . in this paper , we propose a biometric cryptosystem for iris biometrics . the digital modulation paradigm is based on the digital modulation paradigm , which allows template security to be controlled by intra-class variability such as iris . the proposed biometric cryptosystem consists of two modulation constellations : turbo codes with soft-decoding , and turbo codes with soft-decoding . the experimental results on the casia-irisv4 database show that the proposed biometric cryptosystem outperforms the state-of-the-art methods in terms of verification rates and security .
in this paper , we address the problem of boundary detection in natural images . we propose a novel multi-scale boundary detection problem , which is based on a combination of local boundary cues -lrb- e.g. , contrast , localization , relative contrast -rrb- and localization -lrb- e.g. , localization -rrb- . our multi-scale boundary detection problem is motivated by the observation that the underlying distribution of boundary detection in natural images is highly correlated with clutter , and therefore can be used as a classifier to detect the presence of clutter . we evaluate our multi-scale boundary detection problem on two boundary and object datasets with human-marked , and show that multi-scale boundary detection problem outperforms single-scale approaches in both small-scale detection and large-scale detection .
we consider the problem of learning non-stationary policies in adversarial zero-sum matrix games , where the goal is to learn a non-stationary policy in the presence of an adversarial relationship between the agents and the actions of other agents . we propose elph , an on-line sequence learning algorithm for learning such non-stationary policies in multiagent environments . elph is an entropy pruning technique that allows the construction of agents in such games . we show that elph is able to learn non-stationary policies in 2-player zero sum games , and that elph is able to learn optimal policies in such games . we empirically evaluate elph and compare its performance to other on-line learning methods .
in this paper , we consider the problem of optimal feature reduction in the context of maximum-likelihood estimation problem . we propose a uniform statistical framework for constructing a mapping from a lower dimensional subspace to a lower dimensional subspace . we show that the optimal feature reduction can be formulated as a maximum-likelihood estimation problem . we compare our approach with other linear selection methods in terms of recognition accuracy .
this paper presents a novel approach to binaural pre-processing of speech signals for a linear hearing aid . the proposed approach is based on the least mean squares algorithm applied to speech signals captured by a wide-band signal . the signal characteristics of the signal are estimated by the least mean squares algorithm , which is then used to estimate the noise ratios . the proposed algorithm is tested on both simulated and real-room acoustics , where acoustic speech and noise data are used as input to the processing mechanism . the results show that the proposed algorithm is able to improve the performance of hearing impaired volunteers in various acoustic environments .
in this paper , we propose a novel analysis methodology to analyze the relationship between the dynamic range of the line buffer and the overflow of coefficients in the reconstructed image . the proposed analysis methodology is based on the analysis methodology of line buffer and the overflow of coefficients in the reconstructed image . the experimental results show that the proposed analysis methodology can significantly improve the quality of the reconstructed image . moreover , the proposed analysis methodology can also be used to analyze the performance of the proposed analysis methodology in terms of the psnr and the dynamic range of the reconstructed image .
we propose a novel method for automatic estimation of the input-output function of single cells in single neurons using voltage sensitive imaging techniques . the method is based on constrained linear regression , where the spatiotemporal pattern of synaptic input and the spatial distribution of channel densities are modeled by a set of reversal potentials . each voltage is represented by a spatiotemporal voltage signal , and the noise level 5 is estimated by minimizing the weighted sum of the weighted sum of the weighted sum of the weighted sum of the weighted sum of the weighted sum of the weighted sum of the weighted sum of the weighted sum of the weighted sum of the weighted sum of the weighted sum of the weighted sum of the weighted sum of the reversal potentials of the input and the noise level . the proposed method is evaluated on three model datasets and compared to state-of-the-art methods . the accuracy of the proposed method is comparable to that of biophysically accurate multi-compartmental models in the presence of noise level and in-tercompartmental conductances . it is also shown that the proposed method can be used for hand tuning .
in this paper , we propose a directionally adaptive image interpolation based on directionlets . directionlets are a multiple-direction wavelet transform that encodes the edge information of a high-resolution image . directionally adaptive image interpolation uses directionlets to extract directional features from a low-resolution image . directionlets are then used to estimate the quality of the interpolated image . the directionally adaptive image interpolation is evaluated in terms of both numeric and visual quality . experimental results show that directionally adaptive image interpolation produces better results than the state-of-the-art methods .
in this paper , we propose a novel cross-entropy objective function and softmax activation for deep neural network frame-level training . the cross-entropy objective function is designed to minimize the log posterior ratio between the output layer and the output layer of the deep neural network . the proposed cross-entropy objective function is evaluated on large vocabulary continuous speech recognition for large vocabulary continuous speech recognition . compared to the cross-entropy trained dnn system , the proposed cross-entropy trained dnn system achieves a relative word error rate reduction of up to 25 % on the switchboard task . furthermore , the proposed cross-entropy trained dnn system is shown to be superior to the cross-entropy trained dnn system .
this paper presents a method for characterizing human heart beat intervals in electrocardiogram data . the method is based on probabilistic models of the inverse gaussian model used for analysis of autonomic control . the method is based on the adaptive point process filtering paradigm and the kolmogorov-smirnov test . the method is tested on respiratory covariate measurements and the dynamic respiratory sinus arrhythmia analysis . the results show that the proposed method is able to accurately predict the index of vagal control dynamics in the inverse gaussian model of the instantaneous rsa gain .
hidden semi-markov models -lrb- hidden semi-markov models -rrb- have been widely used for state duration modelling . however , hidden markov and hidden semi-markov models do not fully model the state durations of the electrocardiogram waveform . in this paper , we propose a novel method for modelling the electrocardiogram waveform using a hidden markov model . the proposed method is based on an overcomplete representation of the signal using an undecimated wavelet transform . the proposed method is evaluated on real ecg features . the results show that the proposed method outperforms the state durations of the hidden markov and hidden semi-markov models .
degraded speech comprehension is a challenging problem due to the high and low level mechanisms involved in the auditory system . in this paper , we explore the use of low-level auditory mechanisms for degraded speech restoration . specifically , we focus on the relationship between the medial olivocochlear bundle functionality and the physiological properties of degraded speech , and propose higher-level strategies to reduce the interindividual variability in the reversion windows . in particular , we focus on the relationship between high and low level mechanisms in the auditory system . in particular , we focus on the relationship between the reversion windows in the reversion windows and the reversion windows in the reversion windows . the results show that the interindividual variability in the auditory system affects the performance of degraded speech comprehension , and that the interindividual variability in the reversion windows improves the intelligibility of degraded speech .
in this paper , we present a vision-based technique for dynamically recognizing shop or building signs in street view recognition . the vision-based technique is based on a visual recognition technique and gps scale data . the vision-based technique consists of two steps : -lrb- 1 -rrb- view-angle invariant distance estimation , -lrb- 2 -rrb- path refinement , -lrb- 3 -rrb- view-angle invariant distance estimation , -lrb- 3 -rrb- robust and accurate position estimation , and -lrb- 3 -rrb- robust and accurate position estimation . the m error estimation is performed on a gps map . the experimental results show that the proposed vision-based technique is effective in recognizing a real user location .
in this paper , we propose a method for quasi text-independent speaker verification based on pattern matching . in the proposed method , phonetically matched segments are extracted from speech signals by matching gaussian mixture models . the frame-level probabilities of the phonetically matched segments are extracted from the speech signals using pattern matching . the performance of the proposed method is compared with that of a conventional speech recognizer . the results show that the proposed method outperforms the conventional methods .
understanding common sense reasoning -lrb- understanding common sense reasoning -rrb- is a fundamental problem in qualitative reasoning research . understanding common sense reasoning -lrb- understanding common sense reasoning -rrb- is a key component of understanding common sense reasoning . understanding common sense reasoning -lrb- understanding common sense reasoning -rrb- is a key component of understanding common sense reasoning . understanding common sense reasoning -lrb- understanding common sense reasoning -rrb- involves reasoning about physical world , and understanding common sense reasoning -lrb- understanding common sense reasoning -rrb- . understanding common sense reasoning -lrb- understanding common sense reasoning -rrb- involves reasoning about the physical world , and understanding common sense reasoning -lrb- understanding common sense reasoning -rrb- of the physical world . understanding common sense reasoning -lrb- understanding common sense reasoning -rrb- is an important step in understanding common sense reasoning . in this paper , we present a novel approach to understanding common sense reasoning that combines ideas from qualitative mechanics and analogy for comparative analysis problems . we demonstrate the effectiveness of our approach on a bennett mechanical comprehension test . we also show that modeling decisions based on sketch annotations leads to significant improvements in understanding common sense reasoning .
in this paper , we present a novel approach to translation assistance in l2 . the approach is based on a classification-based approach , where the goal is to translate native language fragments into foreign language fragments , and then to translate them into english using second language learning . in contrast to previous approaches , our approach does not require any language learners to be able to provide high-quality translation suggestions based on cross-lingual context . in contrast to previous approaches , our approach does not require any language learners to be able to perform well in l2 context . instead , we propose to use a contex-tual window to select the best translation assistance for each sentence in the l2 context . we evaluate our approach on a variety of datasets and show that our approach significantly outperforms a state-of-the-art translation assistance system . furthermore , we show that our approach is able to generate high-quality translation suggestions for both word-sense dis-ambiguation baselines and statistical language modelling .
in this paper , we propose a corpus-based chinese speech synthesis system , corpus design , unit selection procedure , and unit selection procedure . corpus design is a corpus-based chinese speech synthesis system for the synthesis unit . the corpus-based chinese speech synthesis system consists of two steps : corpus design and unit selection procedure . corpus design consists of two steps : prosody parameter prediction and prosody feature modification . in the first step , the context similarity between the speaker 's utterances and the synthesized speech is calculated based on the context similarity between the speaker 's utterances and the synthesized speech . the experimental results show that the proposed corpus-based chinese speech synthesis system is effective for the synthesis unit .
in this paper , we propose a novel image classification algorithm , named region evaluation function , which integrates local information into a global decision . specifically , we incorporate local information into the image classification algorithm by pooling local information into a single global decision . the proposed image classification algorithm is evaluated on three challenging ilsvrc2014 datasets . the experimental results show that the proposed image classification algorithm outperforms the state-of-the-art methods , such as max-pooling and average-pooling . moreover , the proposed image classification algorithm is competitive with the state of the art .
ordinal regression is a fundamental problem in machine learning . in this paper , we propose a novel ordinal regression approach for ordinal regression of high order data . the ordinal regression approach is based on manifold learning , where each data item is represented by a fixed , discrete rating scale , and the intrinsic geometry of the data item is represented by a natural tensor structure . the proposed ordinal regression approach is able to capture the embedded nonlinear structure of the data item in a high-dimensional feature space , and can capture the intrinsic geometry of the data item . we demonstrate the effectiveness of the proposed ordinal regression approach on several data sets .
in this paper , we consider the problem of causal structure learning from observed measurement data . in particular , we consider the problem of learning dynamic causal graphs from observed measurement data , where the observed measurement data can be represented by dynamic causal graphs . we propose two causal structure learning algorithms for learning such dynamic causal graphs from time series data . the first algorithm is a generalization of the extant algorithms for learning dynamic causal graphs from observed measurement data . the second algorithm is a generalization of the extant algorithms for learning dynamic causal graphs from observed measurement data . the third algorithm is a generalization of the extant algorithms for learning dynamic causal graphs from time series data . the experimental results show that the proposed algorithms are able to learn the causal structure of the observed measurement data .
multi-armed bandits -lrb- multi-armed bandits problems -rrb- problems are a discrete random variable for graphical models and large-scale bayesian inference . in this paper , we consider the multi-armed bandits problems , where the goal is to minimize the sum of a finite reward population , subject to a finite reward population . we propose a subsampling approach to efficiently compute the approximate solution . we provide theoretical guarantees on the quality of the sampling algorithms , and provide theoretical guarantees on the quality of the approximate solution . our analysis shows that the proposed subsampling approach can be applied to many large-scale inference problems with a discrete distribution , and can be efficiently solved using monte carlo methods . we empirically evaluate the proposed subsampling approach on synthetic and real-world large-scale problems , and show that the proposed subsampling approach significantly improves the robustness of existing approximate algorithms .
overlapping acoustic event detection aims at detecting the temporal evolution of sound events in an input time/frequency representation . in this paper , we propose a novel approach to detect overlapping acoustic events based on probabilistic latent component analysis . first , we propose a novel sound event dictionary based on event class-wise hidden markov models . then , the event class-wise hidden markov models is used to generate a sound event dictionary from the equivalent rectangular bandwidth spectrogram . the proposed approach is evaluated on two polyphonic datasets of office sounds using an acoustic scene simulator . the experimental results show that the proposed method outperforms the state-of-the-art frame-based and event-based metrics . furthermore , the proposed method is also shown to be effective in detecting overlapping events in both real and synthesized monophonic datasets .
we present a classification method for defining motion maps in complex videos . our classification method is based on a feedforward model of center-surround interactions of mt cells , which captures the functional properties of mt cells in complex videos . our classification method learns feature vectors for defining motion maps from complex videos , which are then used for action recognition in neurophysiology . our classification method is inspired by bio -- inspired models of neurophysiology . first , we show that cortical cells in the visual space can be represented by a set of center-surround interactions of mt cells in the motion pathway . second , we show that cortical cells in the mt level can be represented by a set of simple velocity detectors . third , we show that cortical cells in the visual space can be represented by a set of simple , bio -- inspired models . finally , we show that our classification method achieves an average recognition rate of 88.3 % on the weizmann database , which is significantly better than the state of the art in action recognition .
the minimax principle is a popular heuristic function for evaluating the behavior of game trees . in this paper , we study minimax principle in the context of games with pathology noise . we show that minimax principle is a powerful tool for studying the behavior of game-playing programs . we show that minimax principle is a powerful tool for studying the behavior of games with value dependence on the structure of the game tree , and show that minimax principle is a powerful tool for studying the behavior of games with incomplete searches position values . we also show that minimax principle can be used to study the behavior of games with incomplete information about the structure of the game tree . finally , we show how minimax principle can be used to derive a more general class of games with deeper searches position values .
in this paper , we consider the problem of inferring causal mechanisms from data with missing data . we propose a formal representation called ` missinthe graphs ' , which is a consistent estimator of the true distribution of missing data . we show that this formal representation can be used to infer causal mechanisms in the presence of missing data . in particular , we show that this formal representation can be used to infer causal mechanisms from data . we also show how this formal representation can be used to identify missinand identify causal mechanisms .
in this paper , we propose generalized metho, which is based on pairwise comparisons between the full rankings and the generalized moment conditions . we show that the generalized methothe generalized methothe generalized methoand the classical minorize-maximization algorithm can be viewed as special cases of the generalized methoand inconsistent breakings , respectively . we prove that the generalized methothe generalized methoand the generalized methothe moments algorithms can be generalized to any single pairwise comparisons , which can be used to derive the generalized methothe moments algorithms from pairwise comparisons . the statistical efficiency of the proposed generalized methothe proposed generalized methoand the algorithms is verified by numerical experiments .
we consider the problem of clustering categorical data using an entropy-based criterion . we show that the heterogeneity of clusters can be characterized by entropy-type measures , and that this heterogeneity of clusters can not be handled by standard probabilistic clustering models . we also show that the resulting partitions can be used to determine the number of partitions in the data set . finally , we show that the resulting partitions can be used to determine the number of partitions in the data set .
we present lookahead-based algorithms for anytime induction of decision trees . the lookahead-based algorithms are based on a stochastic version of id3 , which is a stochastic version of the id3 , but uses depth-k lookahead to guide the search for the best tree in the constructed tree . we show that these lookahead-based algorithms improve tree quality , learning time , and tree quality by a factor of two orders of magnitude . we also show that these lookahead-based algorithms can be used to improve the anytime induction of decision trees . we also show that these lookahead-based algorithms can be applied to a wide range of problems , including learning decision trees , and learning time .
schatten-p quasi-norm minimization algorithms based on singular value decomposition and eigenvalue decomposition have recently been proposed for solving representative matrix completion problems . in this paper , we propose a new class of schatten-p quasi-norm minimization algorithms based on singular value decomposition and eigenvalue decomposition . the proposed schatten-p quasi-norm minimization algorithms can be viewed as a generalization of the nuclear norm to the rank function of the factor matrices . we prove that the proposed schatten-p quasi-norm minimization algorithms converge to a tractable schatten quasi-norms , and the global convergence of the proposed schatten-p quasi-norm minimization algorithms is guaranteed . moreover , we prove that the proposed schatten-p quasi-norm minimization algorithms converges to a stationary point of the optimal solution in o -lrb- log -lrb- n -rrb- log -lrb- n -rrb- log -lrb- n -rrb- -rrb- log -lrb- n -rrb- -rrb- -rrb- - norm , where n is the dimension of the matrix . experiments on synthetic and real-world data show that the proposed schatten-p quasi-norm minimization algorithms outperform the state-of-the-art methods in large-scale problems .
in this paper , we present a framework for data-driven grapheme-to-phoneme conversion . the framework is based on latent analogy , a global definition of analogous events -lrb- top-down -rrb- inductive learning , and a data-driven mapping of the out-of-vocabulary word to the graphemic form . the phoneme transcription is performed using locally optimal sequence alignment and maximum likelihood position scoring . the data-driven mapping enables the synthesis of proper names with no external linguistic knowledge and no supervision . the proposed framework is evaluated on a large vocabulary continuous speech recognition -lrb- lvcsr -rrb- task . the results show that the proposed framework is capable of producing globally relevant pronunciations without any supervision , and that it is possible to improve the performance of data-driven grapheme-to-phoneme conversion .
in this paper , we propose a novel feature space adaptation method based on the maximum a posteriori linear regression framework for large vocabulary continuous speech recognition . in the proposed feature space adaptation method , a straightforward feature space adaptation method based on lin parameters is proposed . in the proposed feature space adaptation method , the parameters of the dnn acoustic models are dynamically updated according to the prior knowledge of the adaptation process . in the proposed feature space adaptation method , the adaptation process is divided into two steps : -lrb- 1 -rrb- a linear input network is trained by the proposed feature space adaptation method , and -lrb- 2 -rrb- a straightforward feature space adaptation method based on the lin parameters is proposed . experimental results on the switchboard task show that the proposed feature space adaptation method can achieve a relative word error rate reduction of 9.6 % compared to the conventional fmaplin method , and the proposed feature space adaptation method can reduce the over-fitting caused by the robustness situation .
this paper presents new codec structures for noise feedback coding , called broadvoice ® 16 . the broadvoice ® 16 is a packeand 1.5 mandatory narrowband speech codec designed for noise feedback coding . the broadvoice ® 16 has been designed to provide a clean speech codec with both long-term and short-term noise spectral shaping . in this paper , a vector-quantization-based nfc is proposed , based on scalar-quantization-based nfc . the vector-quantization-based nfc is composed of a closed-loop vq codebook design and vq codebook search . the experimental results show that the proposed codec structures can improve the performance of noise feedback coding .
social network analysis -lrb- social network analysis -rrb- is the task of discovering the role of a user in a social network . in this paper , we propose author-diagrapient-topic model , a author-topic model for social network analysis based on latent dirichlet allocation . we use a author-topic model to learn topic distributions from direction-sensitive messages , and apply author-diagrapient-topic model to social network analysis . we evaluate our author-diagrapient-topic model on a re-searcher 's email archive and the enron email corpus . our results show that the author-diagrapient-topic model is effective in discovering topic distributions in social network analysis .
variational approaches to large-scale image processing problems require the use of pc-hardware for real-time 2d image processing . in this paper , we propose a framework for parallel variational optical flow computation using domain decomposition and cluster computing -lrb- pc-hardware -rrb- . in particular , we propose a global solution to the variational approach in rectangular subdomains , where the number of iterations is limited by inter-process communication and the number of iterations required for the variational approach is much smaller than the number of iterations . in addition , we introduce a lower-dimensional interface , where the number of pc-clusters is much smaller than the number of iterations , and the number of local solutions is much smaller than that of multi-grid iterations . we demonstrate the effectiveness of our approach by applying it to the domain decomposition of an image plane , where the number of iterations is much smaller than the number of iterations . we demonstrate the effectiveness of our approach by applying it to the task of estimating the number of pc-clusters in an image plane .
in this paper , we investigate the use of short-and long-term speech features in logistic regression fusion for two-class and five-class emotion detection . we show that fusion with cepstral gmm gives an unweighted recall value of 0.86 , which is significantly better than the baseline system . we also show that fusion with cepstral gmm improves the performance of the baseline system .
in this paper , we propose a dynamic sinusoidal synthesis model for statistical parametric speech synthesis . the dynamic sinusoidal synthesis model is based on mel-cepstra generated by pitch synchronous spectral analysis . the mel-cepstra are derived from the cepstral representation of the dynamic sinusoidal synthesis model . the dynamic sinusoidal synthesis model is based on the assumption that the static amplitude of the dynamic sinusoidal synthesis model is independent of the duration of the dynamic sinusoidal synthesis model . the dynamic sinusoidal synthesis model is evaluated in terms of mean opinion score test . the results show that the proposed dynamic sinusoidal synthesis model has a better perceptual criterion than the cepstral representation of the dynamic sinusoidal synthesis model . the dynamic sinusoidal synthesis model has a better mean opinion score test than the conventional dynamic sinusoidal synthesis model .
tissue distribution plays an important role in classification . in this paper , we propose a generative model based on the statistical text literature . in particular , we propose to use probabilis-tic latent semantic analysis to learn a compact tissue representation in an unsupervised manner . in the classification stage , we use local descriptors and probabilis-tic latent semantic analysis as the classifier . in the classification stage , we use the mias and ddsm datasets to compare the performance of the proposed probabilis-tic latent semantic analysis with other descriptors such as texture , sift features , and mam-mogram . in the classification stage , we find that the proposed probabilis-tic latent semantic analysis is more effective than the state-of-the-art classifier , especially when the tissue densities are highly non-stationary . in the classification stage , we find that the proposed probabilis-tic latent semantic analysis is more effective than the state-of-the-art methods , especially when the regions are highly non-stationary , and that the proposed probabilis-tic latent semantic analysis is more effective than the state-of-the-art methods .
in this paper , we propose an unsupervised learning approach from user-edited videos captured by social media websites such as youtube . the proposed unsupervised learning approach is based on a shrinking exponential loss function , which can effectively capture the temporal structure of highlight segments in a video class . the robust recurrent auto-encoder is trained in an unsupervised setting , and is robust to noise and is robust to noise . the proposed unsupervised learning approach is evaluated in two different scenarios : -lrb- 1 -rrb- unsupervised learning approach is based on user-edited videos collected from different short-form video sharing platforms -lrb- e.g. instagram and youtube -rrb- , and -lrb- 2 -rrb- unsupervised learning approach is applied in an unsupervised setting . the experimental results show that the proposed unsupervised learning approach is effective in dealing with down-loaded edited videos . the proposed unsupervised learning approach is evaluated in two scenarios : 1 -rrb- unsupervised learning approach is trained on user-edited videos collected from different social media websites -lrb- e.g. , youtube -rrb- and 2 -rrb- unsupervised learning approach is effective in dealing with noise . the experimental results show that the proposed unsupervised learning approach is superior to the state-of-the-art supervised techniques .
this paper addresses the problem of recovering high resolution luminance and depth information from low resolution camera images . we propose a probabilistic framework for recovering high resolution albedo and depth maps using markov random fields . the proposed probabilistic framework allows us to incorporate a priori knowledge of the scene in the imaging process . in contrast to existing methods , the proposed probabilistic framework does not require any prior knowledge of the scene or the relative displacements between the image frames . in contrast , the proposed probabilistic framework allows us to combine high resolution luminance and depth information with geometrical techniques in statistical models . the surface reconstruction is formulated as expectation maximization and solved efficiently using iterative algorithms . experimental results show that the proposed probabilistic framework is able to recover high resolution albedo and depth maps even when the surface orientations are unknown .
convolutional neural networks -lrb- convolutional neural networks -rrb- have been shown to outperform feature-based systems in a domain adaptation setting . in this paper , we study the event detection problem in the context of convolutional neural networks . we propose a novel approach to address this event detection problem by incorporating rich feature sets and error propagation into the convolutional neural networks . the proposed approach is based on feature engineering and can be easily incorporated into the convolutional neural networks . experimental results show that the proposed convolutional neural networks outperforms the state-of-the-art feature-based systems in the domain of event detection problem .
forward-backward filters -lrb- forward-backward filters -rrb- are widely used in neural networks and signal processing . in this paper , we propose a new approach to smoothing prediction , which is based on a nonlinear noise reduction and estimation of the model parameters from noisy data . the proposed approach is based on the kalman frameworks and can be interpreted as a nonlinear extension of forward-backward filters to neural networks . in the linear case , it is shown that the proposed approach can be applied to a wide range of problems , including smoothing prediction , estimation of the model parameters , and estimation of the model parameters from noisy data . simulations of noisy time series demonstrate the effectiveness of the proposed approach .
in this paper , we propose a monte carlo algorithm for fixed-point iir digital filters . the monte carlo algorithm is based on the assumption that the fixed point representation and the quantiza-tion function of the state space are zero-input limit cycles . the proposed monte carlo algorithm can be used to derive limit cycles for a class of fixed-point iir digital filters . the monte carlo algorithm can be applied to any class of limit cycles . the monte carlo algorithm can be applied to any class of fixed-point iir digital filters . numerical simulations are presented to illustrate the performance of the proposed monte carlo algorithm .
in this paper , we propose a fast exact least mean square -lrb- lms -rrb- algorithm for high level synthesis in the fir case . the proposed algorithm is based on processing and memory units , and algorithmic transformations are suitable for acoustic echo cancellation . the computational load of the proposed algorithm is reduced by a factor of 2 . the proposed algorithm is compared with the conventional lms algorithms in terms of theoretical arithmetic reduction and memory requirements . the simulation results show that the proposed algorithm is capable of reducing the memory requirements for dierent lter lengths .
tensor null space invariants -lrb- tensor null space invariants -rrb- are widely used for archiv-ing and searching motion events in high order data classification . however , tensor null space invariants are not suitable for multidimensional affine transformations because tensor null space invariants are not invariant to camera motions . in this paper , we propose a novel representation for tensor null space invariants , which is based on ten-sor based null space affine invariants . tensor null space invariants can be used for archiv-ing and searching motion events , which can be used for retrieval and retrieval system . a linear classifier is used to classify consecutive motion events . experimental results show the effectiveness of the proposed representation .
functional magnetic resonance imaging -lrb- fmri -rrb- is a powerful tool for data analysis in functional magnetic resonance imaging . in this paper , we propose a novel approach to fmri group analysis based on the group markov random field -lrb- group mrf -rrb- . specifically , the group markov random field -lrb- group mrf -rrb- is a neighborhood system where the activation maps of the active brain regions are represented by an mrf . the group markov random field -lrb- group mrf -rrb- is capable of capturing the correlations between the activation maps of the active brain regions and the regions of the brain activation . furthermore , the group markov random field -lrb- group mrf -rrb- is used to model the correlations between the active brain regions and the activation maps of the active brain regions . the experimental results on both synthetic and real fmri data demonstrate the effectiveness of the proposed analysis techniques .
in this paper , we present a novel image signal processor design for cfas , such as bayer , cmy , and rgbw patterns . the image signal processor design is based on the observation that the image signal processor design for cfas can be viewed as the convolution of regular pattern color filter arrays -lrb- cfas -rrb- with near poissonian noise . the image signal processor design for cfas is composed of two steps : first , the filter weights are designed to minimize the noise induced arti-facts , and second , the filter weights are designed to minimize the noise reduction in the image signal processor design . the proposed image signal processor design is based on two steps : -lrb- 1 -rrb- a universal de, which is based on finite impulse response filters , and -lrb- 2 -rrb- a set of speed and quality optimizations . the experimental results show that the proposed image signal processor design is capable of reducing the noise in images without sacrificing the performance of the optical pipeline . the proposed image signal processor design can be applied to any type of cfas , e.g. , bayer , cmy , etc. .
in this paper , we propose a photo-real talking head system based on audio/visual modeling using deep bidirec-tional lstm . in our photo-real talking head system , the audio/visual stereo data is first converted into parallel temporal sequences -lrb- e.g. con-textual label sequences -rrb- , and then a regression model is trained on the deep bidirec-tional lstm . in our photo-real talking head system , a deep bidirec-tional lstm is trained to predict the temporal sequences and the long-range dependencies between the two blstm layers . in the proposed photo-real talking head system , a recurrent neural network architecture is trained to predict the temporal sequences and the long-range dependencies between the two blstm layers . in the hmm-based system , the objective measurement is performed on the lower face region and the lower face region is predicted by the blstm rnns . in the proposed photo-real talking head system , the prediction is carried out by the deep bidirec-tional lstm square error between the two network topologies . the proposed photo-real talking head system is evaluated on the audio/visual database and the subjective a/b test visual feature sequences show that the proposed photo-real talking head system outperforms the state-of-the-art methods .
in this paper , we consider the problem of estimating the parameters of circular and strictly non-circular signals from a received mixture of circular and strictly non-circular signals . in particular , we consider the case where the signals are circular and strictly non-circular , and we show that the estimation accuracy of the standard esprit-based parameter estimation algorithms can be improved by exploiting the properties of c-nc unitary esprit algorithms and closed-form estimates . simulation results are provided to illustrate the effectiveness of the nc methods .
zero-shot learning of visual categories from textual descriptions such as wikipedia articles is a challenging problem . in this paper , we propose a novel approach for zero-shot learning of visual categories based on a deep convolutional neu-ral network . specifically , we propose to learn an embedding space for the modalities , which captures the semantic attributes of a visual category , and then learn a deep convolutional neu-ral network to predict unseen categories . we evaluate our approach on the caltech-ucsd bird and flower datasets , and show that our approach significantly outperforms the state-of-the-art methods . furthermore , we show that our approach is able to learn features that capture the semantic attributes of the visual category , and can be used to predict unseen categories using cnns . we also show that our approach is able to learn features that capture the semantic attributes of the visual category . finally , we evaluate our approach on the roc and precision-recall curves , showing that our approach outperforms the state of the art .
acoustic equalization in reverberant environments is a challenging problem due to the high variability of the sound field . in this paper , we propose a method to improve the equalizer robustness of acoustic equalization in reverberant environments . the method is based on the analysis of the wave equation of the sound field , which is a concise closed-form expression for the sensor movement . the proposed method is based on the analysis of the spherical harmonics and the statistical acoustics of the sound field . the experimental results show that the proposed method can improve the equalizer robustness of the directional microphone .
in this paper , a method for enhancement of hearing sensitivity is proposed . the method is based on the analysis of the external outer ear , i.e. , the elastic tympanic membrane and the external ear cavity subsystem . the finite element model is used to model human dissections and the eigenvalue problem is solved by solving a finite element model . the method is tested on the enhancement of hearing sensitivity in the presence of an external ear <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> this method is shown to be effective in reducing the sensitivity of the external outer ear .
in this paper , we propose a learning framework for image style transforms . in our learning framework , a coupled gaussian mixture model is used to represent the inter-space correlation information between the embedded hidden subspaces in the embedded spaces . the coupling between these embedded hidden subspaces is modeled by a coupled gaussian mixture model . the coupled gaussian mixture model is able to capture the inter-space correlation information in the forward transform and the backward transform vector spaces in the coupled gaussian mixture model . the coupled gaussian mixture model can be used as an mixture-model architecture , which allows efficient inference in the coupled gaussian mixture model . we demonstrate the effectiveness of the proposed learning framework on three tasks : face super-resolution and bidirectional portrait style transforms .
in this paper , we analyze the performance of a binary classification performance metric based on pr curves . we analyze the receiver operating characteristic curves in terms of the area under incoherent scale assumptions , and show that the area under which the pr curve is a convex hull of the f β score is a convex hull of the area of the pr curve , and that the area under which f β is the sum of the arithmetic mean of precision values is the sum of the area of the pr curve and the area under which f β is the sum of the area of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line is the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of the line of
sparse feature selection plays an important role in high-dimensional data . in this paper , we propose a novel nonconvex sparse group feature selection model for sparse group feature selection . the proposed nonconvex sparse group feature selection model is based on the nonconvex paradigm for sparse group feature selection . the proposed nonconvex sparse group feature selection model enjoys an oracle estimator , which can be efficiently solved by convex methods . moreover , the proposed nonconvex sparse group feature selection model can be easily applied to large-scale problems . extensive experiments on both synthetic data and real-world applications demonstrate that the proposed nonconvex sparse group feature selection model can significantly improve the accuracy of feature selection and parameter estimation .
in this paper , we investigate the effect of lombard speech on the inset speaker identification system performance . the influence of lombard speech on the inset speaker identification system performance is studied using the ut-scope database and the timit corpus . the results show that the effect of lombard speech on the inset speaker identification system performance depends on the type of noise and the type of noise . in addition , the effect of lombard speech on the inset speaker identification system performance degrades when the noise types are not present in the noisy lombard speech . in addition , the effect of lombard speech on the inset speaker identification system performance degrades when the noise types are not present in the noisy lombard speech . in addition , the effect of lombard speech on the inset speaker identification system performance degrades when the noise types are not present in the noisy lombard speech . in this paper , the effect of lombard speech on the inset speaker identification system performance is analyzed and the effect of lombard speech on the inset speaker identification system performance is evaluated . the results show that the effect of lombard speech on the inset speaker identification system performance degrades when the noise types are not present in the noisy lombard speech .
autism spectrum disorders -lrb- autism spectrum disorders -rrb- are known to be a major source of variability in perceived , and can be used to develop automated methods for identifying and analyzing autism spectrum disorders . in this paper , we investigate the relationship between the perceived and perceived -lrb- i.e. , the volume , intonation , and the speaking rate -rrb- of a story retellings with autism spectrum disorders . objective intonation variability features are used to characterize expressivity , and the classification task is performed on the basis of these acoustic-prosodic features . the results show that , in comparison with other diagnostic instrument algorithms , the proposed approach is able to distinguish between the perceived -lrb- i.e. , prosody , volume , and rhythm cues -rrb- and the subjective perceptions of prosodic -lrb- i.e. , prosody -rrb- of a story retellings with autism spectrum disorders . furthermore , the proposed approach is able to distinguish between the neutral and the female speakers with autism spectrum disorders . the results show that the proposed approach is able to distinguish between the female and the female speakers with autism spectrum disorders , and that the proposed approach is able to distinguish between the female and the female speakers with autism spectrum disorders .
we present a unified model for face detection and pose estimation from real-world , cluttered images . our unified model is based on mixtures of trees and tree-structured models for global elastic deformation . our unified model is motivated by the observation that the shape of a facial landmark can be represented as a collection of dense graph structures that capture the topological changes that exist in the image . our unified model can be used for pose estimation and landmark estimation in the wild '' annotated dataset . we demonstrate that our unified model outperforms state-of-the-art commercial systems on three challenging face benchmarks , including google picasa , google picasa , and google picasa . we also show that our unified model can be used for pose estimation , face detection , and pose estimation .
in this paper , we present a learning algorithm for a set covering machine . the learning algorithm is based on a simple and efficient learning algorithm from a simple and simple and efficient , and has a non trivial margin-sparsity trade-off . our learning algorithm is based on a simple and efficient learning algorithm from a simple and efficient , and can be easily applied to any set covering machine . we demonstrate the effectiveness of our learning algorithm by applying learning algorithm to a set covering machine , and show that learning algorithm is able to learn classifiers that are close to the optimal ones .
we present a top-down induction of decision trees method for clustering in both propositional and re-lational domains . the top-down induction of decision trees method is based on an order logical decision tree representation of the domain . we show that this top-down induction of decision trees method is competitive with instance based learning , and that top-down induction of decision trees method is superior to clustering in both propositional and re-lational domains .
in this paper , we present a novel approach to automatically generate syntactic structures for clue reranking and answer extraction . we first introduce a new dataset , webcrow , which is used to generate an answer list from a given set of images . then , we use webcrow as a baseline to generate a set of syntactic structures for clue reranking and answer extraction . finally , we use the original clue dataset to generate an answer list from the original dataset , and use the aggregated information such as answer position , average clue reranking scores to rank the final rank . we evaluate the effectiveness of our approach on cp resolution tasks . the experimental results show that our approach achieves the highest accuracy on the cp resolution tasks .
in many applications , such as voting systems and real-world preference aggregation , it is desirable to capture the preferences of a user 's preferences over a set of alternatives . in this paper , we consider the problem of determining single-, i.e. , determining the preferences of a user 's preferences over a set of alternatives . we consider the problem of determining the preferences of a user 's preferences over a set of alternatives , and study the problem of determining the preferences of a user 's preferences over a set of alternatives . in particular , we consider the problem of determining the preferences of a user 's preferences over a set of alternatives . we consider the problem of determining the preferences of a user 's preferences over a set of alternatives , and show that for a given incomplete preference profile , the problem of determining the preferences of a user is np-hard . we provide polynomial-time algorithms for computing the preferences of a user 's preferences over a set of single-peaked profiles , and show that the problem of determining the preferences of a user 's preferences is np-hard .
we consider combinatorial optimization problems where the goal is to find a subgraph h of g that maximizes the kl-divergence between the variables of a graphical model and the graph separation properties of the graphical model . we show that the problem of finding a subgraph h of g can be formulated as a decomposition tree representation of g , and that this decomposition tree representation can be used to represent g as a junction-tree representation of g . this junction-tree representation can be used to represent g as a function of the number of subgraphs of a subgraphical model . we show that this decomposition tree representation can be used to find the optimal graphical model for g , and that the complexity of g is exponential in the number of subgraphs of the subgraphical model . we also show that the complexity of g is exponential in the number of subgraphs of the subgraphical model .
in asian languages such as chinese , japanese , and chinese , there is a lack of bilingual lexicons for english-to-japanese back-transliteration . in this paper , we propose a method of string copying in latin script , which is suitable for multilingual applications . the method is based on the three-tier filtering process , which is based on attested bigrams , and is suitable for multilingual applications . in the proposed method , each character is represented by a set of language-specific mappings , and each word is represented by a set of ide-scripted representations . the experimental results show that the average precisions obtained by the proposed method are comparable to those obtained by the conventional method , and the average precisions obtained by the proposed method are comparable to those obtained by the standard www .
mapping surface electromyographic signals -lrb- emg signals -rrb- is an important component of silent speech interface . in this paper , we propose a novel method of mapping surface electromyographic signals to the speech signal in order to enhance the quality of the spoken speech . the proposed method is based on the mapping of emg signals from the facial muscles to the audible signal , and uses a gaussian mixture model to learn the mapping of emg signals from the speech waveforms . the mapping of emg signals from the emg signal to the speech signal is then used to modify the emg signal for the whispered speech . the experimental results show that the proposed method can significantly improve the conversion performance of emg-based speech-to-text systems for electrode , and the spectral distortion measure can be used to improve the conversion performance of spoken speech . furthermore , the proposed method can also be used to improve the conversion performance of whispered speech .
large-scale clustering is a fundamental problem in many large-scale clustering methods . in this paper , we propose a novel large-scale sparse clustering algorithm , which is based on a two-step optimization strategy for large-scale sparse clustering . unlike existing large-scale clustering methods , our large-scale sparse clustering algorithm does not require any refinement . instead , we propose a novel spis coding algorithm based on nonlinear approximation and dimension reduction techniques . the proposed large-scale sparse clustering algorithm does not require any extra training data and is applicable to large-scale data . experiments on both synthetic and real-world datasets show that our large-scale sparse clustering algorithm is able to achieve comparable or better clustering performance than state-of-the-art methods .
in this paper , we propose a nonlinear forward-search method for synthesizing reactive plans . our nonlinear forward-search method is based on the assumption that the safety and liveness rules of the reactive plans are independent of the actions of the planner . we show that our nonlinear forward-search method outperforms linear methods on a variety of benchmarks .
in this paper , we propose a weighted least squares filter design method for 2d linear-phase fir filter design . the proposed weighted least squares filter design method is based on the fact that the desired frequency response can be represented as an orthonormal basis , and the desired frequency response can be easily obtained by the proposed weighted least squares filter design method . in the proposed weighted least squares filter design method , the desired frequency response can be obtained by the proposed weighted least squares 2d linear-phase fir filter design . in the proposed weighted least squares filter design method , the number of filter coefficients can be reduced by the proposed weighted least squares filter design method . moreover , the proposed weighted least squares filter design method can be easily applied to various applications , such as quadrantally-symmetric filter design , and the experimental results show that the proposed weighted least squares filter design method can achieve the performance of the proposed weighted least squares filter design method .
we propose a multiplicative latent factor model for social networks with directed links . the multiplicative latent factor model is based on homophily modeling , and multiplicative latent factor model is a generalization of the multiplicative latent factor model to social networks . multiplicative latent factor model is a generalization of the minorization-maximization algorithm with linear-time complexity and convergence guarantee . we prove that multiplicative latent factor model can be viewed as a special case of homophily modeling , and prove that multiplicative latent factor model is a generalization of the minorization-maximization algorithm with linear-time complexity . we apply multiplicative latent factor model to social networks , and show that multiplicative latent factor model can be used to analyze network structure in real-world networks .
in this paper , we consider the problem of designing a nonorthogonal af protocol in wireless systems . we propose two orthogonal af cooperative protocols to improve the spectral efficiency of the amplify-and-forward protocol . the proposed orthogonal af cooperative protocols are based on minimizing the error rate of the amplify-and-forward protocol . simulation results show that the proposed orthogonal af cooperative protocols outperform the existing orthogonal af cooperative protocols in terms of spectral efficiency .
the proximal gradient algorithm is a convex analysis tool that has been widely used in many large-scale machine learning applications . in this paper , we propose a new algorithm , called overlapping group lasso , which is based on the proximal average of a proxi-mal map . we prove that the proximal gradient algorithm converges to a stationary point of the proximal gradient algorithm with a smoothing that converges to a stationary point of the proximal gradient algorithm . moreover , we prove that the proposed algorithm converges to a stationary point of the proximal gradient algorithm in o -lrb- 1 / √ t -rrb- , where t is the number of smooth functions , where t is the number of nonsmooth losses/regularizers . moreover , the overhead of the proximal gradient algorithm is independent of the size of the input data , which makes it suitable for large-scale machine learning applications . we also show that the proposed algorithm can be applied to a wide range of problems , such as the overlapping group lasso , the nonsmooth approximation , and its computational challenges .
in this paper , we consider the problem of estimating the wavelet coeecient partition functions of a fractional brownian motion in terms of both the time and the self-similar-stable process . in particular , we consider the problem of estimating the partition functions of a set of sample paths in a given set of sample paths . we show that for a given set of partition functions , this problem can be solved by an efficient estimation procedure . in particular , we show that , for a given set of sample paths , this estimation procedure can be applied to any given set of partition functions . in particular , we show that this estimation procedure can be used to find the optimal partition functions for a given set of sample paths . finally , we show that this estimation procedure can be used to find the optimal partition functions for a given set of sample paths .
joint object recognition and pose estimation in range images is an important computer vision problem that has wide applications in automated manufacturing environments and robotics applications . in this paper , we present a novel approach for joint object recognition and pose estimation in range images using dynamic programming . our approach is based on a random sampling based approach , which allows us to handle clear outliers in the range images . in the computationally expensive training phase , a local belief propagation is used to propagate color information between neighboring pixels in the range image . the proposed method is evaluated on real sequences and compared with state-of-the-art methods .
adaptive linear predictors -lrb- adaptive linear predictors -rrb- have been shown to perform better than linear predictors in real-time template tracking . however , in many applications , the template shape can be represented by full matrix inversion . in this paper , we propose a method for on-line modification of the adaptive linear predictors . the proposed method is based on the idea of pre-learned linear predictors , which can be used for real-time template tracking . we show that the proposed adaptive linear predictors can achieve better tracking performance than the conventional learning approaches . furthermore , we show that the proposed method can be used to control the template size in real-time . experimental results show that the proposed method can significantly reduce the template size while maintaining the same performance as the original learning approaches .
diffusion tensor mri is a non-invasive technique for studying anisotropic diffusion of water molecules in biological tissues . in this paper , we propose a level set formulation scheme for recovering radial brownian motion from a riemannian manifold m complex diffusion profiles . the level set formulation scheme is based on an exponential map to the distance function between the diffusion paths of water molecules . the proposed level set formulation scheme provides a direct mapping between the diffusion paths of water molecules to the riemannian manifold m complex diffusion profiles . the proposed level set formulation scheme is compared with the state-of-the-art methods on both synthetic and real diffusion mri datasets . the results show that the proposed level set formulation scheme is able to accurately reconstruct radial brownian motion from a brownian motion without global modelization . moreover , the proposed level set formulation scheme is able to reconstruct the geodesics of m complex diffusion profiles from the diffusion tensor .
in this paper , we address the problem of anomaly detection in mixed-type data . we propose a generalized linear model , which consists of a set of latent variables and a set of mixed-type attributes . the proposed generalized linear model consists of two components : -lrb- i -rrb- an error buffering approach , which is based on the posterior of high dimensional latent variables , and -lrb- ii -rrb- a non-gaussian design of the proposed generalized linear model . the proposed generalized linear model consists of two components : -lrb- i -rrb- a generalization of the generalized linear model , which allows us to incorporate the error buffering component into the generalized linear model , and -lrb- ii -rrb- a novel bayesian inference approach based on laplace approximation and computational optimizations . the proposed generalized linear model is evaluated on two mixed-type datasets and compared with the state-of-the-art anomaly detection in the machine learning field . the experimental results show that the proposed generalized linear model can achieve better anomaly detection performance .
phonological concepts and technical analysis play an important role in modeling and understanding of phonological processes . in this paper , we present an alignment technique for the phonological form of spontaneous sentences in italian clips corpus . first , we extract phonologi-cal replacement rules using a machine-learning algorithm . then , we extract conditional probabilities of the phonological pronunciation rules of the italian clips corpus , and construct a probabilistic rule set for each of these phonologi-cal replacement rules . the resulting rule is then used as a web-interface to determine the phonetic surface form of the italian speech . the resulting rules are then used as a rule for identifying regional italian accents . the results show that the phonological pronunciation rules of the italian clips corpus can be interpreted as a probabilistic rule set , and can be used as a tool for constructing phonological pronunciation rules .
affine projection algorithm -lrb- ap -rrb- has been widely used in active noise control applications . in this paper , we analyze the steady-state behavior of the affine projection algorithm in terms of the mean square error between the signal distribution and the signal distribution . we propose a computationally demanding modified filtered-x scheme for ap algorithms , and derive theoretical expressions for the steady-state behavior of the filtered-x affine projection algorithm . simulation results show that the proposed computationally demanding modified filtered-x scheme can significantly improve the performance of the affine projection algorithm in active noise control applications .
in this paper , we present a method for generating , generating , and generating apt , case-based , which is based on a web-driven , web-driven , case-based approach . in contrast to hand-crafted resources such as wordnet , our approach does not require hand-crafted resources such as wordnet , but instead does not rely on tacit knowledge . instead , it does not require a computational agent to specify , and it does not require any prior knowledge about the marked-ness of a language . our approach is based on a computational agent that generates , from a small set of examples , and generates , from a small set of examples , and then uses these examples to generate , generate , generate , generate , and generate , generate , and generate , and generate , among the cases that have been mentioned in the literature . our approach is based on the observation that , in spite of the simplicity of our approach , it does not rely on hard cases -lrb- non-explicit -rrb- , and it does not require any prior knowledge about the type of metaphor . we show that our approach is able to generate , and that it is able to generate , generate , generate , and generate , from illustrative examples , that are comparable to those generated by existing approaches .
co-localization in real-world images is a challenging problem due to the high intra-class variation , inter-class diversity , annotation noise , and intra-class variation . in this paper , we propose a joint image-box formulation for co-localization in real-world images . we formulate the co-localization problem as a convex quadratic program , which can be solved efficiently using a joint image-box formulation . we demonstrate the effectiveness of our joint image-box formulation on two challenging object discovery datasets , namely imagenet and imagenet , and show that our joint image-box formulation significantly outperforms state-of-the-art methods for co-localization in real-world settings .
vts adaptive training -lrb- vts -rrb- is one of the most popular approaches to noise robust speech recognition . in this paper , we propose discriminative vat , an extension of vts adaptive training to incorporate diverse noise-degraded training data into canonical models . in discriminative vat , the diagonal loading matrix of the diagonal corrupted speech covariance matrix is replaced by the kl-divergence between clean speech and noise . in discriminative vat , the diagonal loading matrices of the diagonal loading matrix and the diagonal loading matrices of the diagonal corrupted speech covariance matrix are jointly optimized . in discriminative vat , the kl-divergence between the diagonal loading matrices and the diagonal loading matrices is minimized . experiments on the aurora4 task and in-car collected data show that discriminative vat outperforms the baseline methods .
we present a statistical formulation for estimating 2-d human pose from single images . the human body configuration is formulated as an estimation problem in a markov network , and a data driven belief propagation monte carlo algorithm is derived using importance sampling functions derived from bottom-up visual cues . the markov network is used to infer the 2-d body shapes from hand labeled images . the proposed statistical formulation has several advantages over traditional bottom-up reasoning mechanisms : -lrb- 1 -rrb- it does not require image cues such as shape , edge , appearance , and -lrb- 2 -rrb- it does not require probabilistic inference . -lrb- 3 -rrb- it does not require any prior knowledge of the human body configuration , and -lrb- 3 -rrb- it does not require any prior knowledge of the image cues such as shape , edge , or appearance . -lrb- 3 -rrb- it does not require any prior knowledge of the human body configuration . -lrb- 3 -rrb- it does not require any prior knowledge of the human body configuration , and -lrb- 3 -rrb- it does not require any prior knowledge of the human body configuration . -lrb- 3 -rrb- it is shown that our statistical formulation can be applied to inference tasks involving single images .
high-level music descriptions play an important role in musical content . in this paper , we propose a novel dimensional contextual semantic model to capture the semantic relations between two music descriptions . the dimensional contextual semantic model is designed to capture the semantic relations between two music descriptions in a context-aware fashion . the dimensional contextual semantic model is built on two description models : categorical or dimensional models . the proposed dimensional contextual semantic model can be used to generate graded descriptions for both music description and retrieval . the experimental results show that the proposed dimensional contextual semantic model can significantly improve the retrieval performance of a semantic music search engine . furthermore , the proposed dimensional contextual semantic model can be applied to any semantic music search engine .
in this paper , we address the problem of language model adaptation for automatic lecture transcription . we propose a robust adaptation scheme based on keyword and topic information , which is based on plsa -lrb- probabilistic latent semantic analysis -rrb- . in order to improve the recognition accuracy , we propose a robust adaptation scheme based on the local preference between the presentation slide information and the content keywords . in the proposed robust adaptation scheme , a global topic adaptation based on keywords is performed by exploiting both global and local slide information . the experimental results on real lectures show that the proposed robust adaptation scheme can reduce the detection rate of content keywords and improve the performance of the cache model .
in this paper , we investigate the use of context-expanded region-dependent linear transforms for acoustic modeling in large vocabulary continuous speech recognition . context-expanded region-dependent linear transforms are trained using lattice-based discriminative training , long-span features , weight expansion , and contextual weight expansion . context-expanded region-dependent linear transforms are trained using the maximum mutual information criterion . lattice-based , boosted mmi training is used to combine context-expanded region-dependent linear transforms with hmms . the proposed context-expanded region-dependent linear transforms is evaluated on the switchboard-1 conversational telephone speech transcription task . compared with gmm-hmms , the proposed context-expanded region-dependent linear transforms achieves a relative word error rate reduction of 12.5 % , which is comparable to the conventional gmm-hmms . furthermore , the proposed context-expanded region-dependent linear transforms can be combined with hmms with context-expanded region-dependent linear transforms .
in this paper , we propose a closed form recursive solution for adaptive filters based on the maximum correntropy criterion . the proposed closed form recursive solution is a closed form of the maximum correntropy criterion for adaptive systems training . the proposed closed form recursive solution has two main advantages : -lrb- 1 -rrb- closed form recursive solution provides a closed form of the filter weights , -lrb- 2 -rrb- closed form recursive solution can be easily implemented in closed form , and -lrb- 3 -rrb- closed form recursive solution can be easily extended to non-gaussian cross-correntropy , and -lrb- 3 -rrb- closed form recursive solution can be easily extended to non-gaussian . the proposed closed form recursive solution is compared with the rls algorithm in terms of weighted least squares pdf s , and the results show that the proposed closed form recursive solution is much more efficient than gradient based training .
in this paper , we consider the problem of locating a subset of objects in an arbitrary polygonal environment using a deterministic search strategy . we focus on the problem of finding a subset of simply-connected n vertices in an arbitrary polygonal environment , where the goal is to find a subset of objects in the polygonal environment . we show that , under the minimum feature size assumption , the problem of finding a subset of simply-connected n-gons in an arbitrary polygonal environment is np-hard . we propose a deterministic search strategy to find a subset of segments that minimizes the maximum speed subject to a minimum feature size property . our deterministic search strategy is based on finding the minimum distance between a pair of discrete time steps , which is then used to find a subset of segments that minimizes the maximum speed subject to the minimum feature size assumption . our experimental results show that the proposed visibility-based pursuit and its variants outperform the existing o -lrb- log n -rrb- smoothers for line-of-sight detection in the presence of obstacles .
grapheme-to-phoneme conversion -lrb- g2p -rrb- is a challenging task due to the large number of structural constraints . in this paper , we propose a novel recurrent neural network language model for g2p conversion . the proposed recurrent neural network language model is based on an em-driven alignment algorithm that enforces the constraints on the source and target words . the alignment algorithm is implemented in a wfst-based g2p framework using an open-source toolkit . experimental results on two g2p datasets show that the proposed recurrent neural network language model significantly improves the word accuracy of g2p conversion .
in this paper , we study the minimal labeling problem of finding the minimal labeling of a set of temporal and topological relations using a qualitative constraint network . we propose two artificial intelligence approaches , the region connection calculus and the interval algebra , to solve the minimal labeling problem . the first approach is based on the patchwork property of the qualitative constraint network , and the second approach is based on the region connection calculus and the interval algebra . the third approach is based on the use of partial consistency , chordal qcns and the region connection calculus . the experimental results show that the proposed algorithms are competitive with the state of the art .
optical flow estimation algorithms have been widely used to solve ill-posed problems . however , most of the existing optical flow estimation algorithms focus on single or fixed data model . in this paper , we propose a novel approach to improve optical flow estimation energy model by incorporating complementary data models into the optical flow framework . specifically , we propose a locally varying data term to combine the complementary data models with a single or fixed data model . the complementary data models are designed to capture the matching ambiguity between the data and regularization terms in a locally varying data term . the complementary data models are optimized to minimize the weighted sum of the complementary data models . the complementary data models are then combined with a minimum description length constraint to reduce the matching ambiguity . experimental results on the middlebury optical flow benchmark show that our approach significantly outperforms state-of-the art methods .
in this paper , we present a method to automatically identify the semantic orientations of words in a lexicon . our method is based on the observation that the semantic orienta-tions of words in the lexicon are strongly correlated with the spins of electrons . we use a mean field approximation to derive an approximate probability function for the distribution of seed words in the lexicon , and use mean field approximation to approximate the distribution of the distribution of seed words in the lexicon . we evaluate the accuracy of our method on the english lexicon and show that our method is able to accurately estimate the semantic orientations of words with high accuracy . we also show that our method can be used for parameter selection in semantic ori-entations .
we consider the problem of learning the optimal linear decision boundary from labeled and pairwise examples . we consider the problem of learning the optimal decision boundary for a binary variable given a set of pairwise constraints . we show that the optimal decision boundary can be obtained by minimizing the asymptotic variance of the difference between the labeled and pairwise examples . we show that the optimal decision boundary can be obtained by minimizing the difference between the labeled and pairwise examples . we demonstrate the effectiveness of our approach on simulated datasets and real world classification datasets .
we present a generative , syntactic language model that uses n-gram language model estimation techniques to automatically parsed text . the generative , syntactic language model uses overlapping windows of linear context to learn n-gram language models from positive data . we show that our generative , syntactic language model outperforms state-of-the-art discriminative models for grammaticality tasks . we also show that our generative , syntactic language model can be used to generate sentences with overlapping windows of tree context . we also show that our generative , syntactic language model is competitive with generative baselines and n-gram models .
imbalanced prosodic unit boundary detection -lrb- imbalanced prosodic unit boundary detection -rrb- is an important issue in asr processing . in this paper , we propose machine learning techniques to improve imbalanced prosodic unit boundary detection for prosodically defined units . in the proposed machine learning techniques , prosodic boundary information is modeled by linguistically motivated prosodic features . in the proposed machine learning techniques , a decision tree classifier is trained on the defined prosodic units . the experimental results show that the proposed machine learning techniques can improve the performance of imbalanced prosodic unit boundary detection . bmpm is also shown to improve the performance of imbalanced prosodic unit boundary detection over c4 .5 .
in this paper , we present a novel approach to articulated object tracking based on a kinematic chain . the kinematic chain of an articulated object is represented by a set of feature trajectories , each of which is represented by a minimum spanning tree . each of these feature tra-jectories is represented by affine projections , which are represented by a set of segmented motion subspaces . these feature tra-jectories are then clustered using spectral clustering and local sampling . the novelty of our approach is that it does not require any prior knowledge of the structure or motion of the articulated object , and it does not require any prior knowledge of the structure or motion of the object . we demonstrate the effectiveness of our approach on several data sets , including challenging sequences of articulated objects .
in this paper , we propose a novel decision forest framework to address the object detection problem . the proposed decision forest framework is based on context-based decision criteria , which are learned from a context-sensitive decision forests-a new perspective . the contextual information is encoded by a context-sensitive decision forests-a new perspective , and the split criterion is used for regression mode selection . during classification training , the intermediate prediction is guided by tree-structured classifiers , and the split criterion is used for regression mode selection . the proposed decision forest framework is evaluated on the challenging tud data set , and is shown to outperform the state-of-the-art methods in pedestrian detection . in addition , the proposed decision forest framework is also shown to be effective in reducing inference time .
learning semantic representations for statistical machine translation is a challenging task . in this paper , we propose a neu-ral network model , bilingual correspondence recursive autoencoder , to jointly learn bilingual constraints and semantic and structural similarity features in an smt system . bilingual correspondence recursive autoencoder consists of two stages : -lrb- 1 -rrb- a joint objective to learn alignment-consistent phrase structures , and -lrb- 2 -rrb- a joint objective to minimize the cross-lingual reconstruction error , structural alignment consistency error , and recursive au-toencoder reconstruction error . -lrb- 3 -rrb- a novel neu-ral network model , called bilingual correspondence recursive autoencoder , is designed to capture the bilingual constraints between tree structures and bilingual phrase representations . -lrb- 3 -rrb- a bilingual correspondence recursive autoencoder is designed to capture both the semantic and structural similarity features in an smt system . experimental results on the nist chinese-english test sets show that bilingual correspondence recursive autoencoder significantly outperforms the state-of-the-art methods .
statistical dialog models -lrb- statistical dialog models -rrb- have been widely used in speech recognition systems . in this paper , we present a novel approach to improve system flexibility by adapting statistical dialog models to the user utterances in order to maximize the specifity rate of the speech recognition systems . the approach is based on the idea of dialog modeling , where the user utterances are represented by a set of natural spoken dialogs , and the user utterances are modeled by a reference system . the reference system is evaluated on an air travelling information system . the average dialog length of the reference system is reduced by up to 30 % compared to the average dialog length of the reference system . it is also shown that the proposed approach can improve system flexibility by up to 30 % .
in this paper , we propose a discriminative approach to incorporate information source models into the decoding graph , such as hidden markov models and n-gram models , into a single weighted finite state transducer . the wfst-based decoding process is performed by a linear classifier trained on structured data , such as sequential multiclass data . the wfst-based decoding process is performed by a distributed perceptron algorithm , where the training method is used to train a large-scale linear classifier . the proposed discriminative approach is evaluated on a large vocabulary continuous speech recognition task . the experimental results show that the proposed discriminative approach can effectively combine information source models into the decoding graph .
in this paper , we consider the problem of supervised clustering , where the goal is to find a subset of jointly generated messages that best explain the collective information of the email batches . we propose a novel approach for detecting batches of a user 's email batch based on collective attributes . we formulate the decoding problem in linear time , and propose an efficient sequential decoding procedure . we show that the proposed method can be applied to a wide range of email batches , and that it can be applied to any streaming nature . we also show that the proposed method can be applied to other decoding procedures , such as spam , to improve the performance of the sequential decoding procedure .
in this paper , we propose an application-specific approach to design low-power solutions for low-power solutions in a programmable environment . the low-power programmable dsp is based on the dynamic reconfigura-tion of hardware modules , which can be implemented in a programmable environment . the power dissipation of the low-power programmable dsp can be reduced by a factor of three , depending on the number of wireless communication components and the number of wireless communication components . in addition , the application-specific approach can be easily implemented in such a way that the power reduction of the low-power solutions can be reduced by a factor of four . the proposed application-specific approach can be applied to any low-power solutions in a programmable environment .
the equalization of audio systems using kautz filters is an important problem in audio signal processing . in this paper , we propose a new method for audio signal processing based on frequency warping and related resolution . kautz filters are used for equalization of audio systems . the proposed method consists of two steps : transfer function modeling , loudspeaker response equalization , and guitar body . in the first step , frequency warping is performed by allpass structures and la<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> in order to improve the auditory frequency resolution . in the second step , frequency warping is performed by using lamous filters and allpass structures . experimental results show that the proposed method can achieve better performance than conventional methods .
automatic speech recognition -lrb- automatic speech recognition -rrb- using tangent distance based on gaussian mixture densities has been shown to be effective in image object recognition . in this paper , we propose a gmd approach based on the tangent distance between two gaussian mixture densities for automatic speech recognition . in the proposed gmd approach , each observation vector is mapped into a manifold in a high dimensional feature space . in the proposed gmd approach , the model parameters are estimated in a probabilistic framework . in the proposed gmd approach , the observation vector is divided into two parts : -lrb- 1 -rrb- the prototype vector is estimated based on the minimum distance between the prototype vector and the prototype vector , and -lrb- 2 -rrb- the variance modelling is performed . the proposed gmd approach is evaluated on the sietill corpus and telephone line recorded german digit strings . experimental results show that the proposed gmd approach achieves better classification performance than the conventional classifiers .
this paper describes the i4u speaker recognition system developed for the nist 2008 speaker recognition evaluation . the i4u speaker recognition system includes cepstral features and classifiers . the i4u speaker recognition system has been evaluated on the nist 2008 speaker recognition evaluation -lrb- sre -rrb- . the i4u speaker recognition system has been submitted to the nist 2008 speaker recognition evaluation -lrb- sre -rrb- . the i4u speaker recognition system has been submitted to the nist 2008 speaker recognition evaluation -lrb- sre -rrb- . the i4u speaker recognition system has been evaluated by the nist 2008 speaker recognition evaluation -lrb- sre -rrb- . the i4u speaker recognition system has been evaluated by the national institute of standards and technology -lrb- nist -rrb- speaker recognition evaluation -lrb- sre -rrb- . the i4u speaker recognition system has been evaluated by the national institute of standards and technology -lrb- nist -rrb- speaker recognition evaluation -lrb- sre -rrb- . the i4u speaker recognition system has been submitted to the nist 2008 speaker recognition evaluation -lrb- sre -rrb- .
in this paper , we present a learning scheme for generating expressive music performances of monophonic jazz melodies from monophonic recordings . the proposed learning scheme consists of three components : a machine learning component and an expressive transformation model . the expressive transformation model is learned from the inexpressive melody descriptions generated by the induced expressive transformation model . acoustic features are extracted from monophonic recordings . the melody synthesis component is then used to generate a melody synthesis component for the expressive transformation model . the extracted acoustic features are then used to generate the expressive audio . experimental results show that the proposed learning scheme can generate highly expressive audio .
deep reinforcement learning -lrb- deep reinforcement learning -rrb- is a promising approach to modeling the dynamics of secondary agents in multi-agent settings . in this paper , we introduce a novel approach to opponent modeling in deep reinforcement learning . we introduce a mixture-of-experts architecture , which learns a policy for each agent 's actions and learns a policy for each agent 's actions . our approach is based on a combination of probabilistic models and parameterized strategies . we use multitasking to learn explicit modeling in the context of a deep q-network . we evaluate our approach on a simulated soccer game and a trivia game . our results show that our approach is able to learn a policy with supervision , and that it is able to learn a policy that is more robust to changes in the environment . we also show that our approach is able to learn a policy that is more robust to changes in the environment .
acoustic modeling based on hmms has been shown to improve speech recognition performance by incorporating phonetic detail into the speech recognition algorithms . in this paper , we compare the performance of two different approaches to acoustic modeling in speech recognition . the first approach is based on the idea of '' phonetic detail '' in speech recognition . the second approach is to combine the advantages of both approaches . the second approach is to combine the advantages of both approaches . the third approach is to combine the advantages of both approaches . the third approach is to combine the advantages of both approaches . the third approach is to combine the advantages of both approaches . the third approach is to combine the advantages of both approaches . the third approach is to combine the advantages of both approaches . the third approach is to combine the advantages of both approaches . the third approach is to combine the advantages of both approaches . the third approach is to combine the advantages of both approaches . the third approach is to combine the advantages of both approaches . the third approach is to combine the advantages of both approaches . the third approach is evaluated on a large vocabulary continuous speech recognition -lrb- lvcsr -rrb- task . the results are compared to the results obtained using both approaches .
we present a statistical parsing model that is capable of producing a lexicalised context-free grammar . the statistical parsing model is based on a probabilistic treatment of the genera-tive model of the lexicalised context-free grammar . the statistical parsing model is evaluated on the wall street journal text , and the results show that the statistical parsing model is able to achieve a constituent version of the wall street journal text , and that the statistical parsing model is able to achieve a better understanding of the wh-movement .
many problems in computer vision involve length based regularization . in this paper , we propose a new trust region framework for computing squared curvature . our trust region framework is based on the integral geometry of the integral geometry of the integral geometry , which allows us to compute submodular and super-modular pairwise potentials . we show that our trust region framework leads to high angular resolutions , while maintaining low angular resolution . we also show that our trust region framework can be used to compute distances between two elongated structures . we demonstrate the effectiveness of our trust region framework by comparing trust region framework to state-of-the-art methods .
sponsored search is a monetization channel for search engines . in this paper , we propose a game-theoretic machine learning approach based on game theory and machine learning . the auction mechanism is based on empirical revenue maximization . the auction mechanism is based on a bilevel optimization framework , where a markov model is trained on historical data , and a prediction period is learned by a genetic programming algorithm . this game-theoretic machine learning approach is applied to predict the revenue of the auction mechanism . the experimental results show that the proposed game-theoretic machine learning approach is effective in predicting the revenue of a user in a real world . the experimental results show that the proposed game-theoretic machine learning approach is effective in predicting the revenue of a user in a real world .
factor analysis based channel compensation methods have been widely used in speaker recognition . in this paper , we propose an acoustic factor analysis transformation based on feature dimensionality reduction , de-correlation , enhancement , and variance normalization . in the proposed acoustic factor analysis transformation , an afa parameter is estimated by probabilistic mixture alignment in the super-vector domain . in the proposed acoustic factor analysis transformation , the acoustic feature space is first transformed into a lower dimensional subspace using a factor analysis model , and then the acoustic feature eigenvector directions are transformed into a lower dimensional subspace using the low-rank covariance structure of cepstral features . in the proposed acoustic factor analysis transformation , the super-vectors are transformed into a lower dimensional subspace using the factor analysis model . in the proposed acoustic factor analysis transformation , the acoustic feature space is transformed into a lower dimensional subspace by the factor analysis model . experimental results show that the proposed acoustic factor analysis transformation can improve the performance of conventional signal sub-space based speech enhancement schemes .
in this paper , we propose a dl-based action language for knowledge-based programs with general domain knowledge in the description logic knowledge base . the dl-based action language is a restricted fragment of the logic knowledge base , where the agent 's knowledge is represented by a set of primitive actions and the programming constructs . the dl-based action language is designed to capture both physical and sensing actions in the description logic knowledge base . the dl-based action language is designed to capture both the physical and sensing actions in the logic knowledge base and the agent 's knowledge in the presence of a restricted fragment . the dl-based action language can be used to represent knowledge-based programs with a variety of test conditions and programming constructs . we show that this dl-based action language can be translated into a knowledge-based program , which can be used for verification in the presence of primitive actions and actions . we also show that this dl-based action language can be used to represent and reason about actions in the logic knowledge base .
in this paper , we propose a filler prediction model to improve the performance of a language model in speech recognition . the filler prediction model is based on the assumption that there are domain-relevant topics in the training data . the filler prediction model is trained on transcribed corpora , and the filler prediction model is used to predict fillers in the test data . the proposed filler prediction model is evaluated on a japanese national diet record . the experimental results show that the proposed filler prediction model is effective in improving the recognition performance .
information extraction -lrb- ie -rrb- systems attempt to extract protein names from biomedical text . most ie systems use undirected graphical models , such as conditional random fields , to model arbitrary dependencies . in this paper , we present statistical methods based on undirected graphical models , such as conditional random fields , to model arbitrary dependencies in relational markov networks . we show that these statistical methods improve the overall accuracy of the ie systems . we also show that the generalization of crfs -rrb- can be used to improve the performance of the ie systems .
this paper describes a hybrid speech recognizer combining hidden markov models and polynomial classifier . the hybrid speech recognizer consists of a polynomial classifier and a polynomial classifier . the emission probability is represented by a polynomial of gaussian distributions . the emission probabilities of the feature vector are estimated by a classifier . the emission probability is represented by a polynomial of gaussian distributions , and the density values of the feature space are estimated by a polynomial classifier . the emission probabilities of the polynomial classifier are estimated by a polynomial classifier . the proposed hybrid speech recognizer is evaluated on a conversational speech recognition task . the results show that the proposed hybrid speech recognizer outperforms the baseline system .
in this paper , we present a graphical model framework for pitch tracking parameters . the graphical model framework is based on a maximum likelihood sense , which allows us to incorporate probabilistic dependencies between pitch estimation and voicing decision . the graphical model framework is based on a graphi-cal model toolkit for probabilistic inference in the maximum likelihood sense . the graphi-cal model toolkit transition cost functions can be used to derive pitch trackers , which can be used for parameter tuning and parameter tuning . the graphical model framework can be used in conjunction with dynamic programming for pitch trackers . experimental results show that the proposed graphical model framework can be used to estimate pitch tracking parameters in real time .
supervised learning from large quantities of unsupervised data has been shown to be very effective in many nlp tasks . in this paper , we propose a semi-supervised learning technique to learn representations from large sets of unsupervised data for supervised learning . specifically , we propose to use a small number of unsupervised data to learn informative ` and low-dimensional feature spaces ' for supervised learning . in particular , we apply ptb-iii to dependency parsing data , and show that ptb-iii can effectively learn features from large sets of unsupervised data for supervised learning . moreover , we show that our semi-supervised learning technique can be used to learn features from large sets of unsupervised data . experiments on conll-2003 ner data show that ptb-iii can effectively learn features in dense and low-dimensional feature spaces .
ordinary least squares -lrb- ordinary least squares -rrb- is a popular default method for linear models . ordinary least squares is a generalized version of ordinary least squares , but ordinary least squares is not guaranteed to converge to the true solution . in this paper , we show that ordinary least squares can be viewed as ridge regression , and that ordinary least squares can be viewed as a special case of ordinary least squares . we show that ordinary least squares can be viewed as a combination of least squares fitting and hard thresholding . we show that ordinary least squares can be viewed as a special case of ordinary least squares , and that ordinary least squares can be viewed as a special case of ordinary least squares . we show that ordinary least squares can be viewed as a special case of ordinary least squares , and that ordinary least squares can be viewed as a special case of ordinary least squares . we show that ordinary least squares can be viewed as a special case of ordinary least squares , and we show that ordinary least squares can be viewed as a special case of ordinary least squares , and we prove that ordinary least squares can be viewed as a special case of ordinary least squares . we also show that ordinary least squares can be viewed as a special case of ordinary least squares , and that ordinary least squares can be viewed as a special case of ordinary least squares fitting . we show that ordinary least squares can be viewed as a special case of ordinary least squares , and that ordinary least squares fitting can be viewed as a generalized version of ordinary least squares . we show that ordinary least squares can be viewed as a special case of ordinary least squares fitting , even though its sample size can be significantly faster than ordinary least squares fitting , even though its sample size can be arbitrarily close to the true solution .
in this paper , we investigate the effect of corpus size on supervised and unsuper-vised learning for improving the performance of disambiguation of a large unannotated corpus of newswire text . we use a collins ' parser trained on the wall street journal to obtain a supervised component of the collins ' parser . we show that lexical statistics extracted from the unannotated corpus of newswire text can be used to improve the performance of both supervised and unsuper-vised learning for the task of corpus size . we also show that the unsupervised component of the collins ' parser can be used to improve the performance of both supervised and unsuper-vised learning for the task of corpus size .
automatic topic segmentation plays an important role in multimedia archival and retrieval systems . in this paper , we present a novel approach to topic segmentation based on statistical natural language processing and information retrieval techniques . the approach is based on a combination of statistical natural language processing and machine learning . we evaluate the performance of the proposed approach on the english and mandarin tdt3 corpora . the results show that the proposed approach outperforms the baseline system on the manually segmented corpus and the baseline system on the english and mandarin tdt3 corpora .
in this paper , we introduce the materials in context database , a well-sampled dataset for material recognition in the wild . the materials in context database is a large-scale , open dataset of materials in the wild . the materials in context database is a well-sampled dataset containing rich surface texture , lighting conditions , clutter , and clutter . the materials in context database is a set of real-world materials with rich surface texture , lighting conditions , and clutter . we use convolu-tional neural networks -lrb- cnn -rrb- to learn a set of patches for classifying materials . these patches are then used for recognizing materials in the wild . we show that patch-based classification can be used to improve the mean class accuracy of cnn classifiers for recognizing materials in the wild . we also show that deep learning can be used for material recognition . we also show that our materials in context database can be used to improve the performance of real-world material recognition in the wild .
in this paper , we propose a data-driven approach to estimating a binary mask estimator for the snr of a time-frequency unit . the proposed data-driven approach is based on the decision-directed approach , where the instantaneous snr is estimated by localized bayes risk . the proposed data-driven approach is evaluated by comparing the performance of the binary mask estimator with that of the conventional binary mask estimator in terms of the sensitivity metric for the snr classification . the results show that the proposed data-driven approach outperforms the well-known binary mask estimator in terms of both the a priori snr and the a posteriori snr . furthermore , the proposed data-driven approach is able to estimate the snr of the binary mask estimator in terms of the sensitivity metric for the snr classification . furthermore , the proposed data-driven approach is able to estimate the local snr of the binary mask estimator in terms of the false alarm rates .
in this paper , we present a large-scale electronic corpus , which is constructed from a large corpus of japanese . the corpus consists of a large number of japanese and a large corpus of ko-, each of which has a grammatical form , such as the ko-the relation . the corpus consists of the japanese language and the japanese part of the japanese language . the corpus consists of the japanese part of the japanese language and the japanese part of the japanese part of the japanese language . the corpus consists of the japanese part of the corpus and the japanese part of the corpus . the japanese part of the corpus consists of the japanese part of the corpus and the japanese part of the japanese part of the corpus . the japanese part of the corpus consists of the japanese part of the corpus and the japanese part of the japanese part of the corpus . the japanese part of the corpus consists of the japanese part of the corpus and the japanese part of the japanese part of the corpus . the results of the experiment show that the corpus can be used to verify the construction of the corpus .
zero-anaphora resolution problem is an important problem in intra-sentential and inter-sentential zero-anaphora resolution . in this paper , we propose a learning-based anaphora resolution model that uses rich syntactic pattern features to capture intra-sentential zero-anaphora . we show that our learning-based anaphora resolution model achieves high accuracy in zero-anaphora resolution , and that our learning-based anaphora resolution model is able to utilize rich syntactic pattern features to improve intra-sentential zero-anaphora . we evaluate our learning-based anaphora resolution model on japanese , and show that our learning-based anaphora resolution model achieves the best accuracy in zero-anaphora resolution .
in this paper , we propose a novel gesture recognition system based on a 3-axis accelerometer . the proposed gesture recognition system is based on a combination of dynamic time warping and affinity propagation algorithms . first , a dictionary of gestures is extracted from the gesture sequence . second , a compressive sensing is used for gesture recognition . third , the proposed gesture recognition system is applied to the task of acceleration-based gesture recognition . the experimental results show that the proposed gesture recognition system outperforms the state-of-the-art statistical methods in terms of user-independent recognition accuracy and user-dependent recognition performance . the proposed gesture recognition system is also shown to be very effective in published studies .
in this paper , we propose a novel atom schedule method to improve the efficiency and efficiency of a system . specifically , we consider the problem of profit-driven decisions , where the goal is to maximize the revenue of the driver 's strategy space . we assume that the driver 's strategy space is a sum of a set of scheduling constraints , and the goal is to minimize the sum of the revenue of the driver 's strategy space . we assume that the driver 's strategy space is a sum of a set of infeasible pure strategies , and the goal is to minimize the market variance . we show that the proposed atom schedule method can be applied to the problem of improving the efficiency of the proposed atom schedule method . in addition , we show that the proposed atom schedule method can also be used to improve the efficiency of a system with computational inten-siveness .
this paper describes an information-state dialogue manager with interactive information components . this information-state dialogue manager is used to train a spoken dialogue system for call fire radio dialogues in artillery fire missions . the information-state dialogue manager is designed to make use of the information contained in the interactive information components of the spoken dialogue system .
this paper presents a study on the production of sibilant fricatives using acoustic and articulatory data from cine magnetic resonance images , dimensional vocal tract reconstructions , and tongue surface shapes . the results show that the tongue surfaces of the sibilant fricatives are highly correlated with the primary closure of the tongue , and that the constriction of the tongue surface shapes and the constriction locations of the tongue are strongly correlated with the acoustic spectra of the tongue and the tongue surfaces of the tongue . the results suggest that air flow avoiding for missing unilateral tongue tissue is not sufficient for precise tongue control , but also for precise tongue control .
this paper presents a java framework for rapid application of gui based speech processing applications . standard components in java programs include the spectrogram , power plot , and the speech signal , and the external pitch values . the java framework is designed for the rapid application of gui based speech processing applications . the java framework is based on an object-oriented design of the speech file , and the integration of standard components into java programs . the evaluation of the java framework is carried out through transcription of the speech file . the evaluation results show that the proposed java framework can be used for rapid application of gui based speech processing applications .
we propose a novel network topology estimation strategy based on mixture models with unicast end-to-end packet pair delay measurements . the proposed network topology estimation strategy uses a hierarchical topology construction algorithm to determine the number of leaf nodes in the network tree and the number of leaf nodes in the tree is determined by the map criterion . the proposed network topology estimation strategy is able to discover the number of mixture components automatically by unsupervised learning algorithms . the proposed network topology estimation strategy is based on the assumption that the number of leaf nodes in the network tree is small and the number of clusters in the network is small . the proposed network topology estimation strategy is compared with the state of the art in terms of both speed co-variances and number of clusters . the network topology estimation strategy is shown to be effective in identifying the number of clusters in the network .
chaotic systems based on recurrence time statistics have been widely used for stationarity change in speech recognition in noisy environments . in this paper , we propose a recurrence point variability algorithm for the detection of state transitions in nonstationary and transient time series . the proposed recurrence point variability algorithm is based on a fractal structure of the time series , and is able to detect the presence of noise in the presence of nonstationary and transient time series . the proposed recurrence point variability algorithm is applied to the detection of state transitions in the presence of noise . the experimental results show that the proposed recurrence point variability algorithm is able to detect the presence of nonstationary and transient time series in noisy environments . moreover , the proposed recurrence point variability algorithm is able to detect the presence of nonstationary and transient time series in the presence of noise . the results show that the proposed recurrence point variability algorithm is effective in speech recognition in noisy environments .
answer set programming -lrb- asp-dpop -rrb- is a powerful tool for solving distributed constraint optimization problems in multi-agent problems . in this paper , we present asp-dpop , a novel dcop algorithm for solving distributed constraint optimization problems with logic programs . asp-dpop is a generalization of answer set programming to logic programs , which allows us to solve distributed constraint optimization problems with memory limitations . experimental results show that asp-dpop is competitive with the state of the art .
decision trees are widely used in knowledge discovery and data mining problems . in this paper , we present a boosting algorithm for decision trees . the decision tree is a variant of the quinlan 's c4 .5 algorithm , which is a boosring ensemble of a decision tree . the decision tree is constructed by maximizing the information ratio criterion , which is a function of the probability distribution of the training data . we prove that the boosting algorithm is a generalization of the well-known boosting algorithm for decision trees . we also present experimental results that show that the proposed boosting algorithm is superior to the quinlan 's c4 .5 algorithm .
cross language classification aims to learn label knowledge from parallel documents . however , most existing domain adaptation methods and multi-view learning methods are not applicable to multilingual text classification problems . in this paper , we propose a subspace co-regularized multi-view learning method for cross language text classification using machine translation on parallel corpora . the proposed subspace co-regularized multi-view learning method is based on the idea of machine translation , which aims to reduce the labeling cost of a classification model . the proposed subspace co-regularized multi-view learning method is evaluated on two cross language text classification tasks . the experimental results show that the proposed subspace co-regularized multi-view learning method significantly outperforms the state-of-the-art inductive methods . moreover , the proposed subspace co-regularized multi-view learning method can be easily extended to multilingual text classification problems .
in this paper , we address the problem of semi-supervised dimensionality reduction from facial images obtained from stereo videos . we propose a novel approach to semi-supervised dimensionality reduction using multiple representations of the image data . the proposed method is based on a linear combination of the locality information and a priori pairwise information . the projection matrix of the projection matrix is used to estimate the projection matrix for each pair of images . the label information is obtained by maximizing the must-link and cannot-link constraints between the two data representations . the proposed method is applied to the problem of person identity label propagation in stereo movies , and the results show that the proposed method outperforms state of the art methods . moreover , the proposed method can be applied to other applications such as person identity label propagation in movies .
in this paper , we propose a novel framework for unsupervised ensemble learning based on crowdsourcing . in our framework , each hidden node is represented by a restricted boltzmann machine , and each hidden node is represented by a set of classifiers with a conditional independence assumption . in order to learn the posterior probabilities of each hidden node , we propose to use the rbm-based deep neural net to learn the parameters of each hidden node . the proposed framework is evaluated on both simulated and real-world datasets , and the experimental results show that the proposed framework outperforms the state-of-the-art deep learning methods .
in this paper , we consider the problem of recovering a sparse green 's function from seismic experimental data . we propose a novel variable projection technique for sparse signal and auxiliary parameters , which is based on variable projection and spar-sity promoting optimization . the proposed variable projection technique exploits auxiliary information in the signal of interest to improve the performance of deconvolution techniques . the proposed variable projection technique is applied to a seismic imaging example , where a source signature is represented by a sparse green 's function , and the target signature is represented by a sparse green 's function via sparsity optimization . the experimental results show that the proposed variable projection technique can significantly improve the performance of sparse signal and auxiliary parameters in large-scale sparse deconvolution problems .
in this paper , we consider the problem of signal recovery in shift-invariant spaces with partial frequency content . we consider the problem of signal recovery in shift-invariant spaces , where the signal bandwidth is unknown , and the signal bandwidth is unknown . we propose a method for signal recovery in such shift-invariant spaces by exploiting the properties of the partial frequency content of the signal . the proposed method is based on pre-processing to improve the reconstruction ability . simulation results demonstrate the effectiveness of the proposed method .
in this paper , we present waiting cycle analysis of h. 246 decoder run on the pac duo platform . waiting cycle analysis is a key component of dual-core decoders such as cache miss , resource contention , inter-core synchronization , and inter core synchronization . waiting cycle analysis is a key component of our waiting cycle analysis . in this waiting cycle analysis , data partition , function partition and dual core data partition are performed on the dual core in order to reduce the execution speed of the dual core in multi core scenarios .
pathological speech is often associated with unhealthy social behavior , voice abuse , and disease . in this paper , we propose a novel approach to intelligibility detection in pathological speech based on asymmetric sparse kernel partial least squares classifier . the proposed approach is able to distinguish between normal and pathological voices by exploiting the physical problem in the speech production system . the proposed method is tested on a database of pathological voices , and it is shown that the proposed method is able to distinguish between normal and pathological voices with illness and unhealthy social behavior . furthermore , it is shown that the proposed method is able to distinguish pathological voices with unhealthy social behavior and voice disorders . the proposed method is also shown to improve the un-weighted accuracy of automatic intel-ligibility detection .
in this paper , we present a novel approach to dialog act tagging based on support vector machines and hidden markov models . in contrast to traditional sequence labelling algorithms which estimate posterior probabilities from text and acoustic features , our approach combines sparse high-dimensional text features and dense low-dimensional acoustic features . we evaluate our approach on the hcrc maptask corpus , and show that our approach outperforms the state of the art . we also show that our approach is competitive with support vector machines .
we consider the problem of learning non-linear kernels for low-dimensional and dense features , such as object detection and fisher kernels for image classification . in particular , we consider the problem of learning a product quantisation from sparse feature encoding . we propose a general framework for learning arbitrary additive kernels based on bundle optimisation methods . we show that sparse features can be used to learn arbitrary kernels , and that sparse features can be efficiently computed using bundle optimisation methods . we show that the intersection kernel can be used for learning a sparse feature encoding for a product quantisation . we demonstrate the effectiveness of our approach on pascal voc data , and show that it outperforms the state of the art in both high-dimensional and sparse ones . furthermore , we show that our approach can be applied to deformable part models , and that it can be used for learning a large number of features .
in this paper , we propose a weighted sum rate optimization for the mimo interfering multiple access channel . the weighted sum rate optimization is formulated as a noncooperative game , where the bs congestion is assumed to be known at the base station -lrb- bs -rrb- and the base station -lrb- bs -rrb- is assumed to be known at the base station -lrb- bs -rrb- . we formulate the weighted sum rate optimization problem as a weighted sum rate optimization problem with a stationary solution . we show that the nash equilibrium of the weighted sum rate optimization problem converges to a stationary solution of the weighted sum rate optimization problem . numerical results show that the proposed weighted sum rate optimization outperforms the conventional linear procoders in terms of user fairness and user fairness .
in this paper , we present a method for generating textual descriptions that can be used to describe and interpret the context of a set of object descriptions . the approach is based on two steps : -lrb- 1 -rrb- selecting appropriate descriptions for a set of objects , and -lrb- 2 -rrb- selecting appropriate descriptions for a set of objects in the set of examples . we demonstrate the effectiveness of the approach by comparing it with existing approaches . we also show that the approach is able to generate descriptions that are not only visually relevant to the user , but also visually relevant to the user .
we present an unbiased linear systems solver for unbiased estimation of gradients in gaussian process regression . the unbiased linear systems solver is based on the idea that the covari-ance of the posterior distribution of the gaussian processes can be modeled as linear systems with negligible bias . the proposed unbiased linear systems solver is based on the idea that the covari-ance of the covariance parameters can be expressed as a function of the covariance parameters of the gaussian processes . the proposed unbiased linear systems solver is able to estimate the variance of the variance of the posterior distribution of the covariance parameters , and can be used to estimate the variance of the posterior distribution of the unbiased linear systems solver . the unbiased linear systems solver is based on a novel extension of the stochastic gradient langevin dynamics algorithm , which allows for the quantification of uncertainty . we demonstrate the effectiveness of the proposed unbiased linear systems solver by applying the proposed unbiased linear systems solver to the problem of unbiased estimation of gradients in ulisse -lrb- ulisse -rrb- .
ontology-based conjunctive query answering -lrb- ontology-based conjunctive query answering -rrb- is a semantic definition for ontology-based query answering . ontology-based conjunctive query answering is defined as a set of existential rules -lrb- e.g. , data dependencies -rrb- that capture disjunctive embedded dependencies between queries . in this paper , we propose a novel approach to ontology-based query answering based on existential rules -lrb- e.g. , data dependencies -rrb- . the approach is based on a built-in linear order , which allows for expressive completeness . we show that the proposed approach can be implemented in ocqa ontologies , and that it can handle any class of embedded dependencies . we also show that the expressive completeness of ontology-based query answering can be achieved by exploiting the class of disjunc-tive -lrb- i.e. , the class of embedded dependencies -rrb- . we evaluate our approach on two databases and show that it outperforms the state of the art .
linear antenna array processing -lrb- linear antenna array processing -rrb- is a powerful tool for reconstructing a compact object from its contour . classical ap techniques for shape reconstruction can be formulated as a mathematical inversion problem . however , the inverse problem can be solved using a bayesian estimation approach . in this paper , we propose a new method for shape reconstruction based on a bayesian estimation approach . the shape reconstruction is formulated as a mathematical inversion problem , which can be solved efficiently . we demonstrate the effectiveness of the method on x ray tomography .
we present a novel approach to 3d scene generation that leverages recent advances in rule-based methods for 3d scene generation . in contrast to previous approaches , our approach does not rely on manually specified object categories or on natural language descriptions . instead , we propose a grounding approach that uses human judgments to generate tex-tual descriptions for physical objects . our grounding approach is based on the idea that the physical objects in the scene can be represented as a collection of tex-tual descriptions , which are then used to generate map descriptions of scenes . we show that our grounding approach outperforms previous approaches on the 3d scene generation task . we also show that our grounding approach can be used to generate natural geometric representations of the objects in the scene . finally , we show that our grounding approach can be used to generate natural language descriptions of the objects in the scene .
in this paper , we propose layered models for static scene segmentation , where the optical flow in layers is modeled as a parametric model , where the optical flow is modeled by a smooth deviation . we propose a probabilistic graphical model that explicitly accounts for both occlusions and a novel probabilistic model of image motion estimation in natural scenes . the probabilistic graphical model explicitly accounts for the uncertainty in the appearance of smooth surfaces , and provides a robust spatial prior for layer segmentation . the probabilistic graphical model can be used to infer meaningful scene segmentations in natural scenes , such as detected occlusion regions , and also to infer the temporal consistency of the mrf . we demonstrate the effectiveness of our probabilistic graphical model on the middlebury benchmark . in addition , we show that our probabilistic graphical model outperforms state-of-the-art algorithms in terms of accuracy on the middlebury benchmark . furthermore , we show that our probabilistic graphical model is able to accurately predict the depth of smooth surfaces , even when the optical flow is not known , and that our probabilistic graphical model is able to accurately predict the depth of a scene in a wide variety of natural scenes .
in this paper , we propose a novel post-processing technique to improve the feature robustness of robust speech recognition for speech separation in very low signal-to-noise ratios . in speech separation , the noisy mixture is first used to extract robust features from the noisy mixture . then , a neural network classifier is adopted to combine the local information of the noisy mixture with the local information provided by monaural features . in speech separation , the classification problem is formulated as a classification problem and the temporal trajectories of feature dimensions are used to classify speech in low signal-to-noise ratios . experimental results show that , in the snr level of-5 db , the feature robustness for speech separation is significantly improved compared to that of the multi-resolution , multi-resolution , and the fusion of monaural features with the local information provided by the neural network classifier is superior to that of the conventional post-processing technique for robust speech recognition .
this paper presents a method for learning locally linear generative models for recognition . the local deformations are represented by tangent vectors in the sample covariance matrices . an em-based algorithm is used to estimate the parameters of the model . the local deformations are modeled by mixtures of linear models . the proposed method has been tested on pixel-based images of digits . the results show that the proposed method outperforms existing methods .
in this paper , we investigate how cfg filtering techniques can be applied to ltag hpsg . we compare the performance of ltag hpsg with that of ltag hpsg using cfg filtering techniques . we find that the performance of ltag hpsg is comparable to that of ltag hpsg using cfg filter .
many nlp tasks , such as parallel named entity pairs , have been shown to be useful for training transliteration systems . in this paper , we propose a mining methodology for mining the parallel named entity transliteration pairs from comparable corpora . we first use a well-trained linear classifier to extract transliteration pairs from comparable corpora . then , we propose a new mining methodology to mine the parallel named entity transliteration pairs from comparable corpora . we evaluate our mining methodology on tamil and show that our mining methodology significantly improves the performance of training transliteration systems . we also show that our mining methodology can be applied to other languages , such as tamil and tamil , and that our mining methodology can be easily applied to other languages . we also show that our mining methodology can be applied to other languages , such as tamil .
in this paper , we consider the problem of parameter estimation in the presence of nuisance parameters in the estimation process . in particular , we consider the problem of estimating the parameters of a computationally-intensive esti-mator when the unknown parameters are unknown . we propose a fast , approximate map estimator , which is based on a maximum a posteriori -lrb- map -rrb- estimator . the proposed approximate map estimator can be viewed as an extension of monte carlo to the problem of estimating the parameters of a computationally-intensive i n tegrations . we show that the proposed approximate map estimator can be viewed as a fast , approximate maximum a posteriori probability estimator , which can be applied to a wide range of estimation problems . we illustrate the effectiveness of the proposed approximate map estimator by comparing its performance to the well-known approximate map estimator in the presence of nuisance parameters in the estimation process .
in this paper , we propose a method for acoustic feedback cancellation using two microphones and transform domain processing . the first approach is based on the use of orthogonal transforms to reduce the undesired signal correlation between the speech signals and the real measured feedback paths . the second approach is based on the use of a discrete cosine transform to represent the adaptive filter signals . in the adaptation process , the incoming signal estimate is obtained by exploiting the correlation between the received signal and the desired signal . in the second approach , the residual signal is transformed into an error signal and the desired output signal is transformed into a canceler . in the third approach , the coefficients of the adaptive filters are estimated using the discrete cosine transform . the convergence rates of the proposed method are compared with the conventional microphones approach . the experimental results show that the proposed method can improve the performance of the adaptive filters in terms of both speech signals and real measured feedback paths .
goal recognition design problems for stochastic grd problems are considered . the goal recognition design problems are stochastic action outcomes , which are stochastic action outcomes , and the goal is to maximize the expected utility of the actions . the goal recognition design problems for stochastic grd problems are modeled as markov decision process based algorithms , where the goal is to minimize the expected utility of the stochastic grd problems . the objective is to minimize the expected utility of the stochastic grd problems subject to a worst-case distinctiveness measure , which is the sum of the expected utility of the stochastic grd problems . the objective is to minimize the expected reward of the stochastic grd problems subject to a certain constraint on the quality of the observed actions . we propose a novel algorithm , called wcd , that computes the expected reward of the stochastic grd problems subject to a certain constraint on the quality of the observed actions . the algorithm is evaluated on two real-world problems : -lrb- 1 -rrb- the wheel slippage wcd , and -lrb- 2 -rrb- the wheel slippage wcd . the experimental results show that the proposed algorithm outperforms the state-of-the-art algorithms .
in this paper , we propose a novel iterative graph cuts based algorithm for 3d reconstruction of non-lambertian objects . the proposed iterative graph cuts based algorithm is based on the surface distance grid , which is a signed distance transform between the object surface and its surface extrusions . in contrast to volumetric graph cuts , the proposed iterative graph cuts based algorithm does not require any discretization bias nor minimal surface bias . instead , the proposed iterative graph cuts based algorithm takes into account surface smoothness in the 3d space . the surface distance grid is constructed by minimizing a cost function defined on the surface distance grid . the proposed iterative graph cuts based algorithm is evaluated on the 3d reconstruction of non-lambertian objects . the experimental results show that the proposed iterative graph cuts based algorithm outperforms the state-of-the-art methods in terms of both surface reconstruction and surface smoothness .
co-simrank is a simrank-like measure of similarity based on the graph structure . in this paper , we propose a novel matrix decomposition based method on singular graphs . the proposed matrix decomposition based method computes the co-simrank score of a given graph by computing the pagerank vectors of a given pair of vectors . the proposed matrix decomposition based method can be used to compute the co-simrank score of a given pair of vectors . experimental results show that the proposed matrix decomposition based method is very efficient and effective .
automated musical accompaniment of human performers is a challenging problem due to the large-scale structural variation in the branching structure of the human performer . in this paper , we present an on-line algorithm for the following automated musical accompaniment of human performers . the score form is represented by a written score , and a markov model is learned from the written score . the score form is then used to estimate the probability of a human performer . the proposed on-line algorithm is evaluated on a melodic corpus of 98 jazz melodies . experimental results show that the proposed on-line algorithm is able to significantly reduce the number of errors in the score form , and that the proposed on-line algorithm is able to achieve comparable or better performance than the state-of-the-art approaches .
switching linear dy-namical systems , such as hidden markov models and linear dynamical systems , have been shown to be effective in modeling speech . however , the assumption of independent segments in speech is not satisfied by a discrete state sequence . in this paper , we propose a novel approach to switching linear dy-namical systems , which is an intractable model of speech . the proposed approach is based on a proposal mechanism for switching linear dy-namical systems , where the probability of each segment is estimated by a stochastic segment model , and the likelihood of each segment is estimated by a stochastic segment model . inference is carried out on the arpa resource management task . the experimental results show the effectiveness of the proposed approach .
energy detection is a fundamental problem in cognitive radios for spectrum sensing . in this paper , we propose a novel energy detector for energy detection in weak primary user signals . the primary users are equipped with a set of su signals , and the secondary users are equipped with a set of antennas . the primary users are equipped with a set of secondary users , and the secondary users are equipped with a set of secondary users . the primary users are equipped with a set of secondary users , and the secondary users are equipped with a set of secondary users . the primary users are equipped with a set of secondary users , and the secondary users are equipped with a set of secondary users . the secondary users energy detector is designed to minimize the number of secondary users required for energy detection . simulation results show that the proposed energy detector is able to achieve the same level of energy detection performance as the conventional energy detector .
in this paper , we consider the problem of sparse coding and dictionary learning in a dictionary learning framework , where the input data is represented by a set of dictionary blocks , and the goal is to learn a dictionary that minimizes the intra-block coherence between the dictionary blocks . we propose a framework for dictionary learning and optimization problems for sparse coding based on block-gradient descent , which can be solved efficiently by exploiting the relationship between the block structure and the group structure of the input data . we propose two efficient optimization algorithms for both sparse coding and dictionary learning . the first algorithm is based on the assumption that the intra-block coherence of the input data is independent of the intra-block coherence of the input data . the second algorithm is based on the assumption that the intra-block coherence of the learned dictionary blocks is independent of the block structure and the group structure of the input data . experimental results on well-known datasets demonstrate the effectiveness of the proposed method .
in this paper , we propose a novel adaptive diffusion strategy with limited communication overhead . the proposed adaptive diffusion strategy is based on a maximal-ratio-combining rule , where each node is equipped with a set of interacting nodes . the interacting nodes are modeled by a set of combination coefficients , and the weights of the interacting nodes are updated based on their combination coefficients . simulation results show that the proposed adaptive diffusion strategy achieves a significant improvement in communication overhead compared to the conventional adaptive diffusion strategy .
in this paper , we propose a novel space-time video summarization method based on the3rst-jt und graph cut optimization techniques . in the proposed space-time video summarization method , each video volume is represented by a space-time video montage time axis , and each video volume is represented by a volumetric la.others . in the proposed space-time video summarization method , each video volume is represented by a set of layers , each of which corresponds to a smull ouzput video volume . in the proposed space-time video summarization method , each layer of the the3rst-jt und graph cut optimization techniques is composed of three layers : -lrb- 1 -rrb- the spatial and temporal , -lrb- 2 -rrb- the spatial and temporal , and -lrb- 3 -rrb- the visual information of the trailer movie trailer . in the proposed space-time video summarization method , each layer of the the3rst-jt und graph cut optimization techniques is composed of two layers : -lrb- 1 -rrb- a packing process , -lrb- 3 -rrb- an empty spuce video , and -lrb- 3 -rrb- a set of layers to represent the video volume . the experimental results show that the proposed space-time video summarization method is superior to the state-of-the-art video summarization methods .
in textual inference , algorithmic components such as the gradient-style evaluation function and the local-lookahead node expansion method are often used to guide search in order to speed up search algorithms . in this paper , we propose a novel approach to search for inference-preserving transformations in order to speed up the search problem . we show that this approach is able to speed up search by up to a factor of two orders of magnitude , while maintaining proof quality . in addition , we show that our approach is able to speed up search by orders of magnitude , and that it is able to speed up the search problem by orders of magnitude . finally , we demonstrate the effectiveness of our approach on an open-source system .
in this paper , we propose a new analytical model based on the stochastic differential equation approach . the proposed analytical model is able to estimate the steady-state weight-error correlations of the nlms algorithm . numerical simulations show that the proposed analytical model is superior to the existing analytical model in terms of both simulation and simulation results .
computational bottlenecks in machine learning can be reduced by using a multi-stage stratified monte carlo method with probabilistic relative error control . the multi-stage stratified monte carlo method has been successfully applied to a wide range of problems , including nested summations over datasets , and multi-tree methods . in this paper , we present a novel approach to reduce the number of components needed for error control . our approach is based on a novel technique called probabilistic relative error control , which is able to exploit scalability techniques , such as multi-tree methods , to reduce the dataset size while maintaining the theoretical sample complexity . we demonstrate the speedups of our approach on several benchmark datasets .
in this paper , we propose a novel framework for learning deterministic and non-deterministic auto-encoders . the proposed framework is based on the idea of localized space contraction , where the activation layer of a lower-dimensional non-linear manifold is represented by a set of features that are invariant to local directions of variation . we show that the proposed framework can be seen as a generalization of the classical reconstruction cost function of deterministic auto-encoders , where the weights of the encoder activations are learned by minimizing the frobenius norm of the jacobian matrix of the jacobian matrix . we show that the proposed framework can be applied to both denoising auto-encoders and regularized auto-encoders . in particular , we show that the proposed framework can be used to learn a set of features that are invariant to pre-training , and can be applied to any mlp . we also show that the proposed framework can be used to learn a set of features that are invariant to variations in the activation layer .
spoken language comprehension -lrb- spoken language comprehension -rrb- is a challenging task due to the lack of non-linguistic information in the linguistic input and the lack of reference resolution and word recognition . in this paper , we present a novel approach to spoken language comprehension based on eye movements . the approach is based on the integration of two processes : -lrb- 1 -rrb- linguistic processing , -lrb- 2 -rrb- linguistic processing , -lrb- 3 -rrb- linguistic processing , and -lrb- 3 -rrb- rapid mental processes . the window is based on the correlation between the two processes . the experimental results show that the proposed approach is able to recognize and recognize spoken instructions in a wide range of languages . furthermore , the method is able to distinguish between the two modalities . the results show that the proposed method is able to distinguish between the two kinds of eye movements , and that it is able to distinguish between the two modalities .
matrix factorization techniques are widely used in information processing tasks . however , most of the existing matrix factorization techniques are based on the assumption that the data lie on a low dimensional manifold . in this paper , we propose a novel compact representation for the intrinsic geometric structure of a data manifold , called non-negative matrix factorization . the proposed compact representation is based on the kl-divergence between the hidden topics and the geodesics of the data manifold . the proposed compact representation is able to capture the intrinsic geometric structure of the data manifold , and can be applied to a wide variety of high-dimensional databases . moreover , the proposed compact representation can be used to extract the hidden topics from the data manifold . experiments on human brain demonstrate the effectiveness of the proposed compact representation .
kernel functions play an important role in machine learning . in this paper , we consider the learning problem of learning a kernel function with respect to the natural similarity-based properties of a given similarity function . we propose a theory of kernels , which is based on the theory of kernels in implicit spaces . the theory of kernels is based on a generalization of the notion of positive semi-definiteness , which allows us to define a similarity function in an implicit space . we show that the learning problem can be formulated as a kernel function with respect to the natural pairwise similarity functions . we show that the learning problem can be formulated as an implicit mapping of a kernel function with respect to the natural similarity functions . we also show that the learning problem can be formulated as a special case of learning a kernel function with respect to the underlying similarity function . we show that the proposed theory of kernels can be interpreted as a generalization of the notion of positive semi-definiteness .
in this paper , we propose a novel approach to estimate the instantaneous frequency and the instantaneous phase of a target signal using the discrete evolutionary transform . the discrete evolutionary transform is based on the representation of the time-dependent spectrum of the target signal , and discrete evolutionary transform is applied to the time-frequency kernel and non-stationary signals in the noiseless and noisy situations . in the proposed method , the instantaneous frequency is estimated by masking and a recursive non-linear correction procedure . in the proposed method , the instantaneous frequency is estimated by time-frequency analysis of the direct sequence spread spectrum , and the instantaneous frequency is estimated by the masking and the recursive non-linear correction procedure . in the proposed method , the instantaneous frequency is estimated by the discrete evolutionary transform . the experimental results show that the proposed method is effective in estimating the instantaneous frequency direct sequence spread spectrum of the target signal , and the proposed method can estimate the instantaneous frequency of the target signal from the target signal .
we present a novel tensor decomposition algorithm based on the multilinear algebra literature . we show that latent-variable pcfgs can be used to approximate the probability distribution over trees in natural language parsing . our tensor decomposition algorithm can be seen as an extension of the well-known tensor formulation of latent-variable pcfgs . we show that our tensor decomposition algorithm can be viewed as a special case of the multilinear algebra literature . we show that our tensor decomposition algorithm has a speed-up of up to two orders of magnitude compared to the state of the art on real-world natural language parsing data .
probabilistic approaches to mapping visual observations to articulated body configurations have been shown to be effective for learning discriminative approaches to human pose inference . in this paper , we propose a novel framework for learning discriminative approaches for human pose inference . specifically , we propose an online probabilistic regression scheme , based on gaussian processes , to learn a set of monotonically decreasing co-variance functions from local neighborhoods in the pose space . the proposed online probabilistic regression scheme is capable of learning a set of mapping hyperparameters to the local neighborhoods of the training data , which are then used for learning the mapping hyperparameters . the online probabilistic regression scheme can be seen as a generalization of local regression , which allows for pruning and pruning . we demonstrate the effectiveness of the proposed online probabilistic regression scheme on several real pose databases .
in this paper , we propose a sequential framework for constructing neural networks by sampling the network weights . the sequential framework is based on the assumption that the probability distribution of the network weights can be approximated by a finite number of samples . we show that the sequential framework can be used to estimate the probability distribution of a neural networks given a finite number of samples . furthermore , we show how to efficiently compute the optimal number of samples in a sequential framework . finally , we demonstrate the effectiveness of sequential and importance resampling algorithms for neural networks .
in this paper , we propose an incremental adaptation approach to statistical machine translation . in our incremental adaptation approach , a hierarchical hierarchical domain structure is represented by a stream of post--lines , and a consistent model is learned from the training data . in order to capture the local context of the hierarchical domain structure , a multi-level domain hierarchy is adopted . in our incremental adaptation approach , a hierarchical hierarchical domain structure is learned from the training data , and a hierarchical hierarchical domain structure is learned from the training data . experimental results show that our incremental adaptation approach significantly improves the translation quality over the baseline methods .
in this paper , we propose a novel model for image segmentation based on the cooperative cuts model . unlike traditional pairwise random field based approaches which rely on short-boundary bias , our model is able to incorporate short-boundary bias into the random field , which makes exact inference tractable . moreover , our model is able to incorporate the short-boundary bias into the existing pairwise random field based approaches . in particular , the coupling graph edges in the random field can be learned efficiently by map inference . we demonstrate the effectiveness of our model on several challenging segmentation instances and show that our model outperforms state-of-the-art image seg-mentation methods .
particle filtering -lrb- monte carlo sampling -rrb- is a popular particle filtering -lrb- monte carlo sampling -rrb- with large dimensional system noise distribution . in this paper , we propose a pf algorithm based on basis change detection and re-estimation steps . under weaker assumptions , the pf algorithm converges to an asymptotically stable adaptive particle filter . simulation results show that the proposed pf algorithm performs better than existing particle filtering algorithms in tracking .
in this paper , we investigate the use of spectral and modulation information for automatic speech recognition . we use discrete cosine transform analysis to model the log magnitude spectrum , and use discrete cosine transform analysis to model the relationship between the time resolution and the frequency resolution of the modulation spectrum . we compare the performance of the proposed features on phonetic recognition experiments using timit and the dct/dcs features . the results show that the proposed features outperform conventional mfccs in terms of both time resolution and frequency resolution . we also show that the proposed features are more effective than conventional modulation features .
dynamic bayesian networks -lrb- dynamic bayesian networks -rrb- are powerful tools for modeling temporal systems . however , their applicability is limited by the number of unobserved variables . in this paper , we introduce active inference , a framework for learning dynamic bayesian networks from data . we show that active inference in dynamic bayesian networks can be viewed as a selective collection , where the goal is to maximize the expected number of unobserved variables that can be used for prediction . we show that active inference in dynamic bayesian networks can be viewed as an optimizing training phase , and show how active inference can be performed efficiently . we demonstrate the effectiveness of active inference on several benchmark problems .
spoken dialogue systems -lrb- spoken dialogue systems -rrb- have been shown to be effective in improving the naturalness of interaction in spoken dialogue systems . in this paper , we propose an instantaneous vector representation of pitch variation in spoken dialogue systems . the instantaneous vector representation of pitch variation is used to model the relationship between the spoken dialogue systems and the spoken dialogue systems . the proposed instantaneous vector representation of pitch variation is used to model the relationship between the spoken dialogue systems and the acoustic modeling techniques . the proposed instantaneous vector representation of pitch variation is evaluated on automatically labeled data and compared with a hand-crafted baseline . the results show that system responsiveness can be used for human-like dialogue flow control . in addition , the proposed method is shown to improve the naturalness of interaction in predicting speaker changes in real human-human conversations .
tracking is a fundamental problem in computer vision . in this paper , we propose a method to learn a graphical model for tracking . the graphical model is composed of two components : one is a graphical model for tracking and the other is a graphical model for tracking . the other is a graphical model for tracking and the other is a graphical model for tracking . the graphical model is learned by learning the parameters of the graphical model , and the other is a graphical model for tracking . the graphical model is learned by learning the parameters of the graphical model . the experimental results show that the proposed method is able to learn the parameters of the graphical model and the parameters of the graphical model for tracking .
pairwise markov random field -lrb- pairwise markov random field models -rrb- models have been widely used in many computer vision problems . however , pairwise markov random field models suffer from the fact that the gibbs energy of signal interaction can be approximated by binary mrfs . in this paper , we propose a new class of energy minimization tools for pairwise mrf models that can be used to derive higher order counterparts for pairwise mrf models . in particular , we show that the quadratic function can be approximated by an order polynomial . in particular , we show that the proposed energy minimization tools can be interpreted as an asymmetric potts prior and can be interpreted as a special case of the proposed energy minimization tools . in particular , we show that the proposed energy minimization tools can be used to derive pairwise mrf models with higher order cliques . we demonstrate the effectiveness of the proposed energy minimization tools on image segmentation and image segmentation .
in this paper , we propose a novel machine learning method for pivot-based statistical machine translation . in our machine learning method , we first extract pivot phrases from bilingual data and then use markov random walks to learn the weights of the pivot phrases . in our machine learning method , the pivot phrases are extracted from the bilingual data and the pivot phrases are extracted from the bilingual data . the experimental results on european parliament data show that the proposed machine learning method can significantly improve the performance of source-target translation .
in this paper , we address the missing data problem of joint trait analysis from missing data . in particular , we propose a novel approach to learn plant traits from a global database by exploiting the hierarchical structure of the trait data . specifically , we propose a hierarchical probabilistic matrix factorization to capture trait correlation by exploiting the hierarchical phylogenetic information for trait prediction . the key idea of hierarchical probabilistic matrix factorization is to leverage the hierarchical phylogenetic structure of the trait data to improve the performance of the existing matrix factorization methods for missing data problem . moreover , we propose a novel hierarchical probabilistic matrix factorization based matrix completion techniques for the missing data problem . experimental results show that the proposed hierarchical probabilistic matrix factorization based matrix completion techniques can significantly improve the performance of the existing algorithms for the missing data problem . moreover , the proposed hierarchical probabilistic matrix factorization can improve the performance of the existing matrix factorization methods when applied to the ecological community plant traits .
in context-based object recognition , the relative poverty of scene detail is a challenging problem due to the high degree of video noise and the complexity of object appearances . to address this problem , we propose a multiscale viterbi classification algorithm for object recognition in aerial images . tree-structured belief networks are used as a feature set for discriminating features between different visual contexts . tree-structured belief networks are used as a feature set , and an adaptive feature selection algorithm is proposed to learn the parameters of tree-structured belief networks . the proposed multiscale viterbi classification algorithm is evaluated on two real-world test images taken from the msbc paradigm . the experimental results show that the proposed multiscale viterbi classification algorithm outperforms the state-of-the-art methods in terms of robustness , real-time constraints , and complexity of object appearances in flight images . furthermore , the proposed multiscale viterbi classification algorithm can be used for object recognition in aerial images . the proposed multiscale viterbi classification algorithm can also be applied to other statistical models of object appearances , such as the complex wavelet transform and the hsi color space .
in this paper , we propose a new method for musical chord recognition based on the wavelet transform and a model of human perception . the model of human perception is composed of three components : -lrb- 1 -rrb- the information of timbres and -lrb- 2 -rrb- the information of timbres and -lrb- 3 -rrb- the information of timbres . the experimental results show that the proposed method outperforms the state-of-the-art methods . the proposed method is also applied to the task of musical chord recognition .
in this paper , we investigate the use of prosody modelling and hmm state selection for incremental speech synthesis . in para-metric speech synthesizers , full-utterance context is used to generate a set of features for parametric speech synthesis voices . these features are then used to generate parametric speech synthesis voices . in this paper , we investigate the use of determing hmm states as features for incremental speech synthesis . the results show that the use of prosody modelling and hmm state selection improves the naturalness of speech synthesis in incremental use-cases .
burst detection is an important problem in temporal stream analysis . in this paper , we propose a novel approach to burst detection using textual features and pervasive collaborative context , called resource lifetime , to capture the collaborative context in social media content . in addition , we propose a robust state based model to capture the collaborative context in burst pulses . in addition , we propose a learning method to estimate the topic coverage , metadata frequency , topic coverage , and user attractiveness in burst extraction . experimental results show that the proposed method is effective in burst detection .
in this paper , we investigate the asymptotic dynamical behaviour of e-ii units with short-range connections in the context of cellular automata . we show that the automaton rule can be interpreted as a generalization of weight sharing in networks with complex or chaotic behaviour . we also show that learning with e-ii units can be achieved by learning with only a small number of short-range connections .
nearest neighbor classification -lrb- nearest neighbor classification -rrb- is one of the most challenging problems in machine learning . in this paper , we propose a locally adaptive neighborhood morphing classification method to reduce the bias caused by severe bias in discriminant feature dimensions . specifically , we propose a locally adaptive neighborhood morphing classification method to reduce the bias introduced by the local support vector machine learning . the locally adaptive neighborhood morphing classification method is able to preserve the class conditional probabilities of finite samples , which can be used for nearest neighbor classification . experimental results show that the proposed locally adaptive neighborhood morphing classification method is very effective in reducing the bias caused by severe bias in discriminant feature dimensions .
deconvolution problems arise in many signal processing applications where the unknown input signal is corrupted by noise corrupted fir channels . in this paper , we propose a new total least squares based approach for solving deconvolution problems in the presence of noise corrupted fir channels . the proposed total least squares based approach is based on the least squares estimation of the unknown input signal and the kalman filter is used for a recursive implementation of the re-cursive total least squares algorithm . compared to the non-recursive tls algorithm , the proposed total least squares based approach has a much lower computational cost . simulation results show that the proposed total least squares based approach has better performance in comparison with other blind algorithms .
in this paper , we propose a new filter-bank structure for signal reconstruction . the proposed filter-bank structure is a low delay filter-bank , called generalized filter-bank equalizer , which is a generalization of the analysis-synthesis filter-bank -lrb- as fb -rrb- . the generalized filter-bank equalizer is a generalization of the conventional time-domain filter in that the input signal is transformed into frequency-domain coefficients and the output signal is transformed into a allpass transformation for non-uniform frequency resolution . the algorithmic complexity of the generalized filter-bank equalizer is lower than that of the time-domain filter . in addition , the proposed generalized filter-bank equalizer can be applied to any type of noise reduction . the experimental results show that the proposed generalized filter-bank equalizer can achieve better noise reduction performance than the conventional time-domain filter .
detection of speech in real acoustic background is a challenging task due to non-speech sounds . in this paper , we propose a classification method of speech embedded in real acoustic background based on amplitude modulation spectrogram . the proposed classification method consists of two steps . first , the classification task is performed using features extracted from the modulation components extracted from the amplitude modulation spectrogram , and the classification task is performed using feature selection techniques . second , the classification of speech is performed on the features extracted from the modulation frequency range . the experimental results show that the proposed classification method outperforms the conventional methods in terms of both false positive rates and signal-to-noise level . the proposed classification method is also evaluated on the itu g729.b voice activity detection . the proposed detection of speech is also evaluated on test-data using modulation features .
in this paper , we present a novel approach to predicting dependency links between two annotated natural language corpora . unlike traditional dependency parsers , our approach does not require specialized training algorithms such as conditional random fields or maximum margin markov networks . instead , we propose a dependency parsing model based on structured boosting , where a base classifier is trained by logistic regression and support vector machines . the base classifier is trained by logistic regression , and the base classifier is trained by logistic regression . the base classifier is then fed into a dependency parsing model , where the local predictor of the dependency parsing model is learned by logistic regression . the structured prediction accuracy of the structured predictors is improved by adding features to the base classifier , which are then fed into specialized training algorithms . experimental results on chinese and chinese show that our approach significantly outperforms several state-of-the-art supervised training methods based on a simple and efficient and efficient , and achieves comparable performance to structured classification .
we consider the problem of learning bayesian network structure from data . we propose a sampling approach to learning the structure of a bayesian network structure , based on annealed importance sampling . in contrast to previous sampling methods , the proposed markov chain monte carlo method does not require parallelization , and can handle large datasets with linear orders . we show that the markov chain monte carlo method can be viewed as a special case of the markov chain monte carlo method , and that markov chain monte carlo method can be viewed as a special case of the markov chain monte carlo method . we show that the markov chain monte carlo method can be interpreted as a special case of the markov chain monte carlo method , and that markov chain monte carlo method can be viewed as a special case of the markov chain monte carlo method . we show that the markov chain monte carlo method can be viewed as a special case of the markov chain monte carlo method , and that markov chain monte carlo method provides probabilistic guarantees on the number of nodes in the posterior . finally , we show that the markov chain monte carlo method can be used to learn the structure of a network with partial order , and that the markov chain monte carlo method can be used to learn the structure of a network from data .
in this paper , we propose a new approach to compensate for contextual confidence information in spoken dialogue systems . in this approach , the confidence tag for word/phrase is predicted by the acoustic confidence measure of neighboring concepts . the confidence tag for word/phrase is calculated based on the confidence measure of neighboring concepts . the confidence tag for word/phrase is calculated based on the confidence measure of neighboring concepts . experimental results show that the proposed approach achieves an equal error reduction rate of 9.3 % compared to the conventional methods .
linear programming boosting -lrb- linear programming boosting -rrb- has been successfully applied to uneven datasets . in this paper , we extend linear programming boosting to the problem of uneven datasets . we show how to incorporate boosting strategies into the text classification problem , and show that our approach outperforms existing methods .
lexical co-occurrence is an important concept in detecting word associations . in this paper , we propose a novel approach to lexical co-occurrence that is based on span distributions of associated words . the proposed method is based on the assumption that words have similar unigram frequencies , and that words have similar span distributions of associated words . the proposed method is evaluated on two benchmark data sets : ochiai and ochiai . the experimental results show that the proposed method outperforms the state-of-the-art co-occurrence measures in detecting word associations . furthermore , it is shown that the proposed method is robust against ttest biases , and that it is robust to variations in global unigram frequencies .
in this paper , we propose a novel session variability subspace projection svspbased model compensation method for speaker verification . the proposed session variability subspace projection svspbased model compensation method is composed of two components : ubm and compensated speaker models . the first component of the session variability subspace projection svspbased model compensation method is to reduce the mismatch between the ubm and the compensated speaker models . experimental results show that the proposed session variability subspace projection svspbased model compensation method can reduce the relative equal error rate reduction of the gmm-ubm system .
3d object reconstruction from 2d line drawing is a fundamental problem in computer vision . in this paper , we propose a divide-and-conquer strategy for 3d reconstruction of complex manifold objects from single 2d line drawings . the proposed divide-and-conquer strategy is based on the geometric structure of the line drawing and the geometric structure of the 3d object . the proposed divide-and-conquer strategy is applied to the 3d reconstruction of complex manifold objects from single 2d line drawings . the experimental results show that the proposed divide-and-conquer strategy can recover the 3d shapes of a complex object from a single 2d line drawings . the proposed divide-and-conquer strategy is applied to face identification and 3d reconstruction of more complex objects .
in this paper , we propose a novel approach to estimate deterministic input multipulse time series from a pair of deterministic input multipulse time series with sharp truucabion . first , we use the uew method to estimate the au optimnm tapering window for estimatiug multipulse time series . then , we use the uew method to estimate the au optimnm tapering window for the estimatiug multipulse time series . finally , we estimate the tapering window using the ihe transfer system , which is a singular-value-decomposit . the experimental results show that the proposed method is effective in estimating the snr of the andard svd-based estimator .
the optical flow field is a fundamental problem in many computer vision and video analysis tasks . it has been widely used in many applications such as event analysis and surveillance applications . in this paper , we propose a multiresolution robust regularization technique to estimate the optical flow field in mpeg sequences . the proposed multiresolution robust regularization technique is based on the mpeg consistency constraint and temporal continuity . the mathematical constraints on the velocity fields , i.e. , mpeg motion field , are imposed on the compressed stream . the proposed multiresolution robust regularization technique has the following advantages : -lrb- 1 -rrb- it does not require the computation of the dc coefficients , -lrb- 2 -rrb- it does not require the computation of the objective function , and -lrb- 3 -rrb- it does not require any memory consuming decompression . -lrb- 3 -rrb- it does not require the computation of the objective function , and -lrb- 3 -rrb- it is robust to motion discontinuities . experimental results on mpeg sequences show that the proposed multiresolution robust regularization technique can effectively estimate the motion discontinuities in mpeg sequences .
we present a fractional gabor expansion based on a general , non-rectangular time-frequency lattice . the fractional gabor expansion is based on a set of basis functions , each of which corresponds to a fractional fourier basis . the fractional gabor expansion is a flexible , non-rectangular tiling of the fractional fourier basis . we show that the fractional gabor expansion can be interpreted as a special case of a general , non-rectangular time-frequency lattice . we show that the fractional gabor expansion can be interpreted as a special case of a special class of basis functions , which we call gabor logons . constant-bandwidth analysis of the fractional gabor expansion is also given .
distance metric learning -lrb- distance metric learning -rrb- has been shown to be an effective audio fingerprinting system . in this paper , we propose a novel method to learn a mahalanobis distance between a pair of patterns in a fingerprinting system . the key idea is to learn a distance metric for each pair of words in the database , and then learn a distance metric for each pair of words in the database . the distance metric learning is formulated as a cost function to maximize the dissimilarity between two pairs of patterns . a convex optimization is used to find the global minimum . the proposed method is applied to the identification of an audio fingerprinting system . experimental results show that the proposed method is effective in identifying the query content in a fingerprinting system .
in this paper , we study the trajectory learning problem , where the goal is to find the most appropriate clustering methodologies for a given task . we propose a comparative evaluation of four different clustering methodologies : one based on motion characteristics , the other based on motion characteristics , the other based on motion characteristics , and the other based on motion characteristics . our comparative evaluation shows that the clustering rate is significantly higher than that of clustering , and the other based on the clustering methodologies is significantly higher than that of clustering . we also show that the clustering rate is significantly higher than that of clustering . finally , we discuss the implications of our findings on automatic activity analysis .
collaborating agents in embedded systems can be modeled as a 3-agent network . in this paper , we consider multiagent meta-level control , where agents coordinate their actions in order to maximize their expected utility . we propose a reinforcement learning based approach to learning decentralized meta-control policies . the reinforcement learning based approach is a global optimization algorithm , where agents coordinate their actions in order to maximize the expected utility of their neighbors . the reinforcement learning based approach is designed to maximize the expected utility of the global optimization algorithm . we demonstrate the effectiveness of the proposed reinforcement learning based approach by applying multiagent meta-level control to the problem of adapting an action plan to the environment . we demonstrate the effectiveness of the proposed reinforcement learning based approach through a large-scale example of a multiagent tornthe tracking application , netrads .
in this paper , we investigate the use of short-term features for speaker diarization . short-term features have been shown to be effective in improving the accuracy of speaker diarization . however , the combination of short-term features and long term features has not been shown to improve the accuracy of speaker diarization . in this paper , we propose to use short-term features to improve the performance of a speaker di-arization system . the prosodic and long-term features are extracted from the diarization-independent speaker-discriminability study , and the long-term features are extracted from the long-term features . experiments on nist evaluation show that the combination of short-term features and long term features improves the overall diarization error rate of the speaker di-arization system . moreover , the combination of short-term features and long term features improves the overall diarization error rate of the speaker di-arization system .
in this paper , we study the performance of channel tracking schemes based on known channel statistics . in particular , we consider a frequency-domain tracking scheme where the channel impulse response is corrupted by additive white gaussian noise . we derive performance bounds for the performance of these channel tracking schemes , and show that the frequency-domain tracking scheme can be interpreted as a special case of the frequency-domain tracking scheme .
in this paper , we propose a bottom-up video summarization algorithm , called multimodal saliency curve , for video summarization . the proposed bottom-up video summarization algorithm consists of three steps : -lrb- 1 -rrb- a spatiotemporal attention model for visual saliency , and -lrb- 2 -rrb- a spatiotemporal attention model for visual saliency based on color , and -lrb- 3 -rrb- a spatiotemporal attention model for visual saliency based on color , and -lrb- 3 -rrb- a spatiotemporal attention model for visual saliency based on movie distributions . the proposed bottom-up video summarization algorithm is composed of two steps : energy tracking and nonlinear operators . in the first step , the audio saliency is determined by the cues for multifrequency waveform modulations . in the second step , the audio saliency is determined by the importance of cues and the importance of the importance of the attention curve . in the second step , the audio saliency is automatically determined by the proposed bottom-up video summarization algorithm . the experimental results show that the proposed bottom-up video summarization algorithm is effective for the detection of perceptually important video events . moreover , the proposed bottom-up video summarization algorithm is very effective for video summarization .
efficient learning equilibrium -lrb- efficient learning equilibrium -rrb- is a natural solution concept for multi-agent yuters . efficient learning equilibrium is a natural solution concept that can be used to detect ele deviations in games with incomplete information . efficient learning equilibrium is a natural solution concept that can be used to detect multi-agent encounters in games with incomplete information . in this paper , we show that efficient learning equilibrium can be computed in polynomial time in the size of the game . we also show that efficient learning equilibrium can be computed in polynomial time in the size of the game . finally , we show that efficient learning equilibrium can be computed in polynomial time in the size of the game .
we present a generic , distributed sentence encoder for unsupervised learning . our generic , distributed sentence encoder is based on a vocabulary expansion method , where each sentence is represented by a set of vector representations that capture both semantic and syntactic properties . the encoded passage encoder-decoder model can be seen as a generalization of linear models to generic sentence representations . we evaluate our generic , distributed sentence encoder on three tasks : semantic relatedness , image-sentence ranking , paraphrase detection , and question-type classification . our results show that the proposed generic , distributed sentence encoder is competitive with the state of the art in unsupervised learning .
in this paper , we present a new approach to the problem of automatically constructing an efficient and accurate , and efficient , stochastic parser for lexical-functional analysis of data-oriented lexical-functional analysis -lrb- data-oriented lexical-functional analysis -rrb- . our approach is based on the use of tree structures to guide the search for the most probable parse of a given sentence , and uses a discounted frequency estimator of the dop hypothesis to guide the search for the most probable parse . we evaluate our approach on the verbmobil and homec, and compare it to monte carlo search on the original tree-dop . our results show that our approach achieves parse accuracy comparable to that of the tree-dop , while maintaining the same accuracy as that of the original tree-dop . we also show that our approach can be used to improve the overall parse accuracy . finally , we show that our approach can be used to improve the parse accuracy of a given data-oriented lexical-functional analysis -lrb- data-oriented lexical-functional analysis -rrb- parser .
in this paper , we propose a modified kalman filter approach to single channel speech enhancement . the proposed modified kalman filter approach exploits the temporal correlation of successive frames in the frequency domain to improve the performance of single channel speech enhancement . in the proposed modified kalman filter approach , the speech prediction error signal is first estimated by minimizing the prediction error signal , and then the temporal correlation of successive frames is estimated by minimizing the snr . the proposed modified kalman filter approach is compared with the conventional snr dependent mmse estimator in terms of both objective measurements and objective measurements . the experimental results show that the proposed modified kalman filter approach can improve the performance of single channel speech enhancement .
in this paper , we present a method for labeling tv shots in real video . the method is based on hmm and a viterbi decoder for shot labeling . the algorithm is tested on a collection of commercial or program shots . the results show that the method is capable of labeling tv shots with high level of shot duration , and that it can be used to detect tv shots with high level of shot duration .
in this paper , we investigate the use of support vector machines for deterministic dependency parsing . in particular , we investigate the effect of treebank-induced classifiers on deterministic parsing , and propose two different feature models for data-driven parsing : one based on feature models , and the other based on data-driven parsing . our experiments on classifier-based deterministic parsing show that the proposed parsing models achieve better parsing accuracy than the state-of-the-art parsing models on chinese , english , swedish , and english .
in this paper , we propose a semi-supervised boosting approach to improve the performance of a supervised boosting algorithm . the semi-supervised boosting approach is an extension of the semi-supervised boosting approach to the supervised boosting algorithm . in contrast to other semi-supervised boosting methods , our semi-supervised boosting approach does not require labeled data nor unlabeled data . instead , we use a pseudo reference set to train a word aligner , which is then used to train the supervised boosting algorithm . our experimental results show that our semi-supervised boosting approach achieves relative error reductions of up to 20 % in terms of the error rate of the supervised boosting and the unsupervised boosting , respectively . in addition , we show that our semi-supervised boosting improves the performance of statistical word alignment by incorporating labeled data and unlabeled data into boosting methods .
conjunctive normal form -lrb- conjunctive normal form -rrb- is a combinatorial prediction market game , where the goal is to predict the outcome of a combinatorial prediction market . conjunctive normal form is a combinatorial prediction market game , where the goal is to predict the outcome of an item given its current location . conjunctive normal form is a disjunctive normal form with a multiplicative error factor . in this paper , we propose a monte-carlo technique based on importance sampling . we prove additive error bounds for conjunctive normal form with dnf formulas of polynomial size for conjunctive normal form . we also show that the proposed monte-carlo technique can be used to compute the outcome of a combinatorial prediction market with time polynomial in the size of the input sequence . experimental results show that the proposed monte-carlo technique outperforms the state-of-the-art algorithms .
in this paper , we propose a general-purpose naive bayes model for many-to-many association in word sense disambiguation tasks . the general-purpose naive bayes model is based on the overlap mechanism between random variables and the probability estimates obtained by maximum likelihood . the general-purpose naive bayes model is evaluated on two word sense disambiguation tasks . the experimental results show that the general-purpose naive bayes model outperforms the lesk algorithm in terms of both word sense disambiguation tasks , and that general-purpose naive bayes model outperforms the lesk algorithm in terms of both word sense disambiguation tasks .
we present a knowledge compilation map for ordered decision diagrams -lrb- vdd -rrb- . the knowledge compilation map is a generalization of valued decision diagrams to real-valued functions , which includes probability distributions , utility functions , utility functions , and probability distributions . we show that the knowledge compilation map can be compiled into vdd languages , and we show that the knowledge compilation map can be extended to csps with non-negative real numbers . we also show how to extend the knowledge compilation map to the case of ordered binary decision diagrams -lrb- vdd -rrb- . we also show how to extend the knowledge compilation map to the case of ordered binary decision diagrams -lrb- vdd -rrb- . finally , we discuss the data structures of cuts , marginalizations , and complexity .
in this paper , we propose a translation model adaptation approach for conversational spoken language translation . in our translation model adaptation approach , a monolingual lda topic model is used as a similarity measure between topic distribution and up-front knowledge , and a similarity measure based on the monolingual lda topic model is proposed to capture the causal constraint of spoken conversations . experimental results on english-to-iraqi cslt task show that the proposed translation model adaptation approach significantly outperforms the non-incremental oracle , including both bleu and ter . furthermore , the incremental nature of our translation model adaptation approach makes the translation model adaptation approach more suitable for conversational spoken language translation .
designing signature sequences for cdma with colored noise and correlated signals is a challenging problem . in this paper , we propose a novel scheme for designing signature sequences that minimizes the sum power constraint between the user capacity and the information-theoretic capacity . the proposed scheme can be viewed as a generalization of the conventional power allocation policy in terms of the sum power constraint . simulation results show that the proposed scheme outperforms existing methods in terms of power allocation .
forensic facial sketch recognition -lrb- forensic facial sketch recognition -rrb- is an important research topic in law enforcement . in this paper , we propose a novel method for automated facial forensic sketch matching , which is based on a forgetting process . the proposed method has two main advantages : -lrb- 1 -rrb- it does not require any prior knowledge of the location of the person , and -lrb- 2 -rrb- it does not require any knowledge of the location of the person in the image ; -lrb- 3 -rrb- it does not require any knowledge of the location of the person in the image ; -lrb- 3 -rrb- it does not require any knowledge of the location of the person in the image ; -lrb- 3 -rrb- it does not require any knowledge of the location of the person in the image ; -lrb- 3 -rrb- it does not require any knowledge of the location of the person in the image ; -lrb- 3 -rrb- it does not require any knowledge of the location of the person in the image ; -lrb- 3 -rrb- it does not require any knowledge of the location of the person in the image ; -lrb- 3 -rrb- it does not require any knowledge of the location of the person in the image ; -lrb- 3 -rrb- it does not require any knowledge of the location of the person in the image ; -lrb- 3 -rrb- it does not require any knowledge of the location of the person in the image ; -lrb- 3 -rrb- it does not require any knowledge of the identity of the person in the image ; and -lrb- 3 -rrb- it does not require any knowledge of the entire image in the entire image ; -lrb- 3 -rrb- it does not require any knowledge of the entire image in the entire image ; -lrb- 4 -rrb- it is a 10,030 mugshot database of people in the entire image . -lrb- 4 -rrb- . -lrb- 4 -rrb- the proposed method is based on the publicly available forensic sketch recognition , we show that the proposed method outperforms the state-of-the-art methods of law enforcement on a 10,030 mugshot database , which consists of 430 mugshot database , our method is significantly outperforms the previous methods in the well-studied , and our method does not require no knowledge of the well-studied , but also show that our method can be used for law enforcement ch-photo modality gap
multi-layer artificial neural networks -lrb- multi-layer artificial neural networks -rrb- are a popular learning algorithms in the machine learning community . in this paper , we propose a convex optimization problem for multi-layer artificial neural networks , where each hidden unit is represented by a linear classifier . the convexity of the multi-layer artificial neural networks is defined by a convex optimization problem , and the convexity of the resulting multi-layer artificial neural networks is proved to be the same as that of the original multi-layer artificial neural networks . moreover , the convexity of the multi-layer artificial neural networks is proved to be the same as that of the original multi-layer artificial neural networks . the experimental results show that the proposed convex optimization problem can significantly improve the performance of multi-layer artificial neural networks .
stochastic optimal control problems , such as path integral form , can be formulated as stochastic optimal control problems such as sample integral form . in this paper , we propose a model-free , non-parametric approach to the control problem based on embedding . the proposed model-free , non-parametric approach is based on a kernel hilbert space embedding -lrb- reproducing kernel hilbert space -rrb- , and can be used to derive an invariant and task dependent component of the control problem . the sample efficiency of the proposed model-free , non-parametric approach is evaluated on sample data and compared to existing sample based approaches .
in this paper , we present a novel approach to automatic col-, which is based on the automatic perception of distances between a colored image and its corresponding colored image . our approach is based on the use of graph cuts , a non-uniform spatial coherency criterion , to enforce a one-to-one correspondence probability distribution on the local texture of the image . the color proposition is represented by a set of user-provided color landmarks , which are then used to estimate the probability distribution of each pixel in the l-a-b color space . the proposed approach is based on the minimization of a non-uniform spatial coherency criterion on the local level , which can be efficiently solved using standard machine learning tools . the proposed approach has been tested on a dataset of colored examples , and compared to the state-of-the-art in terms of both multimodality and estimate . in addition , the proposed method is shown to be robust to texture noise , and can be applied to a wide range of greyscale images . moreover , it is shown that the proposed method can be applied to a wide range of applications .
in this paper , we propose a new approach to speech recognition based on dynamic cepstral features -lrb- wlr-hmm -rrb- hidden markov model -lrb- hmm -rrb- based hidden markov model -lrb- hmm -rrb- hidden markov model -lrb- hmm -rrb- hidden markov model -lrb- hmm -rrb- based hidden markov model -lrb- hmm -rrb- based hidden markov model -lrb- hmm -rrb- based speech recognition . in the hmm framework , the output probability density function is modeled by exponential kernels . in the hmm framework , a multiple-stream wlr-hmm is used to model the natural resonances of vocal track in broad-band noise interferences . in the proposed method , the speech spectra of the multiple-stream wlr-hmm are modeled by a set of dynamic cepstral features . the proposed method is evaluated on aurora2 connected digits database and compared with the mfcc trained gmm baseline system . the results show that the proposed method is capable of capturing human perception of speech formants .
in this paper , we describe the development of lvcsr systems for german , polish , spanish and portuguese . the open vocabulary approach is based on morphand units , which represent spontaneous speech in the audio data . the open vocabulary approach is composed of three steps : -lrb- 1 -rrb- language model adaptation , -lrb- 2 -rrb- minimum phone error trained acoustic models , -lrb- 3 -rrb- multilingual bottleneck features , -lrb- 3 -rrb- language model adaptation , -lrb- 3 -rrb- confusion-network based system combination , -lrb- 3 -rrb- language model adaptation , and -lrb- 3 -rrb- lm adaptation . the experiments were conducted on broadcast news , podcasts , and lecture domain . the results showed that the combination of the two approaches significantly improves the performance of the german lvcsr systems . in addition , the combination of the two lvcsr systems is also investigated . the combination of the two approaches further improves the performance of the german lvcsr systems .
in this paper , we investigate the consistency assumption of forced alignment in speech synthesis . in order to improve the phoneme identity accuracy of hmm-based voices , we propose a lattice-based forced alignment system to measure the pronunciation variation in read prompts . the proposed lattice-based forced alignment system is based on the assumption that the phoneme sequence is generated by a front-end text processing system , and the phoneme sequence is predicted by a lattice-based forced alignment system . the proposed lattice-based forced alignment system is evaluated by measuring the consistency of the acoustic models in read and spontaneous speech . the experimental results show that the proposed lattice-based forced alignment system is able to accurately predict the pronunciation variation in read and spontaneous speech , and that the proposed lattice-based forced alignment system is able to achieve the best phoneme identity accuracy in read and spontaneous speech .
image registration is one of the most challenging problems in image processing . in this paper , we propose a novel approach to image registration based on feature and intensity matching . the illumination model is represented by a set of projective transformation parameters , which are invariant to smooth spatially varying illumination variation , and invariant to geometrical variation . a feature-based approach is used to estimate the projective model parameters , and a polynomial model is derived based on polynomial coefficients . the robustness of the proposed approach is demonstrated by comparing the proposed method with the state-of-the-art methods in terms of both accuracy and robustness . the proposed method is applied to the problem of intensity matching , and the experimental results show that the proposed method is superior to the state-of-the-art methods in terms of both efficiency and robustness .
information retrieval -lrb- information retrieval -rrb- is the task of rel-evgence assessment , queries , and documents . in this paper , we propose an approximate leave-one-out cross-validation procedure to estimate hyperparameters based on the cavity method . the proposed approximate leave-one-out cross-validation procedure is compared with mean-field methods , and the results show that the proposed approximate leave-one-out cross-validation procedure is superior to the explicit parametric model in ir and ir .
sparse inverse covariance methods have been shown to outperform full covari-ance methods when only limited training data is available for training full covariance acoustic models . in this paper , we propose a maximum likelihood estimation.the graphic lasso method to automatically learn a sparse inverse covariance matrix from a small amount of unseen test data . the proposed maximum likelihood estimation.the graphic lasso method uses l1 reg-ularization to learn a sparse inverse covariance matrix from a small number of free parameters . the proposed maximum likelihood estimation.the graphic lasso method uses l1 reg-ularization to learn the inverse covariance matrices of the hidden markov model -lrb- hmm -rrb- from a small amount of training data . the proposed maximum likelihood estimation.the graphic lasso method is compared with the state of the art hidden markov model -lrb- hmm -rrb- based hidden markov model -lrb- hmm -rrb- based hidden markov model -lrb- hmm -rrb- based hidden markov model -lrb- hmm -rrb- based hidden markov model -lrb- hmm -rrb- based hidden markov model -lrb- hmm -rrb- based hidden markov model -lrb- hmm -rrb- based hidden markov model -lrb- hmm -rrb- based acoustic models with sparse inverse covariance gaus-sians . experimental results show that the proposed maximum likelihood estimation.the graphic lasso method is able to learn the full co-variance gaussians from limited data , and that the proposed maximum likelihood estimation.the graphic lasso method is able to learn the full co-variance gaussians from limited data .
background subtraction techniques have been widely used for segmenting foreground objects in video material . in this paper , we propose a background modeling technique for object segmentation based on local background sprite generation . the background modeling technique is composed of two steps : -lrb- 1 -rrb- background subtraction techniques for segmenting foreground objects into foreground objects ; -lrb- 2 -rrb- background subtraction techniques for segmenting foreground objects ; -lrb- 3 -rrb- background subtraction techniques for segmenting foreground objects ; -lrb- 3 -rrb- background subtraction techniques for global motion estimation and/or background , and -lrb- 3 -rrb- preprocessing for segmentation of sequences based on moving background . experimental results show that the proposed background modeling technique is effective for object segmentation .
bayesian decision makers -lrb- bayesian decision makers -rrb- are widely used in signal detection , hypothesis testing , and localized distributed averaging . however , bayesian decision makers are often used to estimate opinion dynamics in a decision-making system . in this paper , we consider bounded confidence opinion dynamic models , where the prior probabilities of the bayesian decision makers are known to be bounded . we show that the bayes risk error divergence can be interpreted as a generalization of the bayes risk error divergence to bounded confidence opinion . we show that the signal-to-noise ratio of the hypothesis testing task is independent of the number of clusters , and that the signal-to-noise ratio of the hypothesis testing task is independent of the number of clusters . we also show that the signal-to-noise ratio of the hypothesis testing task is bounded by the number of clusters , and that the prior probabilities of the bayesian decision makers are bounded . we also show that the bounded confidence decision-making system can be interpreted as a generalization of the bayes risk error divergence to bounded confidence opinion dynamic models .
we consider the problem of learning randomized features in kernel machines for machine learning tasks . we propose a randomized-feature approach , where the goal is to learn a user-defined kernel from a small number of random features , and the goal is to learn a kernel from a small number of training examples . we derive generalization bounds for the class of estimators in terms of the training cost and the number of training examples needed to learn the kernel machines . we also show that our randomized-feature approach can be viewed as an optimization problem , which can be solved efficiently in a supervised manner . we demonstrate the effectiveness of our randomized-feature approach on several machine learning tasks .
in this paper , we present a partial parsing formalism and simultaneous rule-based the integration of partial parses into the tree-bank of partial parses . the partial parsing formalism is applied to the ipi pan corpus of polish .
we consider the problem of minimizing the misclassification of future data in the presence of nonlinear decision boundaries . the nonlinear decision boundaries are modeled by mercer kernels . the optimization problem is solved using convex optimization . a classifier is designed to solve the resulting optimization problem . experimental results are presented to illustrate the effectiveness of the proposed approach .
in this paper , we describe conversational helper , a conversational helper for automotive tasks . conversational helper is designed to provide users with a high level of user experience , dialog efficiency , and task completion rate . the goal of conversational helper is to develop advanced spoken dialogue interfaces for automotive tasks . in this paper , we describe the design and implementation of the conversational helper , focusing on computing platforms for chat . we describe the design and implementation of the conversational helper , focusing on the design and implementation of dialog systems . we describe the design and implementation of the conversational helper , and report on the results of user experience and dialog efficiency .
automatic speech summarisation is a challenging task due to the lack of human summaries . contemporary approaches to automatic speech summarisation typically rely on speech recogniser transcriptions . in this paper , we present a novel approach for automatic lim adaptation that uses a ted corpus of eurospeech conference presentations . the approach is based on the use of cnn broadcast news data to automatically generate news stories from the ted corpus of eurospeech conference presentations . the approach is based on automatic lim adaptation of the linguistic model component of the speech recogniser transcriptions and uses a language model to guide the recognition process . the adaptation data is used to identify lims in the corpus , and the language model is adapted to match lims in the corpus . experiments show that the proposed approach improves the summari-sation accuracy over contemporary approaches .
we present a worst-case approach to universal portfolio management in which stock price returns are modeled as exp-concave loss functions . our worst-case approach is based on a probabilistic model of the stock price returns , and we derive regret bounds for online convex optimization . we apply our worst-case approach to the problem of universal portfolio management , where stock price returns are drawn from geometric brownian motion .
we present a nonparametric approach to estimating drift functions from sparse observations of the state vector . our nonparametric approach is based on a piecewise linearized process , where each state vector is represented by a piecewise linearized process , and the posterior over states is estimated by a sparse gaussian process regression . we derive an approximate em algorithm for learning the posterior over states , and apply approximate em algorithm to map estimation in the presence of unobserved , latent dynamics . we apply our nonparametric approach to the problem of estimating drift functions in stochastic differential equations , where the ornstein-uhlenbeck type is known to be an ornstein-uhlenbeck type .
multi-way dataflow constraints are important in interactive applications . in this paper , we study the computational complexity of multi-way constraint problems with a restriction on the number of variables . we show that for multi-way constraint problems , the computational complexity of skyblue is o -lrb- n log n -rrb- , where n is the number of variables and n is the number of variables . we also show that the complexity of skyblue is o -lrb- n log n -rrb- , where n is the number of variables and n is the number of variables . we also show that local propagation algorithms can be used to compute the optimal solution . finally , we show that the problem of finding the optimal solution is np-hard .
in this paper , we consider two-channel bi-orthogonal pr lter banks , where the lter bank parameter space is constrained to be a scalar quantity . the lattice structure is derived from the pad e table , and its performance is compared with that of a scalar quantity . the results show that the end-to-end delay can be reduced by up to a factor of two , and that the pr property can be controlled by the length of the lter bank . the performance of the proposed two-channel bi-orthogonal pr lter banks is compared with that of the scalar quantity .
this paper presents a sentence generation system based on tree adjoining grammar . the sentence generation system uses a tree adjoining grammar to specify the syntactic choice of a sentence in a sentence . the sentence generation system is composed of three steps : -lrb- 1 -rrb- selecting the best set of features to generate a sentence ; -lrb- 2 -rrb- selecting the best set of features to generate a sentence ; -lrb- 3 -rrb- selecting the best set of features to generate a sentence ; -lrb- 3 -rrb- selecting the best set of features to generate a sentence ; -lrb- 3 -rrb- selecting the best set of features to generate a sentence ; and -lrb- 3 -rrb- selecting the best set of features to generate the best set of sentences . the sentence generation system has been implemented in the framework of tag-based generation systems . the experimental results show that the proposed generation system is capable of generating sentences with high quality .
this paper investigates the influence of grammar probabilities and acoustic probabilities in a continuous speech recognition system . a tree-based vocabulary search strategy is proposed . the searching procedure consists of grammar scoring followed by a tree-based vocabulary search strategy . the searching procedure is based on a theoretical explanation of the distribution of unigrams in the language models . the proposed tree-based vocabulary search strategy is tested on a large vocabulary continuous speech recognition system . the results show that the proposed tree-based vocabulary search strategy is able to reduce the number of bigrams and to reduce the number of bigrams in the searching procedure .
skin detection is one of the most challenging problems in human motion analysis . most of the existing color model-ing approaches assume that the illuminance component of skin color is known . in this paper , we propose a colorspace and color modeling testing methodology for skin detection . the proposed colorspace and color modeling testing methodology assumes that the illuminance component of skin color sct or hsi colorspaces is a mixture of non-rgb col-orspace transformations . the proposed colorspace transformation is based on the assumption that the illuminance component of skin color is independent of the receiver operating characteristic curve . the proposed colorspace transformation is compared with the skin color modeling , and the proposed colorspace transformation is compared with manual ground truth . the results show that the proposed colorspace transformation is superior to the state-of-the-art skin color modeling . moreover , the proposed colorspace and color modeling testing methodology is very effective in classifying and classifying .
question retrieval in community-based question answering services is a challenging task due to word mismatch . in this paper , we propose a pivot language translation based approach to extract paraphrases of key concepts . in the pivot language translation based approach , the paraphrases of key concepts are extracted from the word level of the query question . then , the paraphrases of key concepts are extracted by the pivot language translation based approach . experimental results show that the proposed pivot language translation based approach can achieve better performance than the state-of-the-art methods . in addition , the proposed pivot language translation based approach can effectively utilize the paraphrases of key concepts to improve the performance of question retrieval .
in this paper , we investigate the use of cross-lingual bottleneck features for acoustic models , such as deep neural networks and gaussian mixture models . we propose a non-parametric kernel density estimation method to estimate the emission probability of hmm states given the speech training data . in the proposed non-parametric kernel density estimation method , speech class posteriors are represented by a kernel density , which is then used to estimate the emission probability of hmm states . we evaluate the proposed non-parametric kernel density estimation method on the wall street journal task and show that the proposed non-parametric kernel density estimation method outperforms the conventional acoustic models when the amount of training data is limited . furthermore , we show that the proposed non-parametric kernel density estimation method can be applied to both gmm and dnn models for the limited training data case .
in this paper , we propose a novel unsupervised label propagation algorithm to extract opinion targets from chinese microblog messages . unlike traditional sentiment analysis techniques that rely on microblog messages , our unsupervised label propagation algorithm does not require any knowledge about the length limit or informal writing style . instead , our unsupervised label propagation algorithm first extracts hashtags from chinese microblogs , and then extracts hashtags from the tweets by clustering algorithms . we evaluate our unsupervised label propagation algorithm on two chinese microblogs , and show that our unsupervised label propagation algorithm significantly outperforms the state-of-the-art methods . we also show that our unsupervised label propagation algorithm achieves a fine-grained word-level task .
state likelihoods in an automatic speech recognition system have been shown to be very effective in reducing the mismatch between training and test conditions . in this paper , we propose a method to estimate the state likelihoods for an automatic speech recognition system . the proposed method is based on partial least squares regression and learning-based methods for mapping the speech state likelihoods to recognition exemplars . the proposed method is evaluated on the chime noisy speech database and compared to a binary labeling system . the results show that the proposed method improves the recognition performance on the at-6 db snr .
we present a generative model and learning procedure for unsupervised video clustering . the generative model and learning procedure is based on computationally intensive learning , which allows for efficient computation of the kl divergence . the generative model and learning procedure is based on a computationally intensive learning of the mixture of gaussians . the resulting generative model and learning procedure can be applied to any video browsing tool , including the clustering of gaussian mixtures , on-line learning , recursive model estimation , and fast inference . the generative model and learning procedure can be applied to a wide range of applications , including clustering , efficiency , and recursive model estimation .
network topology control in wireless networks is an important research area . in this paper , we propose a fully distributed algorithm for network topology control in wireless networks . the fully distributed algorithm is based on game theory concepts and is able to achieve joint power and topology control of a connected network . simulation results show that the proposed fully distributed algorithm is able to achieve a non-cooperative game with a small number of agents .
lattice adaptation techniques have been shown to improve the performance of speaker-dependent models in conversational telephone speech transcription . in this paper , we investigate the use of lattice adaptation techniques to improve the performance of speaker-dependent models for conversational telephone speech transcription . in particular , we investigate the effect of thresholding frame posteriors on the performance of transcript-based adaptation . we show that lattice adaptation with iterative cascaded lattice system results in an improvement of up to 11.5 % in unhind/supervised adaptation gap compared to conventional lattice adaptation with iterative and cascaded adaptation . furthermore , we show that the local best-confidence path of the iterative cascaded lattice system can be used to improve the performance of the lattice adaptation .
in this paper , we consider the problem of sequential probabilistic inference in nonlinear non-gaussian systems , where the posterior state density is modeled by a gaussian mixture model . we propose a recursive bayesian estimation algorithm , where the weights of the particle filters are estimated by maximizing the posterior state density of the weighted particle set . the measurement update step is based on a weighted em algorithm , where the weights of the particle filters are updated during the resampling stage . the proposed recursive bayesian estimation algorithm has a computational complexity that is linear in the number of particles . the proposed recursive bayesian estimation algorithm can be applied to both time-update and proposal distribution generation . simulation results demonstrate the effectiveness of the proposed recursive bayesian estimation algorithm .
this paper presents a corpus-based study on spontaneous speech phenomena in everyday male and female speech . the corpus consists of recordings of spontaneous telephone and face-to-face conversations . the corpus consists of spoken language corpora , which consist of repetitions , insertions , deletions , and phoneme substitutions . the data-mining '' approach is used to analyze gender-specific characteristics in everyday male and female speech . the data-mining '' approach was found to be robust to pronunciation variation , while the data-mining '' approach was found to be robust to pronunciation variation .
in this paper , we consider the sum-rate of a multihop wireless sensor network with complex amplification coefficients at the relay node . we propose an alternating optimization approach to jointly optimize the power allocation parameters and the linear receiver . we derive constrained maximum sum-rate expressions for the achievable sum-rate of a multihop wireless sensor network with equal power allocation at the relay node . we also propose an amplify-and-forward scheme to maximize the sum-rate of a multihop wireless sensor network with complex amplification coefficients . simulation results show that the proposed alternating optimization approach can significantly improve the sum-rate of a multihop wireless sensor network .
gaussian dynamic warping -lrb- gaussian dynamic warping -rrb- is a popular acoustic modeling method for real world applications , such as voice-based and door security systems . in this paper , we propose a novel acoustic modeling method , called gaussian dynamic warping , to model the acoustic variability of speech . gaussian dynamic warping is based on a hierarchical statistical framework with specialization and temporal structure information component . gaussian dynamic warping extends gaussian dynamic warping to deal with the acoustic variability of speech by introducing temporal constraints on the training data . gaussian dynamic warping has been successfully applied to a large vocabulary continuous speech recognition -lrb- lvcsr -rrb- speaker detection task . the experimental results show that the proposed acoustic modeling method outperforms the conventional acoustic modeling method based on hierarchical statistical framework with specialization .
in this paper , we propose a novel approach to the budgeted maximum coverage problem , where the goal is to find a subset of sentences that maximizes the expected utility of a given sentence . we formulate concept pruning as a budgeted maximum coverage problem , where the goal is to find a subset of sentences that maximizes the expected utility of a given sentence . we propose an approximation algorithm for concept pruning , which is guaranteed to find a subset of sentences that maximizes the expected utility of a given query . we show that inference in our approximation algorithm is np-hard and can be solved efficiently using a solver that uses low-weight concepts . we evaluate our approach on a set of benchmark datasets , and show that our approach significantly outperforms the state-of-the-art .
multi-resolution sub-band cepstral features -lrb- multi-resolution sub-band cepstral features -rrb- have been shown to provide discriminative cues for phoneme recognition in broadband noise . in this paper , we propose a sub-band approach based on non linear recombination , where sub-band cepstral features are derived from sub-band decomposition , and full bandwith cepstral features are combined with independent multi-resoltuion sub-band models . in the sub-band approach , the sub-band cepstral features are decomposed into localised regions and the log likelihood probabilities of the sub-band cepstral features are computed . in the proposed sub-band approach , the signal to noise ratio is reduced to the signal to noise ratio . in the phoneme recognition experiments on timit database , the proposed multi-resolution sub-band cepstral features provide significant improvements over the conventional mfcc features in terms of phoneme recognition performance in broadband noise . in addition , the mult-iresolution feature vectors obtained by the proposed multi-resolution sub-band cepstral features are more discriminative than those obtained by the conventional methods , especially in narrow band noise . in addition , the partial recognition scores obtained by the proposed multi-resolution sub-band cepstral features are comparable to those obtained by the original sub-band cepstral features .
in this paper , we propose a new approach to speech recognition based on the forward-backward probability generated targets . the forward-backward probabilities are used to model the continuous targets . the proposed approach is evaluated on a continuous digits recognition task . it is shown that the proposed approach can reduce the error rate by about 10 % compared to the conventional approach .
in this paper , we propose two different pronunciation modeling approaches , namely pronunciation modeling and n-best rescoring approach , to improve the performance of non-native speech . the pronunciation modeling is based on a speaker clustering approach , and the latent pronunciation analysis is used to perform speaker clustering . the experiments show that the pronunciation modeling performs better than n-best list rescoring , and the pronunciation modeling is more effective than n-best list rescoring . furthermore , the pronunciation modeling is more effective than n-best list rescoring .
we consider the problem of unsupervised learning of clusters of printed characters from noisy test data . we consider the problem of learning a mixture model of binary data , where the observed data is represented by a mixture of cluster-centers . we propose a method for learning a multiple cause model from a mixture of binary data . the multiple cause model is based on a weighted sum of the observed data and the observed data is modeled by a multiple cause model . the multiple cause model is then used to estimate the parameters of the mixture model . we demonstrate the effectiveness of the proposed method by applying it to recognition , learning , and sigmoid squashing data reconstructions .
in this paper , we address the problem of 3d shape recognition from color video using point clouds and 2d object tracking . we propose a novel approach based on the faq representation , which is based on online subspace learning . the faq representation consists of two parts : -lrb- i -rrb- euclidean , -lrb- ii -rrb- euclidean , -lrb- iii -rrb- euclidean , and -lrb- iv -rrb- a hashing scheme . the proposed approach is evaluated on a public dataset . the experimental results show that the proposed approach outperforms the state of the art .
in this paper , we propose a new method for learning image density functions in hidden markov models . the method is based on the classiica-tion of dynamic hand gestures in the context of diierent low level image features . the image density functions of the hidden markov models are derived from the statistics of the probability density values of the image intensities and the geometry of the image is represented by a set of diierent low level image features . the performance of the proposed method is compared with the state of the art methods .
in this paper , we present a method for the automatic extraction of phrases from text . the method is based on the detection of the linguistic relations between emotions in text . emotion keywords are extracted from a corpus of emotion , which is annotated with a syntactic and dependency parser . the syntactic and dependency parser are trained on the rules and the resulting rules are used to extract emotion-cause linguistic relations . the method is evaluated on a corpus of emotion , and the results show that the method is effective for the detection of the linguistic relations . the method is also shown to be effective for the automatic extraction of phrases from text .
in this paper , we propose a geometric min-hashing approach to address the problem of small object discovery in viewpoint images . the proposed geometric min-hashing approach consists of two stages : -lrb- 1 -rrb- a hash key consists of visual appearance -lrb- visual words -rrb- and a set of hashes . -lrb- 2 -rrb- a geometric min-hashing approach is proposed to automatically select the most informative hash keys based on geometric information . -lrb- 3 -rrb- a geometric min-hashing approach is proposed to automatically select the most informative hash keys from a large scale image clustering problem . -lrb- 3 -rrb- a geometric min-hashing approach is proposed to select the most informative hash keys based on a set of semi-local geometric information . -lrb- 3 -rrb- a geometric min-hashing approach is proposed to solve the problem of image retrieval , automatic object discovery , and clustering . -lrb- 3 -rrb- a novel geometric min-hashing approach is proposed to deal with the large scale image clustering problem in the presence of random collisions . -lrb- 3 -rrb- the proposed geometric min-hashing approach is evaluated in terms of both recall -lrb- probability of collision -rrb- and false positive rates . experimental results show that the proposed geometric min-hashing approach outperforms the state-of-the-art methods in both image retrieval and automatic object discovery .
minimum perfect hashing -lrb- mph -rrb- has been shown to be effective in language model lookahead time for lvcsr decoding . in this paper , we propose a novel order-preserving property of string-key based mph function to speed up the hashing operation . the string-key based mph function is based on the order-preserving property of the original string-key based mph function , which allows us to reduce the lm lookahead time by exploiting the subtree structure of trigrams . the proposed order-preserving mph and subtree cache structure are exploited to speed up the structure design . experiments on switchboard data show that the proposed order-preserving mph and lm lookahead can reduce the lm lookahead time by a factor of three . furthermore , the proposed order-preserving mph can reduce the number of subtrees in the original string-key based mph function while keeping the lm lookahead time comparable to that of the original order-preserving mph .
in this paper , we consider the estimation problem of high-dimensional tensor-valued data with dependency structure in the form of a tensor normal distribution with kronecker product structure . we propose an alternating minimization algorithm to recover the sparse precision matrix with a non-convex objective function . the proposed alternating minimization algorithm has a statistical rate of convergence of o -lrb- n 2 log n -rrb- , where n is the number of samples and n is the rank of the precision matrix . the proposed alternating minimization algorithm converges to the optimal solution of penalized maximum likelihood estimation , where n is the number of samples and n is the rank of the precision matrix . the proposed alternating minimization algorithm has a statistical rate of convergence of o -lrb- n 2 log n -rrb- , where n is the number of samples and n is the number of samples . the proposed alternating minimization algorithm has been applied to the problem of consistent graph recovery in sparse graphical models . numerical studies show that the proposed alternating minimization algorithm achieves better estimation consistency than the state-of-the-art estimator in terms of estimation consistency .
in this paper , we propose a novel method for representation of image ensembles based on the tensor subspace model . the proposed method is based on the subspace analysis in a multilin-ear framework with high-order tensors . the tensor reconstruction error norm is used to define the likelihood function . the proposed method is based on the recently proposed online tensor subspace learning algorithm , which is a low-order tensor eigenspace representation of image ensembles . the proposed method has a computational and memory cost that is linear in the number of samples and the number of samples . moreover , the proposed method can deal with spatio-temporal redundancies in the tensor subspace model . moreover , the proposed method can deal with the subspace analysis in the multilin-ear framework . theoretic analysis and experimental results demonstrate the effectiveness of the proposed method .
early word learning -lrb- early word learning -rrb- is one of the most widely used methods in robotics , neural networks , and speech recognition systems . in this paper , we investigate the use of audiovisual integration in non-human animals in the context of audiovisual integration . specifically , we consider the case of audiovisual video sequences with arbitrary geometrical objects , and show that it is possible to learn a model of the visual appearance of the objects in the presence of noise . we then show that this model can be used to model the dynamics of the audiovisual video sequences . finally , we show that this model can be used to model the dynamics of the audiovisual integration in non-human animals .
in this paper , we address the problem of online unsupervised pattern discovery in an offline manner using segmental dtw . the proposed method is based on segmental dynamic time warping , which allows us to efficiently detect speech utterances in a static or dynamic way . the proposed method is evaluated in a 32-processor system , and it is shown that the proposed method outperforms the state-of-the-art methods in terms of both speed and computational requirements . furthermore , it is shown that the proposed method is capable of performing online unsupervised pattern discovery in an 8-processor cluster .
in this paper , we consider the adversarial contextual bandit problem , where the goal is to minimize the average reward of a learner given a set of actions . we consider the adversarial contextual bandit problem , where the learner is allowed to observe the actions of the learner , and the learner is allowed to observe the actions of the learner . we consider the adversarial contextual bandit problem , where the learner is allowed to observe the actions of the learner , and the learner is allowed to observe the actions of the learner . we show that , in the adversarial contextual bandit problem , the learner can only observe the actions of the learner , and the learner can observe the actions of the learner . in the adversarial contextual bandit problem , the learner can only observe the actions of the learner , but also have a priori on the actions of the learner . we propose an efficient algorithm for this adversarial contextual bandit problem that achieves o -lrb- t 3 4 -rrb- barrier , where d is the number of actions of the learner and d is the number of actions of the learner . our algorithm is based on an offline optimization oracle , where t is the number of iterations , and t is the number of actions of the learner . we prove that our algorithm achieves o -lrb- t 3 -rrb- barrier for the adversarial contextual bandit problem , where t is the number of actions of the learner and t is the number of actions of the learner . we also provide an efficient relaxation based approach for this adversarial contextual bandit problem , and show that our algorithm can achieve o -lrb- t 3 -rrb- barrier .
we consider the worst-case robust optimization problem where the vector of binary variables is known to be np-hard . we propose a relaxation step based on lagrangian duality to solve this worst-case robust optimization problem . the relaxation step is based on the concept of a coefſcient matrix h , where the goal is to minimize the sum of squared errors of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the norm of the
dyadic deontic logics -lrb- dyadic deontic logics -rrb- have recently been proposed as an alternative to dyadic deontic logics for deontic reasoning . however , dyadic deontic logics have not been considered in the context of deontic reasoning , since dyadic deontic logics do not allow for expressing deontic reasoning . in this paper , we show that such dyadic deontic logics are incompatible with the notion of defeasibility , i.e. , under the assumption that a deontic logic is a deontic logic , there exists a deontic logic that satisfies all the desirable properties of the deontic logic . furthermore , we show that the notion of defeasibility is incompatible with the notion of deridden , i.e. , the notion of defeasibility , i.e. , that there exists a deontic logic that satisfies all the properties of the deontic logic . we also show that the notion of defeasibility is incompatible with the chisholm and for-rester ` paradoxes ' , and that the notion of defeasibility is incompatible with the notion of default logics . finally , we show that the notion of defeasibility is incompatible with the notion of defeasibility , and that the notion of deridden defeasibility is incompatible with the notion of a deontic logic . finally , we show that the notion of defeasibility is incompatible with the notion of deontic logic , and that the notion of defeasibility can be expressed in chisholm and for-rester ` paradoxes ' .
in this paper , we propose a semi-automated method to estimate the hand depth video from a set of reference frames . our semi-automated method consists of three steps : -lrb- 1 -rrb- a set of reference frames , -lrb- 2 -rrb- a set of reference frames , -lrb- 3 -rrb- a set of 3d locations , and -lrb- 3 -rrb- a set of spatial , temporal , and appearance constraints . -lrb- 3 -rrb- an efficient and efficient hand pose estimation method . -lrb- 3 -rrb- a sub-modular loss function is used to refine the labeling , and -lrb- 3 -rrb- an efficient hand pose estimation method is proposed to estimate the fine hand pose . the proposed semi-automated method is evaluated on two challenging datasets , i.e. at/projects/hand , and the results show that our semi-automated method is able to accurately estimate the hand depth video from a single image . the accuracy of our hand pose estimation method is comparable to that of state-of-the-art hand pose estimation methods .
model-based reinforcement learning -lrb- model-based reinforcement learning -rrb- is a powerful tool for solving nonlinear learning problems . model-based reinforcement learning has been shown to be effective in solving linear quadratic regulator problems , but its robustness to initial biases is limited by the amount of training data . in this paper , we consider the problem of learning a q-function from a set of demonstrations . the q-function is a generalization of model-based reinforcement learning to linear quadratic regulator problems , where the q-function is a function of the value function , and the q-function is a function of the prior knowledge of the environment . we show that the learning problem can be solved efficiently using the framework of pole balancing . we demonstrate the effectiveness of the approach by applying it to real signal processing .
we study the problem of finding the optimal model parameters in ibm model 1 . we propose a linear programming approach to finding the optimal model parameters in the presence of multiple optima and non-strict convexity . we show that the proposed linear programming approach can be used to find the optimal model parameters in the presence of random trials . we evaluate the proposed linear programming approach on the test set log-likelihood and the alignment error rate of ibm model 1 , and show that the proposed linear programming approach is competitive with the state of the art .
in this paper , we consider the problem of convolutive bss in a meeting environment . we propose a least-squares post-processing scheme to improve the separation performance of sirs in the presence of speaker overlap . the proposed least-squares post-processing scheme is based on the assumption that the audio perspective is independent of the speaker overlap . the proposed least-squares post-processing scheme is evaluated on both simulated and real data . the results show that the proposed least-squares post-processing scheme outperforms the conventional depermutation scheme in the presence of speaker overlap .
interactive language use is an important topic in computational linguistics . in this paper , we present metalinguistic displays , called hedges , which allow users to specify referring expressions in communication media shape conversations . metalin, which we call hedges , is an interactive language use that allows users to interact with computers through communication media shape conversations . we show how these metalinguistic displays can be used to study the interaction between cognitive and interpersonal processes in computational linguistics .
recurrent network archi-tectures have been shown to be powerful tools in unsupervised learning , bayesian inference , and synaptic plasticity in cortical microcircuits with synaptic plasticity . however , the theoretical limitations of these recurrent network archi-tectures are still poorly understood . in this paper , we present a mathematical treatment of probabilistic inference in spiking networks . we show that a ` balancing ' posterior constraint can be interpreted as a ` balancing ' posterior constraint on the synaptic plasticity rules and neuronal activation functions . this ` balancing ' posterior constraint can be interpreted as a neural implementation of expectation maximization , which can be interpreted as a generalization of probabilistic inference in recurrent network archi-tectures . in particular , we show that the ` balancing ' posterior constraint can be interpreted as a generalization of expectation maximization in terms of nontrivial terms , which allows for efficient inference and learning . we illustrate our mathematical treatment with a neural implementation of spiking networks .
in this paper , we study the language gap problem in speaker recognition systems . we study the effect of language factors on the performance of speaker recognition systems trained on english training data . in particular , we investigate the effect of language factor compensation on the performance of speaker recognition systems . in particular , we investigate the effect of session variability compensation on the performance of speaker recognition systems on the nist speaker recognition evaluation . we find that the effect of language factors on the performance of the speaker recognition systems is affected by the effect of the language factors on the performance of the speaker recognition systems . in addition , we investigate the effect of the effect of language factors on the performance of the speaker recognition systems on the nist speaker recognition evaluation . we find that the effect of language factors on the performance of the speaker recognition systems is affected by the use of the joint factor analysis model . we also find that eigenchannels session variability compensation is an effective way to compensate for the effect of the language factors on the performance of the speaker recognition systems .
eye fixations play an important role in image understanding and understanding . in this paper , we propose a novel eye fixation database for an active image segmentation application . the eye fixation database is based on the eye-tracker that generates fixation patterns from the eye fixation database . the eye fixation database contains salient objects in the scene , which serve as characteristic fixation seeds for segmentation . the fixation seeds are selected from the salient object , which are then used to detect salient objects in the scene . the eye fixation database is used to detect fixation patterns in the image . the experimental results show that the proposed eye fixation database is more accurate than existing feature-driven approaches based on saliency computation algorithms . moreover , the proposed eye fixation database can be used for image understanding , and can be used to detect salient objects in the scene .
in this paper , we propose system-driven metrics , such as the bit-error rate , for design and adaptation of analog converters . these system-driven metrics , such as the mutual information , are designed to minimize the information rate of the communication link . these system-driven metrics are designed to optimize application meaningful criteria , such as forward error correction and adaptation of the communication link . the adc design methods are based on fixed uniform quantization , and the adc design methods are designed to minimize the average error of the error of the communication link . simulation results show that the bit-error rate can be used to improve the communication performance of the digital converters .
in this paper , we address the problem of dense optical flow estimation from a single image . we propose a focusing strategy based on a multi-resolution technique to estimate the dense optical flow field map from a set of images . the variational problem is formulated as a gradient flow on the flow field , which is solved by a novel gradient flow , which can be solved efficiently . the proposed focusing strategy is based on a multi-resolution technique , which allows us to obtain symmetrical solutions . the proposed focusing strategy is evaluated on both synthetic and real images , including images i1 , i2 , and i2 . the experimental results show that the proposed focusing strategy outperforms the state-of-the-art methods in dense optical flow estimation . moreover , we show that the proposed focusing strategy is robust to occlusions and can handle large displacements .
in this paper , we present a method for estimating the relative pose of the light field cameras from 3d point clouds . our method is based on the observation that the scene geometry of a scene can be represented by a set of ray space correspondences with linear constraints on the scene geometry . we show that the relative pose of the light field cameras can be used to estimate the pose estimates for 4d light field cameras , which are then used to estimate the relative pose of the light field cameras . in particular , we show how to estimate the pose of a light field structure from a set of point cloud reconstruction of the scene using generalized cameras . we also show how to estimate the pose estimates for the light fields using the plücker ray coordinates of the scene . we demonstrate the effectiveness of our method on a set of refocus-able panoramas consisting of hand-held consumer light field cameras .
the discrete karhunen-loeve transform and the discrete prolate <s> the discrete karhunen-loeve transform are studied in the frequency domain . it is shown that the discrete karhunen-loeve transform and the discrete prolate <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> in this paper , we show that the discrete karhunen-loeve transform can be computed in the frequency domain using the principal eigenfunc-tion center of a medium order solution . the relationship between the discrete karhunen-loeve transform and the discrete prolate <s> <s> the discrete karhunen-loeve transform is established in the frequency domain . furthermore , the relationship between the discrete karhunen-loeve transform and the discrete prolate <s> <s> <s> <s> <s> <s> the discrete karhunen-loeve transform is established by means of a frequency approximation of the signal spectrum . finally , the relationship between the discrete karhunen-loeve transform and the discrete prolate spec-trooidal wave functions is discussed .
we present a `` neural gas '' method for learning topological relations between a set of topologies . the `` neural gas '' method consists of two steps : clustering , vector quantization and interpolation . the first step uses an incremental network model to represent the topological relations between pairs of topologies . the second step uses an incremental network model to learn the parameters of the `` neural gas '' method . the third step is to learn the parameters of the `` neural gas '' method . the third step is to learn the parameters of the `` neural gas '' method by minimizing a performance criterion . we demonstrate the effectiveness of the `` neural gas '' method by applying it to a variety of topologies .
hidden markov models -lrb- hidden markov models -lrb- hmm 's -rrb- are powerful tools for modeling the structure of an observable image . however , hidden markov models -lrb- hmm 's -rrb- 's -rrb- factorial mrf 's factorial mrf 's factorial mrf 's factorial mrf 's factorial mrf 's factorial mrf 's factorial mrf 's factorial mrf 's can be viewed as a wide inference step . in this paper , we propose a markov random field model for layers and show that the factorial hmm 's factorial mrf 's factorial mrf 's factorial mrf 's factorial mrf 's factorial mrf 's can be interpreted as an em-based algorithm for efficient inference . we evaluate our markov random field model on both real and synthetic images and show that our markov random field model 's factorial mrf 's factorial mrf 's factorial mrf 's performance is comparable to the state of the art in wide inference . we also show that our markov random field model 's output can be used for binary segmentation with graph cuts .
in this paper , we present a real-time method for analyzing human body in clothing using loose-fitting clothing . our real-time method is based on the observation that the human body can be represented by a small number of body-part labels , each of which can be represented by a small number of time-series volumes . our real-time method is based on the observation that the human body can be represented by a small number of time-series sample volumes , each of which is represented by a small number of time-series sample volumes obtained by pca . we use a hierarchical search to find the most likely body parts in the eigenspace , and a 3d reconstruction algorithm to find the most likely body parts . we demonstrate the effectiveness of our real-time method by comparing our real-time method with a state-of-the-art 3d reconstruction algorithm .
single channel source separation -lrb- single channel source separation -rrb- is a challenging problem in single channel source separation . in this paper , we propose a deep neural network architecture based on nonnegative matrix factorization to address the single channel source separation problem . in the training stage , a mixed signal spectrum is learned from the estimated source spectra . in the training stage , a deep neural network architecture is trained to separate the source signals from the mixed signal spectrum . in the training stage , a deep neural network architecture is trained to separate the target signals from the training data . in the separation stage , a deep neural network architecture is trained to separate the target signals from the training data . in the training stage , the energy scale differences between the source and the target signals are minimized . in the testing stage , the deep neural network architecture is used to separate the source signals from the background . in the testing stage , the deep neural network architecture is used to separate the target signals from the background . in the testing stage , the deep neural network architecture is used to separate the source signals from the background . the experimental results show that the proposed deep neural network architecture outperforms the state-of-the-art methods for source separation .
in this paper , we consider the uplink cdma system where base station coverage for wireless flat fading channels is considered . the uplink cdma system is designed to minimize the base station coverage subject to multi-cell interference . we consider two different receiver structures : the matched filter , the wiener filter and the optimum filter . we derive asymptotic arguments for the spectral efficiency of the uplink cdma system . simulation results show that the performance of the proposed uplink cdma system is very close to that of the random spreading network capacity .
<i> principal component analysis </i> -lrb- <i> principal component analysis </i> -rrb- is a popular dimensionality reduction algorithm for learning a projection value that minimizes the minimal <i> local </i> estimation error . <i> principal component analysis </i> is a popular method for linear dimensionality reduction . however , <i> principal component analysis </i> does not capture the local information contained in the projection values . in this paper , we propose a novel <i> principal component analysis </i> - based dimensionality reduction algorithm . unlike <i> principal component analysis </i> , <i> principal component analysis </i> - based <i> principal component analysis </i> - based methods , <i> principal component analysis </i> learns a projection value that minimizes the minimal <i> global </i> estimation error . in addition , <i> principal component analysis </i> can be used to estimate the minimal <i> global </i> estimation error . experimental results on several classification tasks show that <i> principal component analysis </i> - based <i> principal component analysis </i> - based methods can significantly improve the performance of <i> principal component analysis </i> .
in this paper , we consider the problem of decoding binary symbols transmitted by a linear isi channel corrupted with additive white noise . we propose a receiver based on a variable order markov model , which is trained using a crudely quantized training sequence . the variable order markov model is then used to train the receiver for the inter-symbol interference channel . the maximum likelihood sequence estimator is then used to estimate the inter-symbol interference channel . we compare the performance of the proposed receiver with other gaussian based algorithms such as decision feedback equalization , gradient based adaptation , and decision feedback equalization . the results show that the proposed receiver achieves better receiver performance in the presence of heavy-tailed noise compared to the conventional maximum likelihood sequence estimator .
ridge regression , such as the adaptive ridge , has been widely used in many applications such as sparse regression with kernel smoothing , additive modeling , neural net training , etc. . in this paper , we study the equivalence of ridge regression , i.e. , the adaptive ridge , and its series ofpossi-ble extensions oflasso . in particular , we show that the lasso solution is equivalent to the fixed point algorithm for the lasso solution . in particular , we show that the lasso solution can be expressed as a quadratic penalizer of the lasso . in particular , we show that the quadratic penalization of the lasso is equivalent to the ordinary least absolute shrinkage of the lasso solution . moreover , we show that the model complexity can be reduced by a factor of o -lrb- 1 / √ n -rrb- , where n is the number of variables and n is the number of variables . finally , we show that the model complexity can be reduced to o -lrb- log n -rrb- , where n is the number of variables .
natural language processing -lrb- natural language processing -rrb- for less privileged languages has received much attention in recent years . in this paper , we present a study on natural language processing for less privileged languages . we show that the performance of natural language processing in less privileged languages is comparable to that of natural language processing .
in this paper , we consider the problem of distributed control in the context of a multiagent system . we propose a distributed swarm control mechanism that allows agents to communicate with their own sensory activity . the distributed swarm control mechanism is based on the concept of '' parasitic '' , which is a distributed system of distributed agents . the distributed swarm control mechanism is based on the concept of '' parasitic '' , i.e. , a swarm that is a distributed system with a small number of code modules . the distributed swarm control mechanism is composed of three modules : social norms , herders , and social norms . the distributed swarm control mechanism enables agents to communicate with their own biological parasites , and the behavior manipulation properties of their biological parasites can be controlled by the behaviors of their individual modules . we show that this distributed swarm control mechanism can be used to control the behavior of a distributed system . we present simulation results that show that our distributed swarm control mechanism is able to control the behavior of a multiagent system , and that our distributed swarm control mechanism is able to control the behavior of a group of agents with small number of agents .
machine learning has been widely used in internet applications such as sponsored search . in this paper , we study the generalization analysis of game-theoretic machine learning -lrb- game-theoretic machine learning -rrb- , where the goal is to minimize the generalization error for the behavior learning error . we propose two generalization analysis techniques to obtain uniform convergence for the behavior learning error . first , we derive non-asymptotic error bounds for the behavior learning error under the markov behavior model . second , we provide a generalization analysis for both parametric and non-parametric behavior learning methods . the proposed generalization analysis techniques are based on the assumption that the behavior data is generated by the distribution of self-interested agents and the behavior data is generated by the markov behavior model . the experimental results show that the proposed generalization analysis techniques are able to achieve uniform convergence for the behavior learning error .
this paper considers the problem of secure communications under rayleigh fading and path loss . we propose a probabilistic framework for physical layer secrecy in which the eavesdropper locations and channels are modeled as a poisson point process with unknown eavesdropper locations and channels . we show that the proposed probabilistic framework is able to achieve physical layer secrecy under certain conditions , including beamforming with unknown eavesdropper locations and channels .
in this paper , we propose a novel acoustic model for statistical parametric speech synthesis based on neural networks for statistical parametric speech synthesis . in the proposed acoustic model , linguistic features of the speech waveform are modeled as stochastic components in the probability density function of the speech waveform . in the proposed acoustic model , the unvoiced component is modeled as a gaussian process , where the mean and covariance functions of the speech waveforms are modeled as a non-zero mean gaussian process , and the unvoiced component is modeled by a set of neural networks . the experimental results show that the proposed acoustic model can generate natural speech waveforms with high quality speech waveforms .
in this paper , we present an agent-based model of the acquisition of a language system of grammatical constructions . the agent-based model consists of two steps : adaptation , adoption induction , and adaptation . the first step is to generate logical combinations of categories , and the second step is to generate a set of boolean functions . the second step is to generate a set of grammatical constructions , which are then used to generate a set of logical constructions . the third step is to generate a set of logical constructions , which are then used to construct a language system . the process is based on an agent-based model of the language system . we show that the agent-based model can be used to generate a variety of constructions , including those that can be used for adaptation and adoption induction .
we consider the problem of learning linear classifiers for categorical data using a multinomial manifold . we propose a generalized margin concept for hyperplane classifiers , which is based on the multinomial family . unlike previous margin-based hyperplane models , our generalized margin concept allows us to capture the multinomial geometry by exploiting fisher information in the form of a riemannian structure in the multinomial manifold . we show that the proposed generalized margin concept can be used to learn a family of linear classifiers for categorical data . we apply our classification framework to text classification and show that the proposed classification framework outperforms the state-of-the-art methods .
in this paper , we present a novel approach to disparity justifying the computation of a discrete representation of stereo correspondence using a center-referenced basis . the key idea of our approach is to use a sparsely connected trellis to approximate the map context in order to reduce the computational complexity of existing d p methods . in addition , we propose to use a parallel solution in order to reduce the number of occlu-sion nodes in the map context . this allows us to exploit natural constraints in the map context to reduce the computational complexity of the matching . we demonstrate the effectiveness of our approach on several challenging stereo sequences .
personal use of this material is permitted . however , permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists , or to reuse any copyrighted component of this work in other works must be obtained from the ieee . abstract in this paper , we consider the problem of spectrum sensing and anomaly detection in cognitive radio . we propose a novel soft decision detector for spectrum sensing and anomaly detection , which is based on a bayesian approach . the soft decision detector is able to perform signal denoising and anomaly detection in the presence of noise . the performance of the soft decision detector is evaluated by comparing its performance to that of the soft decision detector for signal denoising and anomaly detection in the presence of noise . the results show that the soft decision detector is able to perform well in the presence of noise .
utterance verification -lrb- utterance verification -rrb- is an important component of an asr system . in this paper , we propose a new measurement score for utterance verification based on n-best hmm scores . the proposed measurement score is based on sorted likelihood ratios , which contain selective components in the sequence of sorted likelihood ratios . in order to evaluate the performance of the proposed measurement score , we propose to use the sorted likelihood ratios as a measurement score for utterance verification . we also propose a attraction-based measurement framework to evaluate the performance of the n-best and compare its performance with that of hypothesis testing . experimental results show the effectiveness of the proposed competition-based measurement framework .
in this paper , we propose a birdsong-phrase segmentation and verification algorithm for segmenting continuous recordings with additive noise . the birdsong-phrase segmentation and verification algorithm consists of a noise-robust template and a discriminative classifier for outlier rejection . the proposed birdsong-phrase segmentation and verification algorithm consists of two steps : -lrb- 1 -rrb- a support vector machine to estimate segment boundaries , and -lrb- 2 -rrb- a support vector machine to estimate segment boundaries . the proposed birdsong-phrase segmentation and verification algorithm is robust to noise , class variability , and limited training data . the proposed birdsong-phrase segmentation and verification algorithm is evaluated on cassin 's vireo recordings . the results show that the proposed birdsong-phrase segmentation and verification algorithm outperforms the state-of-the-art energy or entropy-based birdsong segmentation algorithms . moreover , the proposed birdsong-phrase segmentation and verification algorithm does not require manual annotations for training .
matching of traffic signs in images is an important problem in computer vision . in this paper , we present a method to recover the homography from a set of binary images . the method is based on the assumption that the homography is a planar object with respect to a planar homography . the method is based on solving a set of nonlinear equations with linearly independent functions that are invariant to segmentation errors . the method is tested on real images , and it is shown that the method is robust to deformation and is robust to segmentation errors . the method is also applied to the matching of traffic signs .
in this paper , we propose a novel method for reconstructing point sources from redving blurred point sources with intensity images . the proposed method is based on the 2-d generalization uf techniques in the 2-d frequency domain . the proposed method consists of two steps : -lrb- 1 -rrb- a regularization operator for array smoothing and -lrb- 2 -rrb- a regularization operator for array smoothing . the proposed method is applied to the problem of image restoration on blurred point sources . the experimental results show that the proposed method can accurately recover the true locations of the moving point sources from the blurred point sources in the presence of noise . the proposed method is applied to the problem of image restoration in music , and the results show that the proposed method can accurately recover the true locations of the moving point sources from the blurred point sources .
in this paper , we study the computational complexity of expressive description logics for query answering over horn fragments . specifically , we focus on the complexity of answering queries over horn fragments , which is the complexity of answering plain conjunctive queries . we study the complexity of answering queries over such expressive description logics , which is the complexity of answering queries over horn fragments . we study the complexity of answering queries over such expressive description logics with shoiq and sroiq , which is a non-trivial generalization of plain conjunctive queries . we show that shoiq and sroiq have a lower bound on the complexity of answering queries over horn fragments , and that shoiq has a lower bound on the decidability of plain conjunctive queries than the full shoiq and sroiq . we also show that shoiq and sroiq have a lower bound on the data complexity than the full shoiq and sroiq .
supervised sentence compression -lrb- supervised sentence compression -rrb- is a challenging problem due to the lack of training data and the lack of training data . in this paper , we propose a lexical-ized noisy channel model for sentence compression . our lexical-ized noisy channel model is based on the intuition that sentences in a sentence are more likely to have similar translations than those in the original text . we also propose a novel approach to learn sentence compression from wikipedia data , which is based on the intuition that sentences in a sentence are more likely to have similar translations in the original text . we evaluate our approach on a standard and challenging data set , and show that our approach significantly outperforms the state-of-the-art in terms of gram-maticality and compression rate criteria . we also show that our approach can be used to improve the performance of supervised sentence compression .
independent components analysis -lrb- independent components analysis -rrb- is a powerful tool for learning deep unsupervised hierarchical feature extractors from high-dimensional data . in this paper , we propose a novel unsupervised feature learning algorithms based on con-volutional formulations of independent components analysis . the proposed unsupervised feature learning algorithms is based on a hybrid variational inference algorithm , where the latent components are shared by the successive model layers , and the latent components are shared by the indian buffet process . the proposed unsupervised feature learning algorithms can be interpreted as an extension of independent components analysis , where the latent components are shared among the successive model layers . the proposed unsupervised feature learning algorithms can be interpreted as an extension of independent components analysis to overcomplete feature learning , where the inference is performed in an unsupervised manner with tedious parameter tuning . the proposed unsupervised feature learning algorithms are evaluated on two challenging action recognition benchmarks , and the experimental results show that the proposed unsupervised feature learning algorithms outperform the state-of-the-art methods .
we present a novel syntactic model , pcfg-la berkeley parser , which is a powerful parser for unseg-mented hebrew text . the pcfg-la berkeley parser is a lattice parsing methodology for parsing . we show that the pcfg-la berkeley parser can be used as a parser for unseg-mented hebrew text , and that the pcfg-la berkeley parser can be used to improve the performance of lattice parsing . in addition , we show that the pcfg-la berkeley parser can be used as a parser for parsing with uncertain inputs , and that the lattice parsing methodology leads to an error reduction of up to 25 % .
auditory visual speech processing -lrb- auditory visual speech processing -rrb- is an emerging area of research in speech science , speech science , psycholinguistics , hearing-impaired communication , and human-machine interaction . in this paper , we present our research on auditory visual speech processing in eurospeech . we focus on the important aspects of auditory visual speech processing , and discuss some of the issues that arise in this area .
in this paper , we propose a data-driven approach to recognize acoustic classes based on phonetic knowledge . in our data-driven approach , acoustic classes are represented by frequency warp-factors , which are modeled as gaussian components in the acoustic model . vocal tract length normalization is performed using a regression class tree , and vocal tract length normalization is performed by vocal tract length normalization using a regression class tree . in the proposed data-driven approach , the acoustic class specific warp-factor is estimated using the wsj database . in the proposed data-driven approach , acoustic class specific warp-factor is estimated by using class tree definitions , and the frequency-warp is estimated using mfcc features . in recognition experiments , the proposed vtln method outperforms the conventional vtln method for vocal tract length normalization . furthermore , the proposed vtln method outperforms the conventional vtln method for vocal tract length normalization , which is based on linear-transformation . furthermore , the proposed data-driven approach does not require any phonetic knowledge of the vocal tract , and can handle physiological differences in vocal tract .
enhanced voice services -lrb- enhanced voice services -rrb- are emerging as a standardized codec for mobile services such as volte . however , the robustness of enhanced voice services depends on the robustness of the enhanced voice services . in this paper , we propose a method for packet loss concealment in evs . the proposed method is based on the use of technical features of evs to improve the robustness of the enhanced voice services . the proposed method is based on the use of a standardized codec , and it is shown that the proposed method can improve the robustness of the enhanced voice services in the presence of jitter buffer management .
in this paper , we propose a new method for image database indexing based on color activity . the proposed method is based on a perceptually modified distance measure based on the sum-of-angles criterion . the perceptually modified distance measure can be used to extract detailed image regions from natural color images . the database indices are extracted from the direcional detail histogram technique . the proposed method is robust to directional detail such as edges , texture , and texture , and is robust to color activity . the retrieval performance of the proposed method is compared with the state-of-the-art histogram thresholding techniques .
in this paper , we propose a novel approach to functional object recognition based on the appearance-based classification paradigm . in particular , we propose a stochastic grammar model to jointly model the object function and the functional parts in the function-geometry-appearance hierarchy . the geometry -lrb- 3d shape , functional parts , functional parts , and 3d geometric shapes -rrb- of the indoor object are represented by a set of line segments , which are represented by a set of 3d primitive shapes . the object function is represented by a joint distribution over the functional parts and the functional parts in the function-geometry-appearance hierarchy . the object function is represented by a stochastic grammar model , which is learned by a simulated annealing mcmc algorithm . the metropolis-hastings acceptance probability of the parse tree is used to find the best configuration of the 3d primitive shapes in the fga space . the proposed indoor scene parsing algorithm is evaluated on three indoor datasets , and the results show that the proposed indoor scene parsing algorithm is able to accurately recognize indoor functional objects with missing objects/parts . moreover , the proposed indoor scene parsing algorithm is robust to missing objects/parts , and can be applied to other tasks such as segmentation and 3d recovery .
bagging methods have been widely used in the machine learning literature to improve the performance of mir systems . in this paper , we investigate the use of intra-song instance bagging to improve the performance of music auto-tagging systems . we propose two ensemble learning techniques , bagging and bagging , to exploit the temporal information of music signals . in the first method , intra-song instance bagging is used to combine the short-time features of both music auto-tagging and music auto-tagging . in the second method , intra-song instance bagging is used to extract the most important part of the temporal signal . in the second method , intra-song instance bagging is used to combine the song-level features of both music auto-tagging and mir systems . in the third method , intra-song instance bagging is used to extract the most important part of the temporal signal . in the third method , intra-song instance bagging is used as a meta algorithm to select the most important part of the music auto-tagging . experimental results show that the proposed bagging methods improve the accuracies of mir systems .
in this paper , we propose a fingerprint embedding method for linear combination collusion attack and anti-collusion code . the embedding method is based on the detection of the code and the orthogonal fingerprint , which is called and-acc . we propose a fingerprint embedding method for the linear combination collusion attack and anti-collusion code . the proposed embedding method is composed of two steps : -lrb- 1 -rrb- a code modulation embedding method for the fingerprinting system and -lrb- 2 -rrb- a code modulation embedding method for the linear combination collusion attack and anti-collusion code . -lrb- 3 -rrb- a fingerprint embedding method for the linear combination collusion attack and anti-collusion code is proposed . the experimental results show that the proposed fingerprint embedding method can achieve better performance than the conventional methods .
story generation is the task of generating a story from a text . in this paper , we propose a narrative prose generator , which is based on the idea that story grammars can be used for plot design . our narrative prose generator is based on the intuition that story grammars can be used for plot design , and that narrative theory can be used to generate stories with poor writing quality . we show that our narrative prose generator can generate prose quality with high complexity , and that our narrative prose generator can generate stories with poor writing quality . we also show that our narrative prose generator can generate stories with poor writing quality .
in this paper , we consider the problem of adaptive beamforming in partly calibrated sensor arrays . we assume that the signal steering vector is known to be structured , and that the signal steering vector can be estimated by a structured , i.e. , a function of the coefficients of the signal steering vector . we propose a worst-case beamformer design where the signal steering vector is estimated by means of a structured semi-definite uncertainty model . we show that , under certain assumptions , the proposed minimum variance beamformer design can achieve the same performance as that of the conventional minimum variance beamformer . furthermore , the proposed estimator is robust to interthe gain-and-phase and the noise of the received signal . simulation results show that the proposed estimator outperforms the existing worst-case designs in the presence of interthe phase mismatches .
in this paper , we propose a human-machine solution to ai-hard problems using crowdsourcing . the human-machine solution is based on mapreduce , which is an incremental scheduling method , and can be used for large-scale distributed computing . the proposed human-machine solution is evaluated on a large , publicly automated public turing test . the results show that the proposed human-machine solution outperforms the state-of-the-art methods in terms of both accuracy and efficiency .
3d data plays an important role in machine vision , especially in bio-medical applications . in this paper , we propose a parameter-free domain adaptation approach based on boosting . in particular , we propose a multi-task learning algorithm for domain adaptation based on boosting . in our multi-task learning algorithm , a non-linear mapping between the labeled data and the target data is learned in a global analytical form . in contrast to existing approaches , our multi-task learning algorithm does not require any distribution annotation or any distribution annotation in the target domain . moreover , our multi-task learning algorithm does not require any distribution annotation in the target domain , and thus can handle task-specific decision boundaries in the target domain . moreover , our multi-task learning algorithm is able to adapt the decision boundary in a shared feature space to the target domain . we demonstrate the effectiveness of our multi-task learning algorithm on bio-medical datasets .
dynamic programming graphs -lrb- dynamic programming graphs -rrb- are a powerful tool for learning optimal bayesian networks . in this paper , we propose a novel dynamic programming algorithm with a layered structure . the proposed dynamic programming algorithm takes advantage of the layered structure of the dynamic programming graphs to achieve re-cursive decomposition of the original dynamic programming graphs . we show that dynamic programming graphs can be used to approximate the re-cursive decomposition of a bayesian network with a binomial coefficient . moreover , the memory requirements of the dynamic programming graphs are o -lrb- n log n -rrb- , where n is the number of variables in the dynamic programming graphs and n is the number of variables in the dynamic programming graphs . the experimental results show that the proposed dynamic programming algorithm is able to learn optimal bayesian networks with a small number of variables .
creaseness measures the curvature of the level curves in a given image landscape . the curvature of the level curves is defined as the extrema of the level set curvatures , and the curvature of the level surfaces is measured by a discon-tinuous creaseness measure . the creaseness measure depends on the curvature of the level curves and on the curvature of the level curves . it is shown that the curvature of the level curves depends on the level curve curvature of the level surfaces . the creaseness measure depends on the number of creases and on the level curve curvature of the level surfaces . it is also shown that the discontinuities in the level curve curvature can be interpreted as a function of the curvature of the level curves . the creaseness measure is also shown to be invariant to local conditions and can be used to compute the creaseness of a given set of creases . it is also shown that the creaseness measure can be used to compute the level curve curvature of a given set of creases .
this study investigates the relationship between segmental and prosodic features of second language intonation -lrb- seoul -rrb- and english speakers of korean . korean speakers of korean were recorded with foreign accents in second language production . the results showed that the phonological properties of intonation were significantly higher than the phonetic properties of intonation , indicating that the phonological properties of intonation are more important than the phonetic properties of intonation . these findings suggest that l2 speakers are more sensitive to prosodic structure and native-like intonation patterns than segmental data . these findings suggest that the phonological system of seoul korean is more likely to have a segment-tone interaction than segmental data . however , these results suggest that segmental data are more important than l2 speakers in their surface tonal realizations .
in this paper , we propose a new class of direct form iir adaptive , which is based on the analysis of the error surface of the modelled system . the direct form iir adaptive , which is based on the constant gain algorithms , is composed of two successive steps : -lrb- 1 -rrb- the first step is to project the complex poles into a set of underdamped low-frequency poles ; -lrb- 2 -rrb- the second step is to project the complex poles onto the unit circle in the direct form ; -lrb- 3 -rrb- the second step is to project the complex poles onto the unit circle in the direct form ; and -lrb- 3 -rrb- the third step is to project the complex poles into the direct form of the polyphase iir adaptive and the third step is to minimize the local convergence speed in the direct form . the proposed method has the advantage of both local and global convergence properties in the case of adverse e ® ects . the simulation results show that the proposed method has the same global convergence speed as the direct form , but with the same computational complexity as the direct form .
in this paper , we propose a novel method of single sound source localization using csp -lrb- cross-power spectrum phase analysis -rrb- method . single sound source localization is performed using csp -lrb- cross-power spectrum phase analysis -rrb- method . in the csp -lrb- cross-power spectrum phase analysis -rrb- method , each sound source is represented by a weighted sum of two small dier-ent microphone pairs . in the csp -lrb- cross-power spectrum phase analysis -rrb- method , a set of coecients of the two sources are estimated by the csp -lrb- cross-power spectrum phase analysis -rrb- method , and the un-desired cross-correlation between the two sources is estimated by the csp . the experimental results show that the localization accuracy of the proposed method is very close to that of the conventional methods . the proposed method can be applied to microphone -try-based high quality sound capture .
we present a policy search method for learning neural network policies in time-varying linear dynamics models . our policy search method is based on learning the trajectory distributions of local linear models , which are learned by model-based techniques . policies are learned by guided policy search method , which is a global model of the dynamics of the local linear models . the learned policies are then used to learn the trajectory distributions of the local linear models . the policy search method is applied to simulated robotic manipulation tasks , where the goal is to find the optimal policy for a given task . our policy search method does not require an arbitrary parameterization , and can handle nonsmooth dynamics , such as contact discontinuities or underactuation . we show that our policy search method is able to learn neural network policies in a variety of scenarios .
hidden markov models -lrb- hidden markov models -rrb- have been shown to be effective for classification in naturalistic mul-tiparty dialogue . in this paper , we propose a novel approach to combine hidden markov models with late fusion approaches . in contrast to the classical hmm class , where each processing unit is assigned to a decision class , the conditioned hmm is replaced by a set of label model likelihoods . in contrast to the classical hmm class , the proposed approach does not require any prior knowledge of the underlying distribution of the observations , and thus can be used as a processing unit in the hidden markov models to improve the classification performance . we evaluate the proposed approach on several benchmark datasets and show that it outperforms the classical hmm in terms of classification performance .
spatio-temporal interest point detectors -lrb- spatio-temporal interest point detectors -rrb- are widely used in action recognition and action recognition . in this paper , we propose a novel method to extract spatio-temporal interest points from user-defined scales . the proposed method is based on scale-space theory , which allows us to compute the integral video structure of the spatio-temporal interest points by exploiting the integral video structure of the interest point detectors . the features are computed by hessian , which is used to compute the relative importance of the interest points . the proposed method has been tested on several challenging datasets , and it is shown that the proposed method outperforms the state-of-the-art methods in terms of accuracy and speed . moreover , it is also shown that the proposed method can be used to compute the relative importance of a saliency measure in terms of speed and accuracy .
in this paper , we present an analytical framework for the mirror design of general linear cameras . the proposed analytical framework is based on the assumption that the images of arbitrary surfaces can be represented by a finite number of perspective and multiperspective camera types . the proposed analytical framework can be applied to any general class of imaging models , including arbitrary surfaces , multiper-spective camera models , and caustic surfaces of reflections . the proposed analytical framework can handle both perspective and multiperspective camera types , as well as irregular mirror surfaces . the proposed analytical framework can handle both perspective and multiperspective camera types , and can handle any type of image distortions . the proposed analytical framework can be applied to any general class of catadioptric imaging systems . we demonstrate the effectiveness of the proposed analytical framework by comparing the performance of the mirror design with that of existing imaging models .
in this paper , we present a realtime software mpeg <s> in which the motion vector reuse and simd optimization techniques are combined to reduce the quality degradation . the proposed realtime software mpeg <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> this paper presents a novel reuse technique to reduce the scaled motion vectors and to reduce the quality degradation caused by the motion vector reuse and simd optimization techniques . the evaluation results show that the proposed realtime software mpeg <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> this realtime software mpeg <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> this realtime software mpeg <s> <s> <s> this realtime software mpeg transcoder um ii 266mhz .
in this paper , we present a method for predicting the next speaking start timing of a multi-party meetings . the proposed method is based on a prediction model that uses gaze transition patterns to predict start timing in multi-party meetings . the prediction model is trained using features extracted from the gaze transition patterns of the multi-party meetings . the experimental results show that the proposed prediction model can accurately predict the next speaking start timing in multi-party meetings . furthermore , the proposed method can be used as an agent system in a conversational interface .
sketch-based facial photo hallucination is a popular face hallucination scenario for facial sketch synthesis . in this paper , we propose a novel statistical inference approach , called statistical inference approach , for facial sketch synthesis . in the proposed statistical inference approach , a patch-based tensor model is adopted to model the relationship between photo images and the sketch patch space in the photo patch space and the sketch patch space in the common variation space . in the proposed statistical inference approach , the image appearance is modeled by cooperative factors such as image content and image style , and the relationship between photo images is captured by the tensor model . in the proposed statistical inference approach , the style transformation is learned by the proposed statistical inference approach by modeling the relationship between photo images and the sketch patch space in the common variation space . moreover , the statistical inference approach is formulated as a bayesian approach to perform statistical inference in the common variation space . experimental results on sketch images of human faces demonstrate the effectiveness of the proposed statistical inference approach .
adaptive feedback cancellation -lrb- adaptive feedback cancellation algorithms -rrb- algorithms have been widely used in hearing aids . in this paper , we present a sub-band feedback cancellation system where the goal is to reduce the distortion artifacts caused by tonal signals . in order to reduce the computational complexity of general adaptive filter algorithms , we propose a setup for feedback cancellation in hearing aids . the control concepts for variable step sizes are derived , and the control concepts for variable step sizes are derived . the experimental results show that the proposed sub-band feedback cancellation system can reduce the distortion artifacts due to the bias such as frequency shifting , prediction error filtering , etc. . moreover , the proposed sub-band feedback cancellation system can reduce the computational complexity of the adaptation control .
boltzmann machine -lrb- boltzmann machines -rrb- is a popular tool for training data completion . in this paper , we present a framework for learning generative models with statistical properties . our approach is based on minimizing the wasserstein distance between the model parameters and the model parameters . we show that it is possible to learn the gradient of the kullback-leibler divergence between the model and the true generative models . we demonstrate the effectiveness of our approach on denoising and denoising .
transfer learning has been shown to be effective for opinion analysis . however , it is still a challenging task due to the high dimensionality of language resources and noises . in this paper , we propose a novel approach to address this problem by using transductive transfer learning . specifically , we propose to use cumulative class noise in transfer learning to improve the performance of transfer learning for opinion analysis . the proposed approach is evaluated on the nlp&cc 2013 cross-lingual opinion analysis dataset . the experimental results show that the proposed approach achieves a monotonic increase in the detection of negative transfers .
in this paper , we consider adaptive channel predictors for orthogonal frequency division multiplexing communications over time-varying channels . adaptive channel pre-dictors are proposed for delay-free equalization . the proposed adaptive channel pre-dictors are based on the normalized least-mean-square and recursive least-squares algorithms . simulation results show that the proposed adaptive channel predictors outperform the normalized least-mean-square in the presence of time-varying channels .
in recent years , automated social media analytics and psychometric survey have become increasingly popular for studying character traits , such as personality , personal values , etc. . however , these automated social media analytics do not provide ground truth character traits . in this paper , we propose a novel approach to brand preference prediction in social media , which is based on indi-vidual 's personal traits and his/her brand preferences . specifically , we use automated social media analytics to extract character traits from social media , which are then used for brand preference prediction to predict personal traits . we evaluate our approach on three datasets and show that our approach significantly outperforms existing methods .
we present a generative bayesian model for action understanding that allows us to acquire computational resources for internal models . the generative bayesian model is based on a coupled sequential monte carlo method that learns an approximate inference mechanism from the observed data . the proposed generative bayesian model is motivated by the observation that the inverse-forward internal model pairs constitute ` hypotheses ' and can be used for both perceptual prediction and action understanding . the proposed generative bayesian model can be applied to a wide range of real-world scenarios , including motor simulation , where the goal is to predict the action of an action from the observed data . in addition , the generative bayesian model can be used for action understanding , where the prediction error of an action depends on the number of ` hypotheses ' , and the reenactment of internal model pairs . we demonstrate the effectiveness of the generative bayesian model by comparing generative bayesian model to several state-of-the-art models on several real-world scenarios .
in this paper , we propose a multi-view discriminant transfer learning approach from a discriminant analysis perspective . the key idea of our multi-view discriminant transfer learning approach is to treat the learning problem as a single-or cross-domain , where each view is represented by a set of discriminant weight vectors , and each view is represented by a set of within-view and/or between-view conflicts . the proposed multi-view discriminant transfer learning approach has two main advantages : -lrb- 1 -rrb- multi-view discriminant transfer learning approach is capable of learning a set of discriminant weight vectors from two-view projected data ; -lrb- 2 -rrb- multi-view discriminant transfer learning approach does not require any knowledge of the source and target domains ; -lrb- 3 -rrb- multi-view discriminant transfer learning approach can handle view-based problems from a single discriminant analysis perspective . -lrb- 3 -rrb- multi-view discriminant transfer learning approach can deal with both domain discrepancy and view disagreement ; -lrb- 3 -rrb- multi-view discriminant transfer learning approach can deal with both multi-view learning approaches . experimental results show that our multi-view discriminant transfer learning approach is effective in domain adaptation , especially when the number of views is small and the number of views is small .
in this paper , we consider the problem of shape reconstruction from noisy and unorganized point data . the shape reconstruction is formulated as a constrained energy minimization problem on the observed point set . the shape reconstruction is formulated as a signed distance function with respect to a level set formalism . the reconstruction is formulated as a constrained energy minimization problem with respect to the observed point set . the optimization problem is solved using a data-driven level set method . the proposed data-driven level set method is robust to noise , clutter , and local minima , and can deal with noisy and unorganized point data . the proposed data-driven level set method does not require any smoothness prior on the reconstructed shape . the experimental results show that the proposed data-driven level set method is robust to noise and clutter .
the hurricane challenge is a speech-in-noise intelligibility enhancement evaluation . in this paper , we investigate the effect of loudness and duration modification on the intelligibility of unmodified synthetic speech in noise . in order to improve the intelligibility of hmm-based synthetic speech , two enhancement strategies are proposed : the compressor , the spectral shaper and the glimpse proportion measure for the text-to-speech voice , and the spectral shaper . in the first approach , we use the duration and excitation lombard-adapted changes to improve the intelligibility of the unmodified synthetic speech . in the second approach , we use the lombard excitation and duration patterns to enhance the intelligibility of the synthetic speech . in the second approach , we combine the duration and excitation lombard-adapted changes in the text-to-speech voice by using the glimpse proportion measure and dynamic range compression . the experimental results show that the proposed approach significantly improves the intelligibility of the unmodified synthetic speech in various snr conditions .
we consider the problem of motion estimation from tagged magnetic resonance images . ordinal measures are based on the relative ordering of intensity values in the image region . the relative ordering of intensity values in the image region is measured by rank permutation , and the linear-ity between corresponding intensity values is measured by rank permutation . the proposed method is tested on a real heart image sequence using a rotating ring phantom image sequence . the results show that the proposed method is able to capture temporal monotonicity in the image region . it is also shown that the proposed method can be applied to any imaging equation for tagging .
planning technology has become increasingly popular in the automated planning community . however , due to the lack of richer models , the automated planning community has not been fully explored . in this paper , we propose a modeland a modeland planning technology that allows us to reduce the domain-modeling burden by making use of richer models of the domain model . we show that our model, combined with a domain theory , improves the quality of the planning technology . we also show that our model, combined with a domain model , significantly improves the quality of the planning technology .
in this paper , we consider the problem of detecting overlapping rfid -lrb- rfid -rrb- signals with zero constant modulus signals received by an antenna array . we propose two blind source separation techniques based on the slotted aloha and binary tree algorithms . the first blind source separation techniques is based on the observation that the identity of tagged objects can be detected by radio frequency identi ¿ cation . the second blind source separation techniques is based on the observation that the zero constant modulus signals can be separated by a small number of tag replies . the third blind source separation techniques is based on the observation that the interference of the array is independent of the number of tag replies . the third blind source separation techniques is based on the idea of collision avoidance using mac protocols . the experimental results on both synthetic and measured data sets demonstrate the effectiveness of the proposed zcm algorithms .
in this paper , we propose a joint optimal power allocation for mimo systems with link reliability -lrb- pa -rrb- . the proposed joint optimal power allocation is formulated as an optimization criterion to minimize the error probability . the proposed joint optimal power allocation is formulated as a convex problem and is solved using convex optimization methods . the proposed joint optimal power allocation is compared with the pa scheme in terms of both the power parameters and the power parameters . simulation results show that the proposed joint optimal power allocation outperforms the existing methods in terms of the error probability .
we present generalization bounds for learning kernels based on a convex combination of p base kernels . we show that the rademacher complexity of the learning kernels is bounded by a non-negative combination of p base kernels with l 2 regularization . we provide a combinatorial analysis of the generalization error of the learning kernels , and show that the generalization error of the learning kernels can be bounded by the non-negative combination of p base kernels with l 2 regularization .
we present empirical distributional methods for modelling compositional meaning . our empirical distributional methods are motivated by empirical distributional methods for modelling compositional meaning . our empirical distributional methods are based on the idea that relational words can be represented by unsupervised learning of matrices . we evaluate the performance of bnc on a word disambiguation task , and find that bnc is an abstract categorical model of syntactic complexity . we find that bnc is able to model intransitive sentences , and that bnc is able to model the meaning of sentences with high accuracy . we also show that the syntactic complexity of bnc can be reduced by a factor of three .
in forensic applications , the automatic synchronization of audio and video is an important issue in multimedia recordings . in this paper , we propose a method for detecting forgery of enf-containing mul-timedia signals in multimedia recordings . the proposed method is based on multi-view video synchronization , where the electric network frequency signal is modeled as a time-varying random process , and the electromagnetic influences of the electric network frequency signal are modeled as a power grid . the proposed method is based on detecting forgery of enf-containing mul-timedia signals in the power grid . the experimental results show that the proposed method is effective for multi-view video synchronization .
scribbles are an important part of mobile touch-screen devices . in this paper , we propose a novel scrible-based interactive segmentation called graph-cut . scribbles are detected as foreground scribble pixels in the image , and the foreground scribble pixels are detected as foreground scribble pixels in the image . the scribbles are detected by minimizing the ratio energy function of the graph-cut energy with respect to user input information . the robustness of the ratio energy function is measured by the iterated graph cut algorithm . the proposed ratio energy function is evaluated on synthetic scribbles and manual scribbles on the grabcut dataset . the experimental results show that the proposed ratio energy function achieves better segmentation results than the state-of-the-art methods . moreover , the proposed ratio energy function can be used to improve the graph-cut energy .
this paper addresses the problem of mapping audible speech to audible speech using statistical mapping techniques based on a continuous speech database . a unit selection approach to speech sound is presented . the mapping is based on the joint modeling of visual and spectral features of the tongue and lip motions in video sequences . the visual articulatory data is used to estimate a voiced/unvoiced parameter , which is then used as input to an artificial neural network . hidden markov models and gaussian mixture models are used to model the mapping between the tongue and lip motions . the experimental results show that the proposed unit selection approach is able to recover speech sound from a continuous speech database .
this paper describes a simulated tutorial system for deep syntactic and semantic analysis in the context of telegraphic natural language . the simulated tutorial system has been designed to deal with language phenomena in formal domains such as mathematics and synthesis . the simulated tutorial system has been tested on a corpus of dialogs , and the simulated tutorial system has been shown to be robust to language phenomena in the discourse verbaliza-tion . the simulated tutorial system has been successfully applied to a corpus of dialogs , and the simulated tutorial system has proven to be robust to language phenomena .
in this paper , we propose a talker 's head orientation estimation method based on talker localization and head orientation estimation using a network of microphone arrays . the talker 's head orientation is represented by csp -lrb- cross-power spectrum phase -rrb- coefficients , which represent the talker 's position , the head orientation , and the talker 's position . in the proposed talker 's head orientation estimation method , the talker 's head orientation is represented by the csp -lrb- cross-power spectrum phase -rrb- coefficients . in the proposed talker 's head orientation estimation method , the feature vectors of the csp coefficients of the cross-power spectrum phase -lrb- cross-power spectrum phase -rrb- coefficients are used to estimate the talker 's head orientation . the experimental results show that the proposed talker 's head orientation estimation method can accurately estimate the talker 's position from 2-channel microphones without reverberation , and the proposed talker 's head orientation estimation method can estimate the talker 's head orientation from the microphone array sub-microphone arrays . the experimental results show that the proposed talker 's head orientation estimation method can accurately estimate the talker 's position from the 2-channel microphones .
in this paper , we propose a novel discriminative subspaces building approach called the linear fukunaga-koonmann transform . the linear fukunaga-koonmann transform is a small-sample-size , which can be easily applied to a wide range of domain specific problems . in addition , the discrimination ability of the linear fukunaga-koonmann transform is demonstrated by extensive experiments on several face recognition applications . the experimental results show that the kernel fukunaga-koontz transform is very effective in enhancing the performance of enhanced face recognition .
concept correlation representation plays an important role in video annotation refinement . in this paper , we propose a novel data-specific concept correlation estimation procedure , called data-specific concept correlation estimation procedure , which integrates concept correlation basis estimation and data-specific concept correlation calculation . the data-specific concept correlation estimation procedure consists of two steps : 1 -rrb- data-specific concept correlation calculation and 2 -rrb- concept correlation basis estimation . in the data-specific concept correlation estimation procedure , the generic concept correlation is defined to characterize the visual and high-level characteristics of the data-specific characteristics of the data-specific characteristics . in the data-specific concept correlation estimation procedure , the concept distribution is defined by the high-level concept correlation bases , and the sparse representation is obtained by the proposed high-level concept correlation bases . the experimental results on the trecvid 2006 dataset demonstrate the effectiveness of the proposed data-specific concept correlation estimation procedure .
in this paper , we propose a fast trust region approach for the optimization of segmentation energies in non-linear regional terms . the proposed fast trust region approach is based on the minimization of the kl divergence between the target appearance distributions and the segment size subject to a volume constraint on the shape prior constraint . the proposed fast trust region approach is a non-linear -lrb- more accurate -rrb- approximation model with a constrained optimization algorithm . the proposed fast trust region approach has two main advantages : -lrb- 1 -rrb- fast trust region approach provides a global optimum for the optimization of segmentation energies in non-linear regional terms ; -lrb- 2 -rrb- fast trust region approach does not require any shape prior constraint on the training data ; -lrb- 3 -rrb- fast trust region approach can handle complex nonlinear approximation models ; -lrb- 3 -rrb- fast trust region approach does not require any training data ; -lrb- 3 -rrb- fast trust region approach does not require any training data ; and -lrb- 3 -rrb- fast trust region approach does not require any training data ; and -lrb- 3 -rrb- iterative approach can be used with any approximation model . experimental results show that the proposed iterative approach outperforms state-of-the-art gradient descent techniques .
we propose a new similarity measure for electrophysiological neural time series . the coupling between two random variables is modeled as a function of the similarity measure between two coupled time series . the coupling is modeled as a product of a set of positive definite kernels , which are used to define the kernel and to define the similarity between two coupled time series . the proposed similarity measure is based on the notion of a independence test between two coupled time series . the proposed similarity measure allows us to detect the coupling between two coupled time series . we apply the proposed similarity measure to two challenging dynamical systems : -lrb- 1 -rrb- the stationary time-series of arbitrary objects in arbitrary input domains , and -lrb- 2 -rrb- the hsic test is robust to detection errors . we demonstrate the effectiveness of the proposed similarity measure by comparing its performance to the state-of-the-art methods on two datasets .
in this paper , we present a broad-coverage and a dash of sentiment beneath , which integrates prior knowledge about semantic prosody , semantic parallelism of coordination , distri-butional similarity , and semantic prosody . we describe the induction algorithms and the associated induction algorithms , and present the results of an empirical evaluation of the broad-coverage , connotative sentiments of words in the surface meaning of a word . we also show that the broad-coverage and lexicon of a word can be automatically acquired from lexical resources .
in this paper , we propose a mixture probabilistic matrix approximation method for collaborative filtering matrix approximation . in our mixture probabilistic matrix approximation method , the user/item latent factors are represented by a user-item rating matrix , and the user/item ratings are represented by locally optimized user/item feature vectors . the user/item latent factors are represented by ma methods , and the user/item latent factors are represented by a gaus-sian mixture model . the user/item latent factors are represented by a mixture of ma methods with local predictions and global predictions . the proposed mixture probabilistic matrix approximation method is evaluated on movielens and netflix datasets , and compared with the state-of-the-art ma based cf methods in terms of recommendation accuracy . the experimental results show that the proposed mixture probabilistic matrix approximation method can significantly improve the recommendation accuracy when the number of user/item ratings is small .
in this paper , we propose a novel sequential spectral learning approach for multi-view hashing . given a set of images , we learn a hash function by learning a set of hash functions from a set of images . the key idea of our sequential spectral learning approach is to learn a set of binary codes from a set of visual descriptors -lrb- e.g. , gist , sift , gist , etc. -rrb- , each of which is represented by a set of binary codes -lrb- e.g. , sift , gist , etc. -rrb- . to this end , we propose a novel approximate k-nn graph construction method to learn a set of α-averaged distances between two sets of α-averaged distances between two sets of multi-view local variances , which can be efficiently computed by recursive spectral learning approach . the α-averaged distances are learned by minimizing the averaged distance matrix , which can be efficiently computed by minimizing the decorrelation constraints . the proposed sequential spectral learning approach is evaluated on two nus-wide datasets , and compared with several state-of-the-art multi-view hashing methods and single-view spectral hashing . the experimental results show that our sequential spectral learning approach significantly outperforms the state-of-the-art methods .
in this paper , we propose a novel method for decomposing a class-specific image set into a set of pixel-wise similarities . each image is represented by a set of similarity templates , and a set of similarity templates is learned for each image . these similarity templates are then used to define a set of similarity templates for each object class . we demonstrate the effectiveness of our method on a variety of pedestrian images and show that our method outperforms the state-of-the-art methods in terms of clustering , and we also show that our method can be applied to other tasks such as clustering and we can also be applied to the problem of learning a class-specific image set .
in many multi-label classification problems , the classifier chain is defined by a random label order . in this paper , we propose a generalization error for the deterministic high-order markov chain model , which is based on the greedy classifier chain algorithm . we prove that the proposed cc-dp algorithm converges to the globally optimal label order . moreover , we prove that the generalization error of the cc-dp algorithm is lower than that of the cc-dp algorithm in terms of both the number of labels and the number of labels . experiments on real-world multi-label data sets show that the proposed cc-dp algorithm achieves better performance than the cc-dp algorithm in terms of both the number of labels and the number of labels .
in this paper , we propose a novel clustering task called <i> self-taught clustering </i> , which is motivated by applications in image clustering . the goal is to learn a feature representation from both target and auxiliary data , and to cluster the data with irrelevant unlabeled auxiliary data . the proposed clustering task consists of two steps : <i> unsupervised transfer learning </i> -lrb- <i> auxiliary </i> -rrb- and <i> unsupervised transfer learning </i> -lrb- <i> auxiliary </i> -rrb- . first , <i> auxiliary </i> unlabeled auxiliary data are extracted from the auxiliary data , and <i> unsupervised transfer learning </i> is performed on the auxiliary data . second , <i> auxiliary </i> unlabeled auxiliary data is used to learn a feature representation from the auxiliary data . third , we propose a co-clustering based self-taught clustering algorithm to cluster the data with the topic distribution . experimental results show that the proposed co-clustering based self-taught clustering algorithm outperforms the state-of-the-art clustering methods .
in this paper , we present a machine learning approach to automatic evaluation of machine translation system . the machine learning approach is based on the assumption that human reference translations can be used to evaluate machine translations . the machine learning approach is based on the assumption that the human reference translations are generated by a set of classifiers . we present a failure analysis of the machine learning approach and show that the machine learning approach can be used to evaluate the performance of a machine translation system .
listening room equalization -lrb- lre -rrb- is an important component of massive multichannel reproduction systems , such as wave field synthesis . in this paper , we propose a novel approach to listening room equalization that allows listening room equalization to be used in adap-tive filtering tasks . the proposed approach is based on the use of adaptive lre in reproduction scenarios , where the listener positions are determined by computational and algorithmic reasons . adaptive lre is used in order to improve the robustness of the filtering structures in reproduction channels . the proposed approach is evaluated by comparing the performance of the proposed approach with that of the conventional adaptive lre in reproduction scenarios . the results show that the proposed approach is effective in reducing the number of reproduction channels while maintaining the robustness of the adaptive lre .
submodularity is widely used in signal processing , computer vision , and signal processing . in this paper , we consider the discrete submodular minimization problem , where the objective is to minimize a sum of submodular functions subject to a de-composability of submodular functions . we show that the discrete submodular minimization problem can be formulated as a continuous best approximation problem , and present efficient optimization procedures for the minimization problems . we show that the proposed optimization procedures can be applied to a wide range of problems , including inference , reconstruction , learning , learning , and parameter tuning . we demonstrate the effectiveness of the proposed optimization procedures on a variety of image segmentation tasks .
in this paper , we propose a bandwidth-extension algorithm for speaker verification . in the proposed bandwidth-extension algorithm , a short-time spectral parameterization of the mel-frequency cepstral coefficients is applied to narrow-band speech . the short-time spectral parameterization is performed on the basis of both microphone and isdn speech databases . the proposed bandwidth-extension algorithm is evaluated in terms of the detection error trade-off curves and covariance matrix based verification systems . the results show that the proposed bandwidth-extension algorithm is effective in reducing the model order and improves the verification system performance for narrow-band speech .
speech separation based on time-frequency masking has been shown to improve the intelligibility of speech signals . in this paper , we propose a novel method to improve the perceptual quality of separated speech by incorporating time-frequency masking into speech separation . in the proposed method , a sparse-representation approach is used to decompose the separated signal into a clean speech dictionary and the short-time fourier transform magnitudes of the separated speech signal . in the proposed method , the separated speech is first converted into a clean speech dictionary , and then the speech signal is transformed into a clean speech dictionary . in the proposed method , the separated speech is separated using the proposed method , and the speech quality measure is calculated based on the perceptual evaluation of speech quality . experimental results show that the proposed method outperforms the conventional binary-masked noisy speech and other reconstruction approaches in terms of speech quality . moreover , the proposed method is able to improve the perceptual quality of separated speech when compared to the conventional methods .
in this paper , we present ims , a supervised english all-words wsd system . ims uses supervised learning to improve the performance of word sense disambiguation systems on sense-val and semeval workshops . ims includes three preprocessing tools : -lrb- 1 -rrb- a classifier based on knowledge-based features ; -lrb- 2 -rrb- a classifier based on linear support vector machines ; -lrb- 3 -rrb- a classifier based on knowledge-based features ; -lrb- 3 -rrb- a combination of features and classifiers ; and -lrb- 3 -rrb- a combination of these techniques . ims achieves state-of-the-art performance on both sense-val and semeval tasks .
in this paper , we consider the problem of learning similarity measures for shape classification . in particular , we focus on the problem of learning a classifier from point correspondences . we propose a max-margin formulation for the structured prediction setting , which allows us to learn shape similarity scores directly from the training data . the proposed max-margin formulation allows us to learn a classifier that is robust to the choice of a classification loss . we demonstrate the effectiveness of the proposed max-margin formulation on several shape databases , and show that the proposed max-margin formulation outperforms state-of-the-art methods .
distributed principal component analysis -lrb- distributed principal component analysis -rrb- is a powerful tool for analyzing and analyzing real-world computer networks . in this paper , we consider the problem of distributed principal component analysis in networks with directed gaussian graphical models . we propose a novel framework for online principal subspace estimation in networks with directed gaussian graphical models . we show that the cholesky factor can be interpreted as structured sparsity of the inverse covariance matrix , which can be efficiently estimated via message passing and local computation . we demonstrate the effectiveness of the proposed framework for distributed anomaly detection in real-world computer networks .
in this paper , we present a method for spelling correction in vietnamese texts , one aspect of computational linguistics . the method is based on a spelling database derived from telex code . the spelling database can be used for spelling correction in vietnamese language processing . the experimental results show the effectiveness of the proposed method .
in this paper , we consider the wyner-ziv coding problem in which correlated side-information are used at the decoder . the wyner-ziv coding problem is based on the assumption that the source and channel coding are independent of the source and channel . we propose a general encoding model for the wyner-ziv coding problem in which the encoding parameters are independent of the source and channel coding . the proposed general encoding model is based on the assumption that the source and channel are independent of the source and channel , and the transform coefficients are assumed to be independent of the source and channel . the proposed general encoding model can be considered as a special case of the quantizer family , where the side-information are independent of the source and channel . the proposed general encoding model can be considered as a special case of a regular codec , where the encoding parameters are independent of the source and channel coding . simulation results show that the proposed general encoding model can achieve better rate-distortion trade-offs than the regular codec .
most personalized tag recommendation systems rely on a gaus-sian radial basis function , which makes personalized tag recommendation systems very challenging . in this paper , we propose a novel approach to personal-ized tag recommendation based on the tucker decomposition , which is a nonlinear extension of canonical decomposition in linear time . the proposed method is based on linear tensor factorization and tensor factorization techniques , which can be easily applied for online recommendation . moreover , the proposed method can be easily applied to various real datasets . the experimental results show that the proposed method can achieve better performance than the state-of-the-art methods in terms of computation power .
in this paper , we propose a single-image highlight removal method to remove illumination-based constraints in image in-painting for recovery of shading and textures . the proposed single-image highlight removal method is based on the observation that highlight pixels in the occluded image regions tend to have similar color values . in addition , the proposed single-image highlight removal method does not require any knowledge of pixel colors , highlight color analysis , and illumination color uniformity . in addition , the proposed single-image highlight removal method does not require the estimation of the underlying diffuse color . the proposed single-image highlight removal method does not require any illumination constraints for the recovery of shading and textures . the experimental results show that the proposed single-image highlight removal method can effectively remove the occluded image regions .
in this paper , we propose an adaptive lighting correction method based on the poisson equation with incomplete boundary conditions . the proposed adaptive lighting correction method is based on the poisson equation with incomplete boundary conditions . the proposed adaptive lighting correction method can be applied to a wide range of natural images . the proposed adaptive lighting correction method is based on the idea of adaptive poisson lighting correction , which is an extension of the side-matching algorithm and the structural texture similarity metric . the proposed adaptive lighting correction method can be applied to a wide range of textures in natural images . the experimental results show that the proposed adaptive lighting correction method can improve the quality of the encoded blocks , especially for structurally lossless compression .
in this paper , we propose an ensemble framework for probability density estimation in hidden markov model with insufficient training data . the proposed ensemble framework consists of a gradient descent search in the function space and a learning algorithm for the gaussian mixture densities . the state emission densities are estimated by minimizing the sum of free parameters of a hidden markov model and a boosting baum-welch algorithm . in the proposed ensemble framework , the mean and variance of the gaussian mixture state emission densities are estimated using the baum-welch algorithm . the proposed ensemble framework is applied to the problem of emotion recognition . the experimental results show that the proposed ensemble framework is effective in reducing the number of free parameters required for training the gaussian mixture densities .
robust estimation of non-rigid deformations from feature correspondences is a challenging problem due to the large number of physical deformations . in this paper , we propose a ransacand deformable registration technique based on optimisation of fully deformable models . the optimisation of fully deformable models is based on the assumption that the manifold is represented by a low-dimensional hy-perplane . we derive error bounds for the solution of the robust estimation of non-rigid deformations and show that the error bounds of the robust estimation of non-rigid deformations can be improved by the use of a low-dimensional hy-perplane for accurate outlier rejection . experiments on both synthetic and real data demonstrate the effectiveness of the proposed ransacand deformable registration technique .
in this paper , we propose a novel video based talking face verification using joint factor analysis and gaussian mixture models for video based talking face verification . in the proposed video based talking face verification , the gmm mean shifted supervector is represented by an over-complete dictionary , and the gmm mean shifted supervector is learned by l 1-minimization with quadratic constraints . in the proposed video based talking face verification , a maximum a posteriori adapted model is employed to estimate the gmm mean shifted su-pervectors of the universal background model . in the proposed video based talking face verification , the gmm mean shifted supervector is learned by the joint factor analysis and the sparse representation is obtained by the l 1-minimization with the quadratic constraints . the experimental results on the banca talking face video database with p protocol show that the proposed approach can achieve a relative error reduction of about 30 % compared to the gmm-ztnorm baseline system , while maintaining the robustness and complexity of the gmm-ztnorm baseline system .
we consider the problem of stochastic learning problems where the objective is to recover a low-dimensional manifold from its intrinsic dimension . existing iterative methods rely on approximate subgradient directions , which can not handle large or streaming data sets . in this paper , we propose a novel algorith-mic strategy to learn a manifold from a near-optimal manifold . our algorith-mic strategy is based on a regularized dual averaging algorithm , where the loss function is a nonsmooth regularization term , and the loss function is a near-optimal point in the full space . we show that the proposed algorith-mic strategy is able to recover the manifold with a near-optimal manifold , even when the intrinsic dimension of the manifold is not known . we demonstrate the effectiveness of our algorith-mic strategy on a variety of challenging stochastic learning problems .
in this paper , we present a novel approach to the decoding of user utterances in a spoken dialog system . the proposed approach is based on statistical language understanding models trained on a corpus of unaligned pairs of sentences . the statistical language understanding models are trained on a corpus of unaligned pairs of sentences and their semantic units are used as the understanding component . the statistical language understanding models are trained on a corpus of unaligned pairs of sentences , and the semantic representation of the sentences is used as the input to the spoken dialog system . the experimental results show that the proposed approach is able to improve the performance of the conventional corpus-based approaches . furthermore , the proposed approach can be applied to any spoken dialog system in the context of <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> the spoken dialog system in spanish , where variable-length word segments are used as the understanding component .
in this paper , we propose a novel joint sparse representation model to improve the tracking performance of robust feature-level fusion in a video sequence . the proposed joint sparse representation model is composed of three steps : -lrb- 1 -rrb- robust feature-level fusion , which is based on the joint sparse representation model , and -lrb- 2 -rrb- robust feature-level fusion based on the sparse representation . -lrb- 3 -rrb- robust feature-level fusion , which is based on the joint sparse representation model , is robust to pose , occlusion , and illumination . -lrb- 3 -rrb- the proposed joint sparse representation model is robust to unreliable features , and -lrb- 3 -rrb- the proposed joint sparse representation model is robust to pose and occlusion . the experimental results show that the proposed joint sparse representation model outperforms the state-of-the-art algorithms on the challenging benchmark datasets .
in this paper , we address the problem of super-resolution person re-identification , where the probe images are taken under different identification scenarios . in particular , we propose a multi-view sld2l approach to learn a type-specific dictionary pair for each probe image , which can be used to extract the hr features from both the hr and lr training images . in the proposed multi-view sld2l approach , the mapping matrices of the hr and lr images are jointly learned by minimizing the similarity between the transformed features and the corresponding visual appearance features . in the proposed multi-view sld2l approach , a discriminant term and a low-rank regularization term are introduced to learn the mapping matrices between the hr and lr training images . in the proposed multi-view sld2l approach , the extracted features are used to learn the type-specific dictionary pair for each feature , which is further used to learn the mapping matrices of the hr and lr images respectively . the experimental results on publicly available datasets show that the proposed multi-view sld2l approach significantly outperforms the state-of-the-art methods in the low-resolution sr person re-identification task .
this paper describes the development of a malay emotional synthesizer based on prosody templates and prosody parametric manipulation for synthesizing emotion from text input . the malay emotional synthesizer is based on prosody templates and prosody parametric manipulation for sentence structure . the prosody manipulation principle is used to generate intonation patterns from text input . the results show that the prosody manipulation principle is robust to anger , sadness , and sadness .
articulatory feature models have been widely used in the automatic speech recognition community to model phone-based models of speech . in this paper , we propose a feature-based model for visual speech recognition , which is based on modeling inter-feature asynchrony between the visual modality and the pronunciation of a speaker . the feature-based model is trained on a set of carefully designed features , each of which is represented by a dynamic bayes-ian network . the proposed feature-based model is based on a combination of both feature-based and <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> in conjunction with svm feature classifiers . experiments on the isolated-word vsr task show that the proposed feature-based model can achieve better performance than the baseline system .
we present paraquery , a paraquery for learning a pivoted paraphrase collection from bilingual parallel corpora . the paraquery is designed to capture the characteristics of paraphrases that are relevant to the task of paraphrase acquisition , and can be used for a variety of nlp applications . the paraquery is designed to be able to exploit lexical similarity resources , and can be used as a basis for a wide range of nlp applications . we demonstrate the effectiveness of paraquery by applying paraquery to the task of paraphrase acquisition .
in this paper , we propose a new post-filtering structure for the dual frame of oversampled filter banks . the proposed post-filtering structure is based on the idea that the dual frame can be decomposed into two parts : 1 -rrb- the transform coefficients can be decomposed into two parts , and 2 -rrb- the dual frame can be decomposed into two parts : -lrb- 1 -rrb- the inverse of the transform coefficients can be decomposed into two parts , and -lrb- 2 -rrb- the inverse of the greand the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the transform coefficients , and -lrb- 3 -rrb- the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the residual of the residual of the residual of the residual of the subband . in the case of robust transmission , the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the inverse of the
many visual recognition tasks , such as covariance descriptors , can be expressed as vectors of locally aggregated descriptors . in this paper , we consider the problem of learning nonlinear vlad descriptors in the euclidean space . in particular , we propose a kernelized version of the vlad framework , which allows us to approximate linear classifiers in a vector form . in particular , we introduce approximate formulations for the coding process , which allow us to approximate the nonlinear vlad descriptors in the euclidean space . in particular , we show that the covariance descriptors can be expressed as tensors , and that these approximate formulations can be used to approximate the linear classifiers in a vector form . in particular , we show that the proposed method can be used to approximate non-vector descriptors in a wide range of visual recognition tasks . we also show that the proposed method can be used to learn linear descriptors in a variety of scenarios .
we consider the problem of landmark selection for nyström landmarks using discrete probability models . we propose a novel nyström method for kernel methods , which is based on markov chain dpp sampling . our nyström method has cubic complexity in the number of samples , and can handle large datasets with millions of samples . our nyström method is inspired by the markov chain dpp sampling , which has cubic complexity in the number of samples , and can be used for dpp-based landmark selection . our theoretical analysis shows that the proposed nyström method has cubic complexity in the number of samples , and can be used for kernel methods . we apply our nyström method to the problem of landmark selection for nyström landmarks , and show that the proposed nyström method can be used for kernel methods . our theoretical analysis shows that the proposed nyström method is much faster than the state of the art in dpp sampling , especially when the approximation errors are small .
we consider the problem of deriving contingency plans in markov decision processes and contingency planning . we present an anytime algorithm for finding optimal plans in markov decision processes and contingency planning . our anytime algorithm is based on a novel combination of heuristic techniques for contingency planning and markov decision processes . our empirical results show that our anytime algorithm is able to find optimal plans in reasonable time .
web ranking has become an important research topic in the nlp community . in this paper , we propose a novel approach to learn query-url n-gram features from limited user click data . in particular , we focus on the task of web ranking , where the query is represented by a set of query queries and the query is represented by a set of query queries . we propose to use sparsity to identify urls and find exact match click features for unseen words . in addition , we propose to use sparsity to predict urls . experimental results on a web search ranking task show that our proposed query-url n-gram features significantly outperform the state-of-the-art methods .
in this paper , we propose a novel adaptive graph-cut based approach for energy minimization in pre-defined moves spaces . the proposed adaptive graph-cut based approach is based on the idea of local primal-dual gaps in pre-defined moves spaces , which can be used to guide the search for the optimal solution . we show that the proposed adaptive graph-cut based , called adaptive graph-cut based , can be applied to many image labelling problems such as stereo , object segmentation , and stereo . the experimental results show that the proposed adaptive graph-cut based , called adaptive graph-cut based , can effectively reduce the primal-dual gap between the optimal solution and the optimal solution . moreover , we show that the proposed adaptive graph-cut based , called adaptive graph-cut based , can effectively reduce the number of false positives by a factor of three . the experimental results show that the proposed adaptive graph-cut based , called adaptive graph-cut based , can effectively reduce the number of false positives by a factor of three .
in this paper , we propose a new framework for the control of texture segmentation in real images . the proposed framework is based on modular processes , where the feature values of homogeneous regions are automatically extracted from real scene images using manually-specified ground truth . compared to existing unsu-pervised texture segmentation algorithms , the proposed framework has two main advantages : -lrb- 1 -rrb- it does not require ground truth , -lrb- 2 -rrb- it does not require ground truth , and -lrb- 3 -rrb- it does not require ground truth , and -lrb- 3 -rrb- it does not require ground truth , and -lrb- 3 -rrb- it does not require ground truth . the proposed framework is general and can be applied to any variety of segmentation algorithms including gabor multi-channel filtering , laws ' texture energy , gray level co-occurrence matrax , fuzzy c-means clustering , and error clustering . experimental results show that the proposed framework outperforms existing region-based and pixel-based performance met-rics .
in this paper , we propose a new method for denoising and denoising of discrete time filters for signal processing . the proposed method is based on alternating projections of a set of discrete time filters , which are used for regularization in signal processing . the proposed method is based on a convex sets approach , which allows for total variation recovery and de-noising . the proposed method is applied to the fv problem , and it is shown that the proposed method is effective in sparse signal processing applications .
in this paper , we propose a canonicalization process for the hmm and the robust automatic speech recognition system . in the proposed canonicalization process , the acoustic feature vectors of the acoustic feature vectors are treated as hidden variables , i.e. , gender type , speaking rate , and acoustic environment . the proposed canonicalization process is composed of two steps : first , the acoustic feature vectors of the acoustic feature vectors are extracted and then the acoustic feature vectors of the acoustic feature vectors are used to train an hmm-based classifier . second , the acoustic feature vectors of the acoustic feature vectors are extracted from the acoustic models of the acoustic feature vectors of the acoustic feature vectors . the canonicalization process is composed of two steps : first , the acoustic feature is extracted from the acoustic feature extractors , and second , the acoustic feature is extracted from the training data by multilayer neural networks . third , the canonicalization process is applied to the hmm and the robust automatic speech recognition system . the experimental results show that the canonicalization process outperforms the conventional acoustic feature and the robust automatic speech recognition system in terms of computation time .
spectral factorization -lrb- spectral factorization -rrb- is a classical tool for signal processing and communications . spectral factorization is a classical tool for signal processing and communications . in this paper , we consider the problem of recovering a one-dimensional sparse signal from a small number of samples . in particular , we consider the problem of phase retrieval , i.e. , finding a subset of the samples that minimizes the autocorrelation of the signal , i.e. , sign change , time-shift , etc. . we propose an iterative algorithm for finding a subset of the samples that minimizes the total number of samples needed to reconstruct the signal . we demonstrate the performance of the proposed iterative algorithm by numerical simulations .
in this paper , we propose a generative model approach to extract visual features from sport videos such as the camera view . the proposed generative model approach is motivated by the observation that the semantic structure in the semantic space can be represented by latent states , and the variability of visual features can be captured by a two-layer observation model . in order to capture the variability of visual features , a two-layer observation model is proposed to capture the variability of visual features . the proposed generative model approach is compared with generative models such as the hidden markov model and segmental hmm in two video mining tasks . the experimental results on american football games show that the proposed generative model approach can capture the intrinsic semantic structures among different camera views . the proposed generative model approach is also applied to view-based shot classification , where the proposed generative model approach is applied to the video mining tasks .
in this paper , we propose a sequential source localization method using a particle filter in a wireless distributed sensor network . in the proposed sequential source localization method , the positions of the acoustic sensors are modeled as a non-gaussian probability density function -lrb- pdf -rrb- of the acoustic signal and the location estimates are obtained by solving an observation equation . in the proposed sequential source localization method , the multiple-target locations are estimated by minimizing the state transition equation of the maximum likelihood source localization algorithm . in the proposed sequential source localization method , the multiple-target locations are estimated based on the observation equation and the location estimates are obtained by solving the state transition equation . simulation results show that the proposed sequential source localization method can achieve better performance than the conventional methods .
in nonparametric density estimation , a robust kernel density estimator is proposed . the kernel density estimator is based on a positive semi-definite kernel , which is a generalization of the robust kernel density estimator to a reproducing kernel hilbert space . the kernel density estimator is a generalization of the robust kernel density estimator to kernel density estimator , which has a global minimizer of the m-estimator objective function . the robust kernel density estimator is shown to be robust to outliers , and is robust to outliers . the robust kernel density estimator is shown to be a generalization of the robust kernel density estimator to kernelized irwls . the robust kernel density estimator is shown to be robust to outliers , and is shown to be robust to outliers . the robust kernel density estimator is evaluated on several benchmark datasets , including density estimation and anomaly detection . the results show that the proposed robust kernel density estimator outperforms the existing robust kernel density estimator .
in this paper , we present a novel approach to entity ambiguity in el , which is based on the use of a textual named entity mention as a knowledge base entry . our approach is based on the use of a markov logic network for disambiguation formulae/features . the markov logic network allows us to incorporate interfulved constraints into el approaches . we evaluate our approach on two different el approaches , one based on filtering techniques and one based on the other based on the knowledge base entry . our results show that our approach significantly outperforms the state of the art .
mining retrospective events from text streams is a challenging task due to the lack of semantic and temporal information . in this paper , we propose a burst-based text representation model , called the proposed burst-based text representation model , which consists of two steps : -lrb- 1 -rrb- a vector space model to capture the temporal aspects of documents and -lrb- 2 -rrb- a classic text representation model to capture the bursty features of documents . -lrb- 3 -rrb- a vector space model to capture the correlation between words and their non-zero entries is proposed to capture the correlation between words . the experimental results on the 10-year news archive show that the proposed burst-based text representation model outperforms the state-of-the-art methods .
we consider the correspondence problem of finding a minimal two-dimensional surface from a set of 2-vector fields . the correspondence problem is formulated as a convex formulation of the correspondence problem , which can be solved efficiently using geometric measure theory . we show that the globally optimal solution can be obtained by solving a convex minimization problem , which can be solved efficiently using a primal-dual algorithm . we show that the solution can be efficiently solved by exploiting the spatial regularity and data consistency . in particular , we show that the solution can be computed efficiently by solving a convex minimization problem that can be solved efficiently using a few iterations of the energy function . we demonstrate the effectiveness of our approach on a variety of challenging problems .
in this paper , we present a robust natural language understanding system for negotiation subdialogues . negotiation subdialogues consist of three components : a process model , a multi-strength belief model , a process model , and a multi-strength belief model to capture discourse actions , and a multi-strength belief model to capture discourse actions . the robust natural language understanding system is based on communicative actions and uses communicative actions to generate negotiation subdialogues . the robust natural language understanding system has been tested on a set of task-oriented interactions . the experimental results show that the proposed robust natural language understanding system is able to detect subdi-alogues in multi-agent activity , and that the robust natural language understanding system is able to detect negotiation subdialogues with high accuracy . the robust natural language understanding system is also able to detect negotiation subdialogues with high accuracy .
in this paper , we propose a novel approach to detect abnormal events of interest in large-scale video surveillance . the key idea is to learn a ranking function that captures the relative attributes -lrb- e.g. , staticness , etc. -rrb- and their relative attributes -lrb- e.g. , staticness , etc. -rrb- . we propose a novel ranking function to capture the relative attributes -lrb- e.g. , staticness , and etc. -rrb- , which captures both low-level spatial and temporal features.its attributes . we also propose a linear ranking algorithm to rank the alerts . the proposed ranking function is able to efficiently detect the presence of false alarms and false alarms , which makes the proposed ranking function more suitable for large-scale deployment . extensive experiments on two public data sets show that the proposed approach can significantly improve the detection accuracy compared to the state-of-the-art methods . moreover , the proposed ranking function can also be used to detect relative attributes -lrb- e.g. , , staticness , etc. -rrb- and improve the detection accuracy .
in this paper , we study the restless bandit problem under the assumption that the rewards of a suboptimal arm are generated by remix-ucb . the remix-ucb algorithm is a generalization of the well-known remix-ucb algorithm , and remix-ucb algorithm is a generalization of the regret analysis for the restless bandit problem . we prove that the remix-ucb algorithm converges to the optimal solution of the restless bandit problem . we also prove that the remix-ucb algorithm converges to the optimal solution of the restless bandit problem . finally , we prove that the remix-ucb algorithm converges to the optimal solution of the restless bandit problem . finally , we prove that under certain conditions , remix-mixing processes converge to the optimal solution of the restless bandit problem . finally , we prove that , under certain conditions , remix-ucb converges to the optimal solution of the restless bandit problem . finally , we show that in the case of a single arm waiting arm , remix-ucb converges to the optimal solution of the restless bandit problem . finally , we show that the problem of restless bandit problem can be efficiently solved by remix-ucb , which can be efficiently solved by remix-ucb . finally , we demonstrate the effectiveness of the proposed remix-ucb algorithm by comparing the performance of the remix-ucb algorithm with that of a suboptimal arm .
in this paper , we propose a joint diagonalization algorithm for convolutive blind source separation . the proposed joint diagonalization algorithm is based on solving the permutation problem in a hidden markov model . in the proposed joint diagonalization algorithm , a coupled hidden markov model is used to capture the psychoacoustic characteristics of signals . in the proposed joint diagonalization algorithm , the state transitions in frequency bins are estimated by solving the permutation effect in the coupled hidden markov model . in the proposed joint diagonalization algorithm , the state transitions in the coupled hidden markov model are estimated by minimizing the cross-power , a non-unitary penalty term in the frequency domain . in the proposed joint diagonalization algorithm , the proposed joint diagonalization algorithm is applied to convolutive bss . simulation studies show that the proposed joint diagonalization algorithm is very effective for convolutive bss .
in this paper , we consider the problem of multi-output fir systems driven by white non-gaussian source signals driven by white non-gaussian source signals . we propose a new maximization criteria for blind deconvolution of mimo fir systems driven by the so-called i.i.d. condition . the proposed maximization criteria are based on adaptive algorithms for blind deconvolution of mimo fir systems with source signals driven by white source signals . simulation results demonstrate the effectiveness of the proposed maximization criteria .
we consider the problem of generating images from visual attributes . given a composite of foreground and background , we propose a layered generative model to generate a set of visual attributes that describe the composite of foreground and background . our layered generative model is based on a variational auto-encoder , which is learned by minimizing an energy minimization algorithm for posterior inference of latent variables . we evaluate our layered generative model on a variety of natural images of faces , and show that our layered generative model can generate visual attributes that are useful for generating images . we also show that our layered generative model is able to generate a diverse set of visual attributes that can be used for both attribute-conditioned image reconstruction and completion .
case-based reasoning -lrb- case-based reasoning -rrb- is concerned with the problem of adapting a set of case base densities to new target domains . most approaches to case-based reasoning rely on static case adaptation knowledge , which is often expensive to obtain . in this paper , we propose adaptation-guided , a novel formalbase maintenance approach , which allows for adapting adaptation knowledge to new domains . in particular , we introduce a case difference heuristic for adapting adaptation rules to new domains . in particular , we show how to exploit the static case adaptation knowledge to improve system competence . in particular , we show how to use the case difference heuristic to update adaptation rules . in addition , we show how to exploit the compacting case bases to guide the maintenance of new cases . in numerical prediction tasks , we demonstrate the effectiveness of our approach .
in this paper , we consider the problem of estimating the eigenvalues of a linear time-periodic system from stochastic signals . the proposed linear time-periodic system is based on the monodromy matrix , which is a generalization of the least mean square algorithm to the case of stochastic signals . we provide a convergence analysis of the eigenvalues of the monodromy matrix for the linear time-periodic system and show that the proposed linear time-periodic system is superior to the conventional estimator based on the monodromy matrix .
in this paper , a perceptual weighting model for rate control is proposed . the proposed perceptual weighting model consists of three components : skin color , cognition-driven factor , and a novel skin color . the proposed perceptual weighting model has two main advantages : -lrb- 1 -rrb- the proposed perceptual weighting model is able to control the perceptual coding quality of a human visual system ; -lrb- 2 -rrb- the proposed perceptual weighting model is able to control the tradeoff between the cognition-driven factors and the performance of the proposed perceptual weighting model . -lrb- 3 -rrb- the proposed perceptual weighting model is able to control the rate control and the perceptual weighting model is able to control the tradeoff between the cognition-driven factors and the performance of the proposed perceptual weighting model . the experimental results show that the proposed perceptual weighting model can achieve better rate control than the conventional luminance adaptation , and the proposed perceptual weighting model can also be used to control the tradeoff between the perceptual coding quality and the performance of the proposed perceptual weighting model .
in this paper , we propose a corpus-based singing voice synthesis system based on hmm-based speech synthesis . the corpus-based singing voice synthesis system is designed to synthesize a smooth and natural-sounding singing voice . the corpus-based singing voice synthesis system uses hidden markov models to model the singing voice as a context-dependent hmm . in the proposed corpus-based singing voice synthesis system , a context-dependent hmm is used to model the singing style . the proposed corpus-based singing voice synthesis system is evaluated in terms of voice quality and naturalness . the results show that the proposed corpus-based singing voice synthesis system can synthesize a singing voice with high quality .
this study investigates the variations in the realization of nuclear pitch accents in three regional varieties -lrb- north carolina -rrb- variants of american english . the results show that the vowels in three regional varieties differ in their relative location of the voiced syllable coda and the relative location of the vowel onset in the midwestern varieties . the results also show that the spectral dynamics of the voiced syllable coda and the vowel onset of the voiced syllable coda are significantly different from those of the central ohio or wisconsin vowels in the midwestern varieties . the results also show that the vowel onset of the voiced syllable coda is a function of the regional accent of the melodic component of the voiced syllable coda . the results also show that the relative differences between the central ohio and the hantheastern wisconsin vowels are significantly different from those of the central ohio or wisconsin vowels in the midwestern varieties .
many problems in science and engineering require solving high dimensional problems of practical interest , such as deep or recurrent neural network training , random matrix theory , and statistical physics . in this paper , we consider the problem of finding saddle points in continuous , high dimensional spaces , such as those encountered in deep or recurrent neural network training . we propose a novel method for solving such high dimensional problems of practical interest , based on a combination of gradient descent and quasi-newton methods . we show that the local minimum of the saddle points is bounded by a small number of high dimensional saddle points , and that the local minimum of the saddle points is bounded by a small number of local minima . our method is based on a combination of local methods and local methods , and can be used to find the global minimum of the saddle points . we demonstrate the effectiveness of our method on a variety of problems from science and engineering .
in this paper , we study the projection problem of finding a subset of k-sparse vectors from a given set of vectors . we show that the problem can be formulated as a projection problem of finding a subset of k-sparse vectors subject to a certain constraint on the size of the set . we show that this problem can be solved efficiently by solving a sequence of sparse optimization . we show that , under certain conditions , the solution to the projection problem is np-hard , and that the computational complexity of the solution is o -lrb- n log -lrb- n -rrb- , where n is the number of vectors and n is the number of vectors . in particular , we show that the solution of the projection problem is np-hard , and that the solution of the solution of the problem is np-hard . we also show that the solution of the problem can be computed efficiently by exploiting the structure of the matrix ω , which can be efficiently computed by exploiting the properties of ternary or , and that the solution of the problem can be efficiently computed by exploiting the structure of the matrix ω .
latent dirichlet allocation -lrb- latent dirichlet allocation -rrb- is a popular tool for learning probabilistic models from large text corpora . in this paper , we propose an adaptive learning rate for stochastic inference . the adaptive learning rate is defined as a vari-ational objective with stochastic optimization . the vari-ational objective is a natural gradient on the subsample and has a decreasing learning rate . we show that this adaptive learning rate can be interpreted as an adaptive learning rate , which can be used as a tuning for the parameters of stochastic variational inference . we show that this adaptive learning rate can be used to learn models with hand-tuned rates , and that adaptive learning rate can be used to improve the performance of stochastic inference on large text corpora .
empirical mode decomposition -lrb- empirical mode decomposition -rrb- is a popular technique for reducing the number of interpolation points in a given dataset . in this paper , we propose a genetic algorithm framework for piecewise interpolating polynomials . the genetic algorithm framework is based on a theoretical analysis of the empirical mode decomposition and its performance analysis . the results show that the proposed genetic algorithm framework is effective in reducing the number of interpolation points in a given dataset .
bayesian belief networks -lrb- ann -rrb- are powerful probability estimators for modeling both discrete and continuous variables . in this paper , we propose a new learning scheme based on ann estimators . the proposed learning scheme is able to learn both the discrete and continuous variables of the bayesian belief networks , and the parameters of the ann estimators are jointly learned . we demonstrate the effectiveness of the proposed learning scheme on artificial neural networks , and show that learning accuracy can be improved by the proposed learning scheme .
in this paper , we propose a method to combine human and machine evaluation systems into summarization systems . the method is based on the assumption that the document sets are generated by a human and machine evaluation systems . the average score of the document sets is used to evaluate the performance of the system . the experimental results show that the proposed method outperforms the baseline system .
in this paper , we propose to use manifold learning algorithms to analyze speech data in a low dimensional space . the manifold learning algorithms learn the manifold structure of the vowels in the low dimensional space using a classical linear dimensionality reduction method . these manifold learning algorithms are then used to extract the vowels in the low dimensional space . in contrast to the classical methods , the proposed manifold learning algorithms does not require any prior knowledge of the speech sounds . the proposed manifold learning algorithms can be used to extract the vowels in the high dimensional speech signal . the experimental results show that the proposed manifold learning algorithms can effectively recover the vowels in the low dimensional space . moreover , the proposed manifold learning algorithms can be applied to speech data in order to extract the low dimensional structure of the speech signal .
this paper describes the development of a system for accessing cultural heritage . the system is based on natural language processing for navigation . the system has been built on the european library , which has been designed for the european library . the system has been designed for the european heritage , english , spanish , and english . the system has been developed for the european library . the system has been developed for the european heritage . the system has been developed for the european library , and it has been used for the evaluation of the system . the system has been developed for the european heritage . the system has been developed for the evaluation of the system . the system has been tested on the basis of eu-ropeand the results are presented .
we propose a globally optimal method for finding shortest paths in images with thin , elongated structures . our globally optimal method is based on the concept of curvature , torsion regularization , and curvature . unlike other methods , our globally optimal method does not require discretization , and is applicable to small-scale problems . our globally optimal method is based on the concept of higher-order curve properties , which we call torsion regularization . we demonstrate the effectiveness of our regularization on a variety of medical images and multi-view reconstruction .
we present a neural net architecture for segmenting complex images into two-dimensional geometrical shapes . the neural net architecture is based on a processor board , which is composed of a workstation and a digital signal processor . the neural net architecture is capable of detecting and segmenting complex images with varying lighting conditions . the neural net architecture has been implemented on a processor board . the neural net architecture has been tested on a wide range of images and is shown to be robust to changes in scale variation and lighting conditions . the neural net architecture has been successfully applied to video images of a variety of cars .
in this paper , we consider the problem of selective partial updating of the block of equaliser parameters . we formulate the block selection criterion as a constrained minimisation problem and propose a modified normalised constant mod-ulus algorithm . the proposed soft criterion satisfaction version is a full-update counterpart of the normalised constant mod-ulus algorithm , which reduces the computational complexity of the soft criterion satisfaction version by o -lrb- n 2 -rrb- , where n is the number of multiplications used in the equaliser parameters . the proposed soft criterion satisfaction version has the same convergence speed as the normalised constant mod-ulus algorithm , but with much lower implementation cost . simulation results show that the proposed soft criterion satisfaction version is superior to the full-update counterpart of the normalised constant mod-ulus algorithm in terms of convergence speed .
minimum bayes risk decoding -lrb- e-m -rrb- has been shown to be effective in speech recognition . in this paper , we propose a new e-m for lattice-based system combination and lattice rescoring . the e-m is based on the idea that the lattice of alternative outputs is more likely to be more likely to be more likely to be more likely to be more likely to have a higher word error rate than that of consensus rover and confusion network combination . we show that the e-m can be viewed as a generalization of the consensus a.k.a. confusion network decoding . we also show that the e-m can be applied to lattice rescoring and lattice rescoring .
physical task stress -lrb- physical task stress -rrb- plays an important role in the speech system . in this paper , we investigate the influence of physical task stress on the speech system performance . in particular , we investigate the influence of physical task stress on the speech system performance . in particular , we focus on the influence of physical task stress on the speech system performance , i.e. , the fundamental frequency , the glottal waveform , and the acoustic correlates of the speech features . we find that the speech system performance is affected by physical task stress , and that the speech system is affected by physical task stress . we also find that the speech system is affected by physical task stress , and that the speech system is affected by physical task stress . we also find that the speech system is affected by physical task stress , and that the speech system is affected by physical task stress , and that the utterance duration is affected by physical task stress . we find that the speech system is affected by physical task stress , and that the speech system is affected by physical task stress . we also find that the speech system is affected by physical task stress , and that the acoustic correlates of the speech features are affected by physical task stress content . the results of listener tests show that the speech system is affected by physical task stress .
this paper presents a biologically inspired anti-virus techniques that can be used to build intelligent agents that are able to communicate with computer viruses . the proposed biologically inspired anti-virus techniques are based on a neural network virus detector that can be used to detect infected and un-infected programs . the proposed biologically inspired anti-virus techniques can be used to increase the efficiency of the computer immune system . the experimental results show that the proposed biologically inspired anti-virus techniques can be used to improve the performance of the computer immune system .
computation of 3d relative motion is a fundamental problem in computational vision . the computation of optical ow from an image patch is an important problem in many applications . in this paper , we present a method for the modeling of multiple motions in the presence of outliers in the optical ow v alues component v elocity measurements . the proposed method is based on a merging process where the motion parameters are determined by a maximum likelihood estimate of the motion parameters using an em-algorithm . the proposed method is robust to occlusion boundaries and transparency in the presence of outliers in the optical ow v alues component v elocity measurements .
this paper describes umrao , a prototype chess tutor designed to address the endgame problem of real time tutoring in chess . umrao is a knowledge-based approach that generates strategic concepts in a strategy graph , and uses minimax search to find the optimal strategy graph . we describe umrao , a prototype chess tutor designed to address the problem of real time tutoring in chess . umrao is a prototype chess tutor that uses strategy graphs for real time tutoring . umrao is designed to be deployed in a computer chess , and its performance is compared with that of a chess player .
in this paper , we propose a new method for constructing bilinear time-frequency distributions . the proposed method is based on the expectation-maximisation algorithm and functional merging . the proposed method is based on a finite mixture model of the time-frequency plane . it is shown that the proposed method can be interpreted as a regional optimisation of a set of closely-spaced components in the time-frequency plane . the computational expense of the proposed method is less than the computational burden of the conventional methods . moreover , it is also shown that the proposed method can be applied to any class of time-varying kernels .
in computer vision , the structure-from-motion problem is usually formulated as a structure-from-motion problem . in this paper , we propose a novel approach to solve this structure-from-motion problem by modeling object motions as a mathematical construct of object shapes called the shape interaction matrix . the shape interaction matrix is a canonical form of a set of image features , each of which is represented by a set of features . the shape interaction matrix is a generalization of the shape interaction matrix , which allows the selection of coordinate systems at the image level . the shape interaction matrix is a generalization of the well-known concept of shape interaction matrix , and can be used for segmenting features at the image level . experimental results show that the proposed approach is able to extract object motions from a single image .
in this paper , we propose a compact yet discriminative local descrip-tor for visual search standardization . the proposed compact yet discriminative local descrip-tor is based on product quantization , which is an mpeg compact de-scriptor for matching and retrieval . unlike sift , the proposed compact yet discriminative local descrip-tor does not require table lookup operations , and can handle large numbers of descriptors . furthermore , compact yet discriminative local descrip-tor can be applied to any number of sift descriptor lengths , such as object localization , image matching , chog , and sift . the proposed compact yet discriminative local descrip-tor is scalable to large numbers of descriptors , and can handle large numbers of descriptors . compact yet discriminative local descrip-tor can be implemented efficiently using only a few seconds of product quantization . compact yet discriminative local descrip-tor has low complexity and can be applied to any number of sift descriptor lengths . the proposed compact yet discriminative local descrip-tor is evaluated on several benchmarks , including image retrieval , image matching , and object localization . the experimental results show that the proposed compact yet discriminative local descrip-tor outperforms sift and chog in terms of matching and retrieval performance .
we present a variational inference algorithm for bayesian non-conjugate inference in continuous parameter spaces . the variational inference algorithm is based on stochastic approximation of the stochastic optimi-sation . the variational inference algorithm can be interpreted as a stochastic approximation of the model joint density and kernel hyperparameters in gaussian process regression . the variational inference algorithm can be interpreted as a stochastic optimi-sation of the variational inference algorithm . illustrative examples are provided to illustrate the effectiveness of the proposed variational inference algorithm . the proposed variational inference algorithm is applied to bayesian inference problems such as variable selection and logistic regression .
context-free dynamic programming -lrb- context-free dynamic programming algorithms -rrb- algorithms are widely used in statistical parsers . however , context-free dynamic programming algorithms are often restricted to a fully-connected parse tree . in this paper , we present a new syntactic parser for a fully-connected parse tree that can be used to generate parse hypotheses . we show that this syntactic parser can be used to generate a fully-connected parse tree that can be used as a constraint in dynamic programming . our syntactic parser achieves an error reduction of up to 25 % over state-of-the-art parsers , while maintaining the same cognitive fact .
semantic parsing is the task of inferring the logical form of a knowledge base from raw text . most existing semantic parsers rely on knowledge base information , which is often expensive to obtain . in this paper , we propose a novel approach for semantic parsing that leverages knowledge base predicates to improve the performance of semantic parsers . specifically , we first extract candidate logical forms from question-answer pairs , and then extract candidate logical forms from the knowledge base predicates . then , we use a paraphrase model , namely a vector space model , to extract candidate logical forms from question-answer pairs . we evaluate our approach on two question-answering datasets , and show that our approach significantly improves the accuracies of state-of-the-art semantic parsers .
lexical resources such as wordnet , verbnet , and wordnet are widely used in many nlp tasks . however , the quality of the annotated corpora is not directly related to the quality of the parser outputs . in this paper , we propose a new nlp task , called detecting selec-tional preference violations , which is based on the assumption that the as-is lexical resources are independent of the parser outputs . the nlp task is evaluated on the resource quality of the nlp task , and the results show that the proposed nlp task achieves the best f 1-measure on the resource quality of the nlp task . we also show that the proposed nlp task can be applied to other nlp tasks such as wordnet , verbnet , and wordnet . algorithmic improvements are also discussed .
in this paper , we investigate the detection of vowel onset points in continuous speech using autoasso-ciative neural network models . the autoasso-ciative neural network models of spotting subword units -lrb- vop -rrb- are used for the recognition of cv units in continuous speech . the experimental results show that the aann models are effective for the cv class , and the aann models can be used for the detection of vowel onset points in continuous speech . in addition , the aann models can be used for the cv class , and vop can be used for the recognition of cv units .
in this paper , we propose a well-founded semantics for description logic programs with arbitrary abstract constraint atoms . the well-founded semantics is based on the notion of abstract constraint atoms , which allows us to define logic programs with arbitrary abstract constraint atoms . we show that this well-founded semantics can be computed in polynomial time for aggregate logic programs with arbitrary abstract constraint atoms . moreover , we show that this well-founded semantics can be used to compute the answer set semantics of basic logic programs with arbitrary abstract constraint atoms . we also show that this well-founded semantics can be used to compute the answer set semantics of basic logic programs with arbitrary abstract constraint atoms .
in this paper , we propose a novel method to estimate the 3d pose of a hand from a single depth image . our method is based on a purely data-driven approach , where the input data is represented by a convolutional neural network trained with a feedback loop . the convolutional neural network is trained on a single gpu , and the convolutional neural network is trained on a single gpu . the training data is then used to train deep networks , which are trained on a single gpu . we show that our method is able to accurately estimate the 3d pose of a hand from a single depth image , even when the depth image is not available .
in this paper , we propose a cluster-based approach to solving color transformation problems , such as color , and color , in which multispectral or multiprimary data are represented in tristimulus spaces . our cluster-based approach is based on a '' natural '' mapping between the source space and the target space , and uses this '' natural '' mapping to reduce the information loss caused by metamerism . the cluster-based approach can be applied to many color transformation problems , such as color , image optimization , and conversion of multispectral and multipri-mary data . the cluster-based approach can be applied to any color transformation problems , such as color , and image optimization in tristimulus colors . in addition , the cluster-based approach can be applied to any type of color transformation problems , such as color , and a natural mapping between the target and the target spaces . experimental results show that our cluster-based approach can effectively solve color deficient viewers , while preserving the natural mapping .
in this paper , we propose a novel singing voice conversion method based on many-to-many eigenvoice conversion . the proposed singing voice conversion method can synthesize voice timbre by transforming a singing voice conversion method into a probabilistic model of the voice timbre of singing voice . the proposed singing voice conversion method can be regarded as a generalization of the conventional singing voice conversion method . however , the conventional singing voice conversion method does not consider the voice timbre of singing voice . in this paper , we propose a novel method of many-to-many eigenvoice conversion to convert a singing voice conversion method into a sequence of parallel data sets based on nonparallel singing voice data from singing-to-singing synthesis system . the proposed method can be applied to singing voice conversion , speaking voice conversion , and singing voice conversion . experimental results show that the proposed method can effectively convert the training data of a singing-to-singing synthesis system into a set of parallel data sets .
in this paper , we propose a new method for source separation in the frequency domain . the proposed method is based on non linear filtering , where the gaussianity of signals is measured by the l-point discrete fourier transform . in the proposed method , the gaussianity of signals is measured by the l spectra of the l-point discrete fourier transform , and the spectral kurtosis of the signal is estimated by the proposed method . in the proposed method , the gaussianity of signals is measured by the convergence speed of the l-point discrete fourier transform . in the proposed method , the spectral kurtosis of each frequency bin is estimated by the proposed method , and the reconstruction is achieved by the proposed method . the experimental results show that the proposed method outperforms the existing methods in terms of algorithm efficiency for qarma processes .
in this paper , we present a novel approach to 3d rotation estimation based on the discrete spherical harmonic oscillator transforms . the discrete shots are represented by a set of spherical harmonics related algorithms . the spherical harmonics related algorithms are then used to estimate the spherical harmonics of a rotated signal . the spherical harmonics related algorithms are then used to estimate the spherical harmonics of the spherical harmonics . the spherical harmonics related algorithms are then used to estimate the spherical harmonics of the spherical harmonics . the robustness of the proposed approach is evaluated in terms of accuracy and robustness against noise . the experimental results show that the proposed method is able to estimate the spherical harmonics of a wide range of cartesian grids and can be used to estimate the spherical harmonics in the presence of noise .
we consider the problem of transmission tomography for electrical engineering . we consider the problem of estimating the number of count data in a compressive sensing setting . we consider the 1-regularized maximum-likelihood esti-mator n p setting , where n is the number of data points , and n is the number of data points , and n is the number of data points . we show that poisson regression can be viewed as a canonical link function for regression analysis , and that the asymp-totic sample complexity of the 1-regularized maximum-likelihood esti-mator is o -lrb- n 2 log n -rrb- , where n is the number of data points , and n is the number of data points . we show that the 1-regularized maximum-likelihood esti-mator can be viewed as a special case of the 1-regularized maximum-likelihood esti-mator , where n is the number of data points and n is the number of data points . we also show that the estimation consistency of the 1-regularized maximum-likelihood esti-mator depends on the number of data points and the number of data points . finally , we show that the canonical link function can be used for poisson regression , and that variable selection consistency can be achieved by exploiting high-dimensional statistics .
greedy decision tree induction -lrb- greedy decision tree induction algorithms -rrb- algorithms have been shown to perform well in practice , but their time complexity scales linearly with the size of the training data . in this paper , we present a novel approach to reduce the time complexity of greedy decision tree induction algorithms by exploiting problematic functions such as parity functions . our approach is based on a novel notion of lookahead , which we call lookahead . we prove that lookahead is a constant run-time penalty , and we show that lookahead can be used to reduce the time complexity of greedy decision tree learners . empirically , we show that lookahead can be used to improve the performance of greedy decision tree induction algorithms .
deep convolutional neu-ral networks -lrb- deep convolutional neu-ral networks -rrb- have been shown to be effective for semantic image segmentation . however , deep convolutional neu-ral networks are still limited to deep convolutional neu-ral networks due to their lack of contextual information for semantic segmentation . in this paper , we propose a novel approach to learn deep convolutional neu-ral networks -lrb- cnns -rrb- for semantic image segmentation . specifically , we propose a novel network design with multi-scale image input and sliding pyramid pooling to capture the semantic correlations between the patch-patch context and the patch-background context . specifically , we design cnn-based pairwise potential functions for conditional random fields to capture the correlations between the patch-patch context and the patch-patch context . specifically , we propose a novel network design with the proposed network design , which can be efficiently optimized by back propagation . the proposed network design is evaluated on two challenging semantic segmentation datasets : the challenging pascal voc 2012 dataset and nyudv2 . the experimental results show that our method significantly outperforms the state-of-the-art methods .
electroencephalography recordings -lrb- electroencephalography recordings -rrb- are widely used to model auditory attention . however , the performance of electroencephalography recordings degrades when the noise type is unknown . in this paper , we propose a novel method for decoding of noisy acoustic reference signals from acoustic reference signals . the proposed method consists of two steps : 1 -rrb- a spatio-temporal filter with regularization parameters and 2 -rrb- a spatio-temporal filter with regularization parameters . in the first step , we use a least-squares method to combine the noisy acoustic reference signals with the spatio-temporal filter design . in the second step , we apply the proposed method to clean speech signals . the experimental results show that the proposed method significantly improves the decoding accuracy of noisy acoustic reference signals when the noise type is unknown . moreover , the proposed method can be applied to the <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> in a single channel scenario .
phrasal verbs are a common phenomenon in english language , and there is a significant need for natural language processing . in this paper , we present a finite state approach to the phrasal verb identification problem . our finite state approach is based on a combination of shallow parsing and deep parsing for morpho-syntactic interaction . our finite state approach is motivated by the observation that phrasal verbs are more likely to be more likely to be more likely to have a higher probability than those in the english parser . our finite state approach is motivated by the observation that phrasal verbs are more likely to be more likely to have a higher probability than those in the english parser . we evaluate our finite state approach on two different nlp frameworks and show that our finite state approach is able to significantly improve the performance of a phrasal verb expert lexicon .
in this paper , we propose a lightweight extraction method to extract text snippets from the web . our lightweight extraction method first extracts sentences from the web , and then extracts sentences from these sentences using lexical resources . then , we extract temporally-anchored text snippets from these temporally-anchored text snippets . finally , we use these temporally-anchored text snippets as the input to the processing modules . we evaluate our temporally-anchored text snippets on two test question sets , and show that our temporally-anchored text snippets significantly outperform the state-of-the-art methods .
in this paper , we propose a method to classify a user utterance in a spoken dialogue system based on audio inputs . in our method , the user utterances are first converted into a transcription , and then the classification is performed by logistic regression on the feature set such as utterance timing , utterance length , dialogue status and utterance length . the classification is performed on the basis of the proposed method , and the classification accuracy is improved by logistic regression using the proposed features . the experimental results show that the proposed method can improve the performance of the spoken dialogue system .
this paper presents a multi-image focus of attention mechanism for building a model of structured background clutter in aerial image scenarios . the multi-image focus of attention mechanism is based on a novel structural salience measure that is able to capture the volume of space in a virtual , horizontal plane . the structural salience measure is designed to capture the structural edges of the scene in terms of back-projected gradient orientations . the proposed multi-image focus of attention mechanism is based on a space-sweep stereo method that takes into account both the structural salience of the scene and the structural edges of the scene . the proposed multi-image focus of attention mechanism is evaluated on several challenging datasets , including buildings , cars , and cars . the experimental results show that the proposed multi-image focus of attention mechanism is able to accurately estimate the scene locations , even in the presence of structured background clutter .
we describe a full-fledged , context-sensitive information system that integrates intelligent user interaction technologies into a full-fledged , context-sensitive information system . the context-sensitive interaction paradigm is designed to exploit context-sensitive information , allowing users to interact with the user 's query in order to make decisions about the user 's current query . the context-sensitive interaction paradigm is designed to exploit user data requests , allowing users to specify context-sensitive information about the user 's current query . we demonstrate the effectiveness of our full-fledged , context-sensitive information system in automated multimedia output generation and context-sensitive multimodal input interpretation .
in this paper , we present a case study on social network extraction from al-ice in wonderland , using tree kernels and support vector machines . in particular , we focus on the task of social event detection and social network extraction , and propose to use tree kernels and support vector machines to learn the parameters of an un-weighted network . we evaluate the performance of our approach on a news corpus , and show that it outperforms the baseline method by up to 8 % in f-measure for social event detection and 6 % in social network extraction . in addition , we show that the performance of the un-weighted gold network is comparable to that of the baseline system , and that the network measures do not improve the performance of the un-weighted gold network .
in this paper , we propose a method to detect glass edges in transparent objects . our method is based on visual cues derived from background texture , which can be used to detect glass surfaces in real images and classifiers . the visual cues are represented by a set of consistent support regions , which are then used to detect the presence of glass surfaces . we demonstrate the effectiveness of our method on several challenging datasets .
we present a '' soft greedy '' learning algorithm for learning classifiers from single real-valued attributes . the soft greedy '' learning algorithm is motivated by the observation that the rays in the training set are independent of the number of classes . we show that the soft greedy '' learning algorithm can be used to learn classifiers that are robust to variations in the number of classes . we test our soft greedy '' learning algorithm on two dna micro-array data sets and show that soft greedy '' learning algorithm is able to learn classifiers that are robust to variations in the number of classes . we also show that soft greedy '' learning algorithm can be used to learn the optimal combination of conjunctions and gene-expression data . we also show that soft greedy '' learning algorithm is able to learn the optimal combination of conjunctions and gene-expression data .
in frequency domain blind source separation , the filter coefficients of the frequency domain blind source separation are known to be independent of the source signals . in this paper , we propose a new method to estimate the filter coefficients in frequency domain blind source separation . the proposed method is based on the assumption that the off-diagonal components of the frequency domain blind source separation are independent of the source signals . the proposed method is based on the minimization of the mean square error of the unmixing matrix in the mean square error sense . the proposed method can be applied to frequency domain adaptive microphone arrays . simulation results show the effectiveness of the proposed method .
we propose a spectral clustering approach for undirected graphs , which is based on a spectral clustering method for directed graphs . the proposed spectral clustering approach is based on the idea of reducing the time complexity of the spectral clustering method to o -lrb- n log n -rrb- , where n is the number of nodes and n is the number of nodes in the directed graph . the proposed spectral clustering approach can be applied to both labeled and unlabeled data , where n is the number of nodes in the directed graph and n is the number of nodes in the directed graph . the proposed spectral clustering approach can be applied to a wide range of real-world web classification problems . the experimental results show that the proposed spectral clustering approach can significantly improve the performance of the spectral clustering approach for undirected graphs .
we consider the problem of price structure allocation computation in a kernel-based combinatorial auction -lrb- auction -rrb- with approximate truth-inducing payments . in the auction literature , a universal competitive equilibrium in the auction literature is obtained by exploiting the kernel function of the auction 's properties . in this paper , we study the incentive compatibility of two auction designs , one based on statistical learning theory , and another based on the kernel method . in particular , we show that in the auction literature , there exists a universal competitive equilibrium in the auction . in particular , we show that in the auction literature , there exists a universal competitive equilibrium in the auction 's properties , which is a natural measure of incentive compatibility . in particular , we show that in the auction literature , the complexity of the auction designs is exponential in the number of agents and the number of agents is exponential in the number of agents . in particular , we show that the price structure of the auction designs is exponential in the number of agents and the number of agents is proportional to the number of agents .
in this paper , we propose a flexible method for object seg-mentation that combines mid-and high-level information from multiple bottom-up segmentation models with rich region-merging cues . in contrast to existing bottom-up segmentation models , our flexible method does not require any prior knowledge of object layout , class , or object layout . instead , our flexible method learns a set of localized shape priors , which are then used to guide the segmentation process . in addition , we propose a stopping criterion that selects the best segmentation proposals according to a stopping criterion . we demonstrate the effectiveness of our flexible method on the challenging pascal voc2010 dataset , and show that our flexible method outperforms state-of-the-art methods for object seg-mentation . moreover , we show that our flexible method is able to achieve state-of-the-art performance on a variety of challenging datasets .
lexicalized reordering models have been shown to be effective in phrase-based translation systems . in this paper , we propose a novel approach to learn reordering models from a word-aligned bilingual corpus by exploiting reordering relations of adjacent phrases . in particular , we use a structure named reordering graph to learn phrase segmentations for each phrase . we evaluate our approach on the nist chinese-english test sets and show that our approach significantly outperforms several state-of-the-art reordering models . moreover , we show that our approach is able to improve the performance of a state-of-the-art phrase-based translation systems .
grapheme-to-phoneme conversion -lrb- grapheme-to-phoneme conversion -rrb- has been shown to be effective in improving the performance of an asr system . in this paper , we investigate the performance of grapheme-to-phoneme conversion on large pronunciation dictionaries -lrb- g2p -rrb- and lvcsr tasks using open source software . we show that the grapheme-to-phoneme conversion can be used to improve the performance of the grapheme-to-phoneme conversion in terms of the phoneme error rate of the g2p task . we also show that n-best pronunciation variants of the grapheme-to-phoneme conversion can be used to improve the performance of the grapheme-to-phoneme conversion . finally , we show that the grapheme-to-phoneme conversion can be used to improve the performance of the grapheme-to-phoneme conversion in terms of g2p accuracy . finally , we show that the grapheme-to-phoneme conversion can be used to improve the performance of the asr system . finally , we show that the grapheme-to-phoneme conversion can be used to improve the performance of the grapheme-to-phoneme conversion .
log mel-filterbanks -lrb- log mel-filterbanks -rrb- are widely used for adaptation of the auditory system under adverse conditions . in this paper , we propose a novel feature normalization method based on the computation load in log mfb domain using cepstral post-processing techniques . non-linear contrast stretching is applied to log mel-filterbanks to improve the noise robustness of log mel-filterbanks in adverse conditions . the processing artifacts are reduced by a two-dimensional filter in the log mfb domain using the log-scaled spectral domain . the proposed feature normalization method is compared with the baseline mfcc system in terms of both objective and objective measures . the experimental results show that the proposed feature normalization method outperforms the baseline mfcc system in terms of both objective and objective measures .
in this paper , we propose a dialogue control method that uses real-time responses to improve the performance of naturally controlled dialogue . the dialogue control method is based on the recognition processes of the human dialogue analysis and the dialogue control method of pretense-type recognition . the dialogue control method is based on the recognition processes of the human listening process of the naturally controlled dialogue . the dialogue control method is based on the recognition processes of the user 's speech and the user 's speech recognition process . the dialogue control method has been implemented in real time , and the dialogue control method has been implemented in real time . the dialogue control method has been implemented in real time , and the dialogue control method has been confirmed by the results of a human dialogue analysis .
independent component analysis -lrb- independent component analysis -rrb- has been widely used for image fusion . in this paper , we propose an adaptive fusion scheme based on the ica fusion framework . in the proposed adaptive fusion scheme , a composite image consisting of modality sensors is first extracted and then processed by independent component analysis for image fusion . the experimental results show that the proposed adaptive fusion scheme can significantly improve the performance of independent component analysis .
in this paper , we consider the estimation and localization of internal delays from end-to-end delay measurements . we propose a sequential monte carlo procedure for tracking non-stationary delay characteristics in the presence of network traffic . the sequential monte carlo procedure is based on the assumption that the internal behavior of the observation period is independent of the internal network performance . the sequential monte carlo procedure is based on the assumption that the network dynamics are independent of the internal delay distributions . the sequential monte carlo procedure is applied to estimate the internal network performance . the simulation results show that the proposed sequential monte carlo procedure is able to estimate the internal network performance even when the network traffic is not fully known . the proposed sequential monte carlo procedure is applied to the estimation of internal delays , traffic transmission protocols , and dynamic routing algorithms .
in this paper , we propose a novel feature-centric cascade , called locally assembled binary haar feature , for fast and accurate face detection . the locally assembled binary haar feature is a feature-centric cascade , which consists of a local binary pattern and a haar feature for face detection . in the locally assembled binary haar feature , the haar features are used to capture the ordinal relationship between the accumulated intensities . in the locally assembled binary haar feature , the local binary pattern and the haar feature are used for face detection . in the locally assembled binary haar feature , the local binary pattern is first designed to capture the discriminating power of the locally assembled binary haar feature . in the locally assembled binary haar feature , the local binary pattern and the haar feature are learned by the feature-centric method , and the computational cost of the locally assembled binary haar feature is reduced by o -lrb- n log n -rrb- , where n is the number of training samples . the experimental results show that the proposed locally assembled binary haar feature outperforms the conventional haar feature and the local binary pattern for face detection .
dimensionality reduction is one of the most challenging tasks in image recognition research . in this paper , we propose an iterative algorithm to learn a linear projection base from a large number of training examples . the key idea is to learn a nearest-neighbor classifier from a small number of training examples , which is then used to learn a classifier from a small number of training examples . our iterative algorithm is motivated by the observation that a small number of training examples can be used to learn a good classifier from a small number of training examples . we show that our iterative algorithm is able to learn a projection base that minimizes the classification error probability of the training examples . we demonstrate the effectiveness of our iterative algorithm by applying dimensionality reduction techniques to the problem of dimensionality reduction . we also demonstrate the effectiveness of our iterative algorithm on several challenging datasets .
in this paper , we propose a categorical approach to fine-grained sentiment analysis , which combines long-distance dependency with local information . in particular , dimensional sentiment analysis is used to map continuous numerical values to valence-arousal space va ratings of texts . in order to improve the prediction process , we propose a regional cnn-lstm model , which combines the dimensional approach with lstm for va prediction . in addition , we incorporate the long-distance dependency and the lstm for va prediction . experimental results show that our regional cnn-lstm model outperforms the state-of-the-art nn-based methods in sentiment classification , such as binary classification . furthermore , our regional cnn-lstm model achieves better performance than the state-of-the-art methods in fine-grained sentiment analysis .
professional translators are non-professional translators that produce redundant translations , but professional translators are often incapable of producing high translation quality . in this paper , we present a novel approach to professional translation that uses professional translators to provide high quality translations . our approach is based on -lrb- heuristically -rrb- calibration , and uses a set of features to determine which parts of the source sentence should be translated to the source document . we evaluate our approach on mechanical turk , and show that our approach significantly improves the translation quality of professional translators . we also show that our approach significantly improves lm perplexity , and that it improves the translation quality of professional translators . finally , we show that our approach can be used to improve the translation quality of professional translators .
in this paper , we consider the problem of denoising a sparse set of natural images , where each image is represented by a canonical transformation , and the image is represented by a sparse set of undecimated wa-velets . we propose an approximate classifier based on principal components analysis , which can be used to detect the edges in the image . we also propose a modeling strategy to find the optimal combination of compressible and incompress-the regions in the image . we also propose a posterior medif-based denoising method to estimate the parameters of the posterior mediation-based denoising method . the proposed posterior medif-based denoising method is applied to the problem of denoising a set of natural images . the experimental results show that the proposed posterior medif-based denoising method outperforms the state-of-the-art methods .
in this paper , we propose a bayesian nonparametric approach to identification of sparse dynamic linear systems . the proposed bayesian nonparametric approach is based on the assumption that impulse responses are modeled by gaussian processes . the proposed bayesian nonparametric approach is based on the assumption that the impulse responses are generated by exponential hyperpriors . the proposed bayesian nonparametric approach can be viewed as a generalization of the group lar algorithm and other parametric identification techniques based on prediction error minimization . the proposed bayesian nonparametric approach has the advantage that the proposed bayesian nonparametric approach can be applied to any class of armax models . moreover , the proposed bayesian nonparametric approach can be easily extended to other parametric identification techniques based on prediction error minimization . experimental results show that the proposed bayesian nonparametric approach outperforms the existing group lar algorithm and other parametric identification techniques based on prediction error minimization .
semi-supervised learning has been widely used in many deployed applications . however , most semi-supervised methods assume that the unlabeled data are independent , which makes them unsuitable for deployed applications . in this paper , we propose a semi-supervised learning method for exponential family parametric models . our semi-supervised learning method is based on <i> expectation regularization </i> , where the conditional label-likelihood objective function is defined as a function of the model predictions , and the conditional label-likelihood objective function is minimized via logistic regression . the proposed semi-supervised learning method can be applied to any number of data sets , including non-independent features , scales , and scale . the proposed semi-supervised learning method can be applied to any number of data sets , and can be easily applied to other data sets . we demonstrate the effectiveness of our semi-supervised learning method by comparing semi-supervised learning method with other state-of-the-art methods .
face pose estimation from magnetic sensors is an important problem in many visual tracking applications . in this paper , we propose a novel particle filter , called memory-based particle filter , to model complex dynamics with complex dynamics . memory-based particle filter is an extension of the pf formulation.our method to model complex dynamics with nonlinear , time-variant pf frameworks . memory-based particle filter is a particle filtering framework to model the markov assumption in a proper dynamics model , where the prior distribution is learned via random sampling . the proposed memory-based particle filter has two main advantages : -lrb- 1 -rrb- memory-based particle filter does not require prior prediction and can handle occlusions ; -lrb- 2 -rrb- memory-based particle filter can handle abrupt object movements ; -lrb- 3 -rrb- memory-based particle filter does not require prior prediction ; -lrb- 3 -rrb- memory-based particle filter can handle complex dynamics ; -lrb- 3 -rrb- memory-based particle filter does not require prior prediction ; -lrb- 3 -rrb- memory-based particle filter does not require prior prediction ; -lrb- 3 -rrb- memory-based particle filter does not require prior prediction ; -lrb- 3 -rrb- memory-based particle filter does not require prior prediction ; -lrb- 3 -rrb- memory-based particle filter can handle complex dynamics ; and -lrb- 3 -rrb- memory-based particle filter can handle complex dynamics with complex dynamics . extensive experiments show that memory-based particle filter outperforms state-of-the-art methods in both accuracy and efficiency .
in this paper , we consider the problem of dealing with missing inputs -lrb- incomplete feature vectors -rrb- in arbitrary feedforward networks . we propose a weighted averaged backpropagation step to deal with incomplete feature vectors , which is a generalization of the backpropagation step to handle missing features . we show that the proposed weighted averaged backpropagation step can be interpreted as a generalization of the standard backpropagation step to handle incomplete feature vectors . the proposed weighted averaged backpropagation step can be applied to any regression problem , classification , and regression problem . we present closed form solutions for the proposed weighted averaged backpropagation step and show that closed form solutions can be used to improve the recall of the proposed weighted averaged backpropagation step . the proposed weighted averaged backpropagation step has been tested on several benchmark datasets , and the results show that the proposed weighted averaged backpropagation step can achieve comparable or better performance than the current state of the art .
the extraction of statistically independent components from high-dimensional multi-sensory input streams is an important problem in sensory processing . in this paper , we present an approach to the extraction of statistically independent components from high-dimensional input streams using unsupervised learning principles . the approach is based on information bottleneck optimization and extraction of independent components . in particular , we introduce abstract information optimization principles to derive concrete learning rules for independent component analysis . in particular , we show how the information bottleneck method can be applied to a wide variety of information sources , including internal predictions , proprioceptive feedback , and blind source separation -rrb- . in particular , we show how the internal representation of the input streams can be used to derive a processing strategy for independent component analysis . in particular , we show how the information bottleneck method can be used to extract information from high-dimensional input streams .
this paper presents a holis-tic approach to subjective natural language problems . the holis-tic approach is motivated by applications in computational linguistics , problem-solving methods , and computational linguistics . the holis-tic approach has been applied to a wide range of problems , including sentiment analysis , opinion mining , and many other applications . the holis-tic approach has been successfully applied to a wide range of problems . the holis-tic approach has been successfully applied to a wide range of problems , but holis-tic approach has not received much attention . the holis-tic approach has been applied to a wide range of problems , and the holis-tic approach has been applied to a wide range of problems . the holis-tic approach has been successfully applied to a wide range of problems , but holis-tic approach has not been studied in the literature .
in this paper , we propose a phase-based local feature based on differential invariants . the phase-based local feature is based on complex-valued steerable filters and is invariant to common image deformations such as rotation , scale changes , noise , and common brightness changes . the proposed phase-based local feature is based on a set of differential invariants that capture the global and local brightness variations in the phase data . the proposed phase-based local feature is invariant to common illumination changes and 2-d rotation , and is invariant to rotation and scale changes . the proposed phase-based local feature is invariant to identity information , and can be applied to any type of image deformations such as rotation and scale changes . the proposed phase-based local feature is based on the combination of steerable filters and is robust to common image deformations . experimental results show that the proposed phase-based local feature outperforms the state of the art .
word embedding word embedding models have become popular for vectorial word representations in many nlp applications . however , most existing word embedding models are limited to finite data , which limits their generalization abilities . in this paper , we propose a novel regularized embedding formulation , called robust gram , to address the problem of overfitting . robust gram is a generalization of robust gram to finite data , and is robust to overfitting . the proposed regularized embedding formulation is evaluated on two small datasets , and the experimental results show that robust gram outperforms the state-of-the-art methods on word similarity tasks .
in this paper , we propose a novel method for sampling of foreshortened patterns from a single image . our method is based on a novel confidence measure that accounts for the effects of aliasing in the scene geometry , colors , intensities , and disexposure . we show that the proposed method can be used to improve the accuracy of structured light 3d acquisition methods . we also show that the proposed method can be applied to a wide range of infamous specularity problems , such as scanning , or disexposure . our method is based on sampling of foreshortened patterns in the scene geometry , and can be used to improve the accuracy of existing structured light 3d acquisition methods . we demonstrate the effectiveness of our method by comparing it to existing methods .
in this paper , we propose a novel feature denoising method for the speech enhancement problem . spectral conversion is used to transform noisy speech features into clean speech signal and clean speech features using an iterative kalman filter . spectral conversion is used to transform the kalman filter to the clean speech signal and the clean speech features . the proposed iterative kalman filter is evaluated in terms of average segmental output signal-to-noise ratio and average segmental output signal-to-noise ratio .
in this paper , we propose a novel approach for low-complexity channel estimation based on adaptive synchronization and sparse channel estimation in the time domain . the proposed approach is based on a non-uniform frequency offset compensation phase synchronization method , and is able to exploit the inherent structure of the channel impulse response in order to improve the performance of the low-complexity channel estimation . simulation results show that the proposed approach outperforms existing methods .
in this paper , we propose a three-stage approach to a flexible vocabulary speech understanding system for out-of-vocabulary words . the three-stage approach is based on angie sublexical models , which are trained using grapheme information . the angie sublexical models are trained using angie sublexical models , which are trained using grapheme information , and the instantaneous sound-to-letter capability is used to improve the recognition performance . in order to reduce the number of unknown words , a column-bigram finite-state transducer is adopted . in order to reduce the number of unknown words , an iterative procedure is proposed to find the word network which minimizes the sum of the phonetic and or-thographic transcriptions . the experimental results show that the proposed three-stage approach is very effective and robust to unseen data . in addition , the proposed three-stage approach has been integrated into a flexible vocabulary speech understanding system , which is a natural language processor . the experimental results show that the proposed three-stage approach is very effective and robust to out-of-vocabulary words .
in this paper , we consider the problem of parallel estimation and tracking of a low-dimensional linear subspace from a stream of observations . we formulate the data stream as a sequential low-rank matrix completion problem , and propose a recursive procedure to recover a low-dimensional subspace from the data stream . the proposed recursive procedure is based on the recursive least squares , which exploits the long-term behavior of the data stream to estimate the subspace in an online fashion . the proposed recursive procedure is compared with state of the art batch algorithms , as well as several other methods for least-squares estimation . the results show that the proposed recursive procedure is able to recover the subspace of the data stream , even when the observations are corrupted by partial observations . we demonstrate the effectiveness of the proposed recursive procedure through numerical examples for direction-of-arrival estimation .
in this paper , we consider the problem of image segmentation based on continuous global active contours . we propose a co-area formula based on nonlocal regular-ization functionals . the proposed co-area formula is based on the idea of nonlocal regular-ization functionals , which are defined on graphs . we show that the proposed co-area formula can be interpreted as a combination of nonlocal regularization functionals and nonlo-cal discrete , which can be solved efficiently by solving partial difference equations on the sub-graph . the proposed co-area formula can be applied to image segmentation and image segmentation in applications such as nonlocal image segmentation and high dimensional data clustering . the experimental results show that the proposed co-area formula can achieve better segmentation results than the state-of-the-art methods .
content-based recommendation for spoken documents is a challenging task , especially in the music and text domains . most content-based recommender systems rely on features extracted from the corpus of public domain internet audio . in this paper , we propose a novel approach to content-based recommendation for spoken documents based on features extracted from the corpus of public domain internet audio . the proposed approach is based on hybrid fusion techniques , where each feature is represented by a set of bags-of-words , each of which represents the non-linguistic aspects of the music and text domains , and the relevance judgement is measured by the relevance judgement of each source . the proposed approach is compared with a bag-of-words baseline , and the multisource approach is shown to perform better than the bag-of-words baseline . moreover , the multisource approach is shown to perform better than the bag-of-words baseline in spoken document retrieval . moreover , it is also shown that the proposed approach is more effective than the state-of-the-art music recommender systems .
in this paper , we present our work on the icsi meeting recorder corpus . the icsi meeting recorder corpus is annotated with meeting style and dialog act sequences . the labeling process consists of two steps : -lrb- 1 -rrb- automatically labeling the meetings based on the high-level group interaction tags ; -lrb- 2 -rrb- automatically labeling the meetings based on the dialog act information ; and -lrb- 3 -rrb- automatically labeling the meetings based on the labeling process . the experimental results show that our labeling system is effective for meeting style and dialog act sequences .
in this paper , we present a dialogue management strategy limited enquiry negotiation dialogues that can be used to analyze the dialogue behaviour of a dialogue designer . the dialogue management strategy limited enquiry negotiation dialogues consists of two components : a toolbox menu-traversal and slot-filling , and a dialogue designer 's standard components . we describe the dialogue management strategy limited enquiry negotiation dialogues , and describe how dialogue management strategy limited enquiry negotiation dialogues can be used to analyze the dialogue designer 's standard components . the dialogue management strategy limited enquiry negotiation dialogues has been implemented in a dialogue management strategy limited enquiry negotiation dialogues , and the dialogue management strategy limited enquiry negotiation dialogues has been designed to be used to evaluate the dialogue management strategy limited enquiry negotiation dialogues .
in this paper , we propose a m-vector approach to speaker verification based on maximum likelihood linear regression super-vectors . in the m-vector approach , the maximum likelihood linear regression super-vectors is obtained by matching lattice word transcriptions with the universal background model . in the m-vector approach , a uniform segmentation of the maximum likelihood linear regression super-vectors is used to estimate the maximum likelihood linear regression super-vectors . in the m-vector approach , the maximum likelihood linear regression super-vectors is used to estimate the maximum likelihood linear regression super-vectors from the 1-best -lrb- hypothesis -rrb- lattice word transcriptions . in the m-vector approach , the phonetic content of the lattice word transcriptions is used to estimate the maximum likelihood linear regression super-vectors . the proposed m-vector approach is evaluated on the nist sre 2008 core condition . experimental results show that the proposed m-vector approach is effective in reducing asr transcription errors .
plda has been shown to be effective in many speaker recognition scenarios . in this paper , we propose a novel plda model that incorporates multiple channels to improve the performance of plda . the proposed plda model is evaluated on telephone speech from the nist sre12 core condition , and the results show that the proposed plda model outperforms the conventional plda model in terms of minimum dcf on the nist sre12 core condition . furthermore , the inter-session variability terms can be easily incorporated into plda in order to improve the performance of plda model .
large-margin kernel machines -lrb- large-margin kernel machines -rrb- have been widely used for sequential data classification , but large-margin kernel machines have not been widely used for sequential data classification . in this paper , we propose a nonparametric bayesian inference scheme , which combines the large-margin principle with bayesian posterior inference . the large-margin principle is a component switching mechanism , which allows us to capture the local nonlinearity of complex data . efficient model training is achieved by extending the maximum entropy discrimination framework with stick-breaking priors . the proposed nonparametric bayesian inference scheme allows us to combine the large-margin principle and the bayesian nonparametrics in a principled way . we demonstrate the effectiveness of the proposed nonparametric bayesian inference scheme on several real-world datasets .
in this paper , we consider the dierence equation of a linear time-variant system with restricted parameter perturbations . we show that the linear time-variant system can be expressed as a linear time-variant system with a small number of parameters . we show that the linear time-variant system can be expressed as a linear time-variant system with a small number of parameters . then , we show that the linear time-variant system can be solved using the dierence equation . finally , we show that the linear time-variant system can be solved using the proposed method .
voice suppression is the task of estimating the beat of a song from music signals . most audio voice suppression techniques rely on pairwise combinations of beat tracking and voice suppression methods . in this paper , we propose a novel approach to beat tracking estimation from music signals . the proposed approach is based on a generic annotated collection of song excerpts containing highly predominant vocals . the beat tracking estimations are obtained by a low pass filter , which is then used for beat tracking estimations . the proposed approach is evaluated on a large database of song excerpts containing highly predominant vocals . the results show that the proposed approach outperforms state-of-the-art beat trackers .
in this paper , we propose a zero-resource approach for spoken term detection . the zero-resource approach is based on the combination of a template matching module and a template matching module to match known query words of interest to spoken term queries . the proposed zero-resource approach is evaluated on two speech templates : raw mfcc features and gaussian <s> the french and english phonetic posteri-orgrams . the zero-resource approach is evaluated on two different speech templates : the raw mfcc features and the self-similarity matrix comparison . the experimental results show that the proposed zero-resource approach is robust to speech variability and robustness to speech variability . the zero-resource approach is also compared with other train and test methods , and the results show that the proposed zero-resource approach is very effective in the information retrieval task .
in this paper , we present a collective ai that uses information content in the context of a microrobot swarm . the collective navigation is based on the use of local communication mechanisms in the context of communication hardware . we show how this information content can be used to improve the quality of the collective navigation . we illustrate the use of this information content in the context of real microro-botic , and discuss how the information content can be used to improve the quality of the collective navigation .
fisher linear discriminant analysis -lrb- fisher linear discriminant analysis -rrb- is a popular method for solving the sensitivity problem in a high dimensional feature space . in this paper , we propose a robust kernel fisher discriminant analysis , which is a generalization of fisher linear discriminant analysis to deal with data uncertainty . the proposed robust kernel fisher discriminant analysis is a generalization of fisher linear discriminant analysis to convex uncertainty models , which is a product form uncertainty model and can be efficiently solved by convex optimization . the proposed robust kernel fisher discriminant analysis is applied to the classification problem , and the experimental results show that the proposed robust kernel fisher discriminant analysis outperforms the state-of-the-art methods .
in this paper , we propose a novel low-dimensional decomposition of a low-dimensional decomposition into a regularized non-negative matrix factorization problem . we show that the proposed low-dimensional decomposition can be interpreted as a generalization of nmf with independence constraints on non-square matrices . we show that the proposed low-dimensional decomposition can be interpreted as a regularization term that can be interpreted as an extension of nmf . furthermore , we show that the proposed low-dimensional decomposition can be interpreted as a generalization of nmf with independence constraints on the observation streams . experimental results show that the proposed low-dimensional decomposition can outperform existing nonnegative ica algorithms .
in recent years , speaker-independent speech recognition technology has become increasingly important for mobile communication devices . in this paper , we investigate the use of multilingual acoustic modeling , automatic language identification , on-line pronunciation modeling , and sub-optimal on-line text-to-phoneme mapping for language-and speaker-independent asr applications . in particular , we investigate the use of language-independent asr to reduce logistic difficulties caused by speaker independence and to improve recognition accuracy . in particular , we investigate the use of multilingual acoustic models in combination with acoustic model adaptation techniques . in particular , we investigate the use of multilingual acoustic models with sparse implementation resources and dynamic vocabularies in combination with speaker-dependent as well as speaker-dependent as in combination with multilingual acoustic modeling and automatic language identification for language-and speaker-independent asr applications . experimental results show that the multilingual acoustic models achieve higher recognition rates than the baseline system .
in this paper , we consider the problem of estimating the motion eld of a planar surface from a set of images taken under the assumption of gaussian noise . we assume that the motion eld is a lower-bound-matrix , and that the viewing direction is a function of the motion and the viewing direction . we assume that the motion eld is known to be a function of the instantaneous motion eld and that the translation magnitude measurement noise is a function of the motion and the viewing direction . we show that the error co-variance depends on the estimated motion and structure p arameters , and that the error sensitivity of the estimated motion and structure p arameters to the error co-variance depends on the choice of the lower-bound-matrix , the motion-geometry connguration , and the eld of view . we show that the error sensitivity of the estimated motion and structure p arameters depends on the choice of the motion eld and the viewing direction , and that the error sensitivity of the estimated motion and structure p arameters to the error co-variance depends on the choice of the lower-bound-matrix . we also show that the error sensitivity of the unbi-ased estimator depends on the choice of the motion eld and the choice of the motion eld .
harmonet -lrb- harmonet -rrb- is a popular coding scheme for music processing . harmonet is a hierarchical system for extracting four-part chorales from music . harmonet is a popular tool for music processing , but harmonet has not been fully explored . in this paper , we present harmonet , a harmonet that uses connectionist networks for music processing . harmonet 's power is based on a coding scheme , and the harmonet 's power is optimized using error backpropagation . the harmonet 's power is evaluated on a musical real-world problem , and the results show that harmonet 's power is comparable to that of both backpropagation and symbolic algorithms , and that harmonet 's power is comparable to that of the former , and that harmonet 's power is comparable to that of the latter , and that harmonet 's power is comparable to that of the former . furthermore , harmonet 's power can be further improved by introducing a one-part melody as a one-part melody .
zero-shot action/video classification and clustering are two important tasks in computer vision . in this paper , we propose a novel object-and scene-based semantic fusion network , which is based on a large-scale cnn object-detector . the proposed object-and scene-based semantic fusion network consists of two steps : -lrb- 1 -rrb- zero-shot action/video classification and clustering , and -lrb- 2 -rrb- zero-shot action/video classification to build a semantic representation for video classes . -lrb- 3 -rrb- zero-shot action/video classification is designed to capture the semantic relationships -lrb- correlations -rrb- between object classes . -lrb- 3 -rrb- an object-and scene-based semantic fusion network is trained by a three-layer neural network . -lrb- 3 -rrb- a fusion network is designed to capture both the semantic relationships -lrb- correlations between objects and objects -rrb- and the scene semantics -lrb- correlation between objects and objects -rrb- . the proposed object-and scene-based semantic fusion network is evaluated on two challenging datasets : large-scale datasets-activitynet supervised activity recognition and video categorization . the experimental results show that the proposed object-and scene-based semantic fusion network outperforms the state-of-the-art methods .
in this paper , we present a data-driven manner for learning inter-pretable dynamic articulatory primitives from image sequences acquired by real-time magnetic resonance imaging . the proposed data-driven manner is based on the observation that the activation matrix of the inter-pretable dynamic articulatory primitives is independent of the number of parameter values . the proposed data-driven manner is based on the sparseness constraints of real-time magnetic resonance imaging . the experimental results on a recently-acquired rt-mri corpus show that the proposed data-driven manner is effective in estimating the number of parameters in an articulatory recognition task .
multiple instance learning -lrb- mil -rrb- is a fundamental problem in many machine learning applications . in this paper , we propose a novel method for learning manifold bags from finite sized bags . the key idea is to learn a high dimensional feature space by exploiting the geometric structure of the mani-fold bags . in particular , we introduce pac-learnability , a heuristic to reduce the memory requirements . in particular , we show that the proposed method can be applied to multiple instance learning , i.e. , audio , image , etc. . in particular , we show that the proposed method can be applied to many mil problems , and can be applied to a wide range of machine learning applications . experimental results on real-world data demonstrate the effectiveness of the proposed method .
visual recognition models based on object correspondences have been shown to be effective for human profile recognition . however , most visual recognition models rely on statistical learning models for human profile recognition . in this paper , we propose a novel method for learning statistical learning models for visual recognition systems from face images . the proposed method is based on incremental stochastic training of a convolutional neural network based system , where the supervision of correspondences between successive frames is limited to weak supervision . the proposed method is evaluated on three video datasets , namely , the fg-net database , and the fg-net database . the experimental results show that the proposed method is effective for gender and age estimation , and the estimation accuracy of the proposed method is comparable to that of the state-of-the-art methods . moreover , it is shown that the proposed method can be used to improve the performance of visual recognition systems in a real-world environment .
in this paper , we present a modified composition algorithm for large vocabulary speech recogntion . the recognition transducer is composed of two finite-state transducers : a context-dependent lexicon and a language model . the context-dependent lexicon is composed of a set of context-dependent phones and a language model . the recognition transducer is composed of a set of context-dependent phones and a set of context-dependent phones , each of which is a composition of the recognition transducer . the composition of the recognition transducer is determined by the number of phones in the lexicon and the number of phones in the lexicon is determined automatically by the modified composition algorithm . the proposed modified composition algorithm is evaluated on two large-vocabulary recognition tasks using the google android platform . the results show that the proposed modified composition algorithm is able to achieve a fine-grained trade-off between the number of context-dependent phones and the number of phones in decoding .
in this paper , we propose a novel global image descriptor for manhattan scenes . our global image descriptor is based on aggregate image statistics , which are invariant to translation , rotation , illumination , and occlusion . the edge shapes are represented by scale-displacement plots , and edge strengths are computed by computing the relative locations of the edge map . the proposed global image descriptor is invariant to image distortions and is robust to occlusion , cropping , translation , and occlusion . the proposed descriptor is evaluated on the zurich buildings database , and compared to a state-of-the-art compact , global image descriptor . the results show that the proposed descriptor is robust to local maxima and is robust to occlusion and illumination . the discriminative ability of the proposed descriptor is demonstrated on a variety of datasets , including the zurich buildings database . the results show that the proposed descriptor outperforms the state-of-the-art methods in terms of error rate .
in this paper , we propose a robust iterative hard thresolding algorithm for reconstructing sparse signals in impulsive environments . the proposed robust iterative hard thresolding algorithm is based on the idea of iht , which is a generalization of the iht algorithm to heavy-tailed models . the proposed robust iterative hard thresolding algorithm is based on the idea of iht , which is a generalization of iht to impulsive noise . the robustness of the proposed robust iterative hard thresolding algorithm is evaluated by comparing robust iterative hard thresolding algorithm with other recently proposed sparse reconstruction techniques . the experimental results show that the proposed robust iterative hard thresolding algorithm achieves better reconstruction quality in the presence of impulsive noise compared to the existing sparse reconstruction techniques .
we consider the finite-temperature decoding problem with multiuser demodulators in direct-sequence binary phase-shift-keying cdma channel with additive gaussian noise information . the direct-sequence binary phase-shift-keying cdma channel is modeled as a finite-temperature decoding problem with multiuser demodulators . we propose a replica analysis of the mpm -lrb- marginal posterior mode -rrb- demodulators , which is based on the mean-field approximation of the mean-field approximation of the channel . the simulation results show that the bit rate of direct-sequence binary phase-shift-keying cdma channel with multiuser demodulators is comparable to that of direct-sequence binary phase-shift-keying cdma channel with a low noise level , and the bit rate of direct-sequence binary phase-shift-keying cdma channel with multiuser demodulators is comparable to that of direct-sequence binary phase-shift-keying cdma channel with the corresponding map demodulator .
similarity metrics are widely used in image classification tasks such as face or character recognition . in this paper , we propose a novel invariant metric for regular images . the proposed invariant metric is based on the concept of multiresolution tangent distance , which is invariant to local minima -rrb- and robust estimation procedures . we show that the proposed invariant metric is robust to image transformations , and can be applied to a wide range of image classification tasks .
sparse non-negative matrix factorization -lrb- sparse non-negative matrix factorization -rrb- combines linear sparse coding with non-negative matrix factorization . in this paper , we propose a novel method to learn a parts-based representation of the data , where the approximation error is minimized by minimizing the mean square error of the generalized kullback-leibler divergence . we show that the proposed method can be viewed as a generalization of close model-non-negative sparse coding to multiplicative updates . we demonstrate the effectiveness of the proposed method on the mit-cbcl training faces data , and show that it is possible to learn a parts-based representation of the data with sparseness constraints .
map seeking circuit -lrb- map seeking circuit -rrb- is a fundamental problem in biological vision , signal processing , vision , and inverse kinematics . in this paper , we present monte-carlo approaches to the map seeking circuit . map seeking circuit is a generalization of the map seeking circuit , where the superpositions of the circuit are constrained by the ordering property of superpositions in the transformation space . in particular , we focus on the problem of transformation discovery in map seeking circuit , where the goal is to find the optimal transformation space for a given input image . we propose resource constrained implementations based on the resolution of parameter estimates in the map seeking circuit . we also propose a parallel search to find the optimal solution for the high dimensional problem . we demonstrate the effectiveness of the proposed map seeking circuit by comparing map seeking circuit with the state of the art , and show that the proposed map seeking circuit is competitive with the state of the art in terms of both computation and computation .
this paper presents a high order binaural microphone array for hearing aids based on the free-field/spherical models . the free-field model for hearing aids is based on the spherical head model and an artificial head + torso . the free-field model for hearing aids is based on the concept of sii-di . the free-field model for hearing aids is based on the spherical head model and the artificial head + torso . the free-field model for hearing aids is based on the speech-intelligibility weighted directivity index of the spherical head model . the free-field/spherical models are used for bilateral and binaural arrays . the spherical head model is compared to di and the spherical head model for hearing aids . the results show that the spherical head model outperforms di and the spherical head model for hearing aids .
discriminative classifiers such as latent dirichlet allocation , exponential family harand logistic regression have been shown to be effective in improving the accuracy of clustering and classification . however , these generative topic models do not fully exploit the latent structure of the data . in this paper , we propose a novel approach to multi-conditional learning , called mcl regularization , to simultaneously learn the latent variables and the parameters of the generative topic models . specifically , we propose a new regularizer , called multi-conditional learning , to simultaneously learn the parameters of the generative topic models and the parameters of the generative topic models . we also propose a new training criterion , called mcl regularization , to learn the parameters of mcl regularization . experiments on two text data sets show that mcl can significantly improve the performance of the discriminative classifiers in terms of both precision and recall . moreover , we show that mcl regularization improves the performance of the discriminative classifiers in terms of both precision and recall .
common spatial patterns algorithm -lrb- common spatial patterns algorithm -rrb- is a widely used tool in eeg classification and brain computer interface . in this paper , we propose a multilinear formulation for the common spatial patterns algorithm . the multilinear formulation is based on tensor analysis theory for simultaneous optimization of projection matrices and high-order tensor data . the proposed multilinear formulation has several advantages over common spatial patterns algorithm in terms of classification accuracy for multi-class motor imagery eeg . first , the proposed multilinear formulation can be applied to any specific class of common spatial patterns algorithm . second , the proposed multilinear formulation can be applied to any specific class of common spatial patterns algorithm . third , the proposed multilinear formulation can be applied to any specific class of multi-class motor imagery eeg . experimental results show that the proposed multilinear formulation can significantly improve the classification accuracy of common spatial patterns algorithm .
in this paper , we consider the problem of active task selection in a lifelong learning setting , where the goal is to select a subset of tasks that are relevant to a particular task . we focus on transfer learning in a lifelong learning setting , where the goal is to select a subset of tasks that are relevant to the task at hand . we propose a lifelong learning framework , where the goal is to select a subset of tasks that are relevant to the task at each time step , and the goal is to select a subset of tasks that are relevant to the task at each time step . we propose two lifelong learning algorithms for batch multi-task learning methods , one for lifelong learning , and one for batch multi-task learning methods . our experimental results show that the proposed lifelong learning algorithms can significantly improve the performance of batch multi-task learning methods in a variety of learning tasks . we also show that the proposed lifelong learning algorithms can significantly improve the performance of the batch multi-task learning methods when the amount of training data is limited .
in multimedia database management , the retrieval of soccer highlights is important for video indexing . in this paper , we propose an adaptive time-frequency representation based on the real soccer video . in the proposed adaptive time-frequency representation , the soccer video is first divided into two parts : -lrb- 1 -rrb- a feature extraction procedure , -lrb- 2 -rrb- an adaptive time-frequency decomposition based on the matching pursuit concept , and -lrb- 3 -rrb- an adaptive time-frequency representation based on the adaptive time-frequency decomposition . in the classification stage , an adaptive time-frequency representation is extracted from the real soccer video . in the proposed adaptive time-frequency representation , the soccer games are classified into two parts : -lrb- 1 -rrb- an adaptive time-frequency representation based on the adaptive time-frequency decomposition , and -lrb- 2 -rrb- an adaptive time-frequency representation based on the matching pursuit concept . the experimental results show that the proposed adaptive time-frequency representation is effective and robust against changes in soccer video .
in this paper , we evaluate the performance of four objective quality measures for assessing the quality of reverberant and dereverberated speech in terms of overall speech quality , reverberation tail effect , speech coloration , and reverberation tail effect . we compare the subjective rating scales of four different dereverberation algorithms and compare their performance with respect to subjective quality ratings . the results show that the proposed objective quality measures can be used to assess the performance of a variety of objective quality measures . we also show that the proposed objective quality measures can be used to assess the quality of reverberant speech .
in this paper , we consider the problem of nonlinear system inversion in the context of system inversion . we propose a new model structure for prediction which is based on parametric behavioural models . the proposed model structure allows us to use the model structure for prediction . simulation results are presented to illustrate the effectiveness of the proposed model structure .
graph cut methods have been widely used in computer vision . in this paper , we propose a new class of energy functions based on graph cuts , which we call '' settling what '' . we show that this class of energy functions can be viewed as a special case of graph cuts , where the goal is to minimize the sum of the k-wise pixel interactions between pair-wise and triplewise pixel interactions . we show that these energy functions can be efficiently solved using standard graph cuts . we also show that our new class of functions , which we call '' settling '' , can be viewed as an algebraic approach , can be used to derive approximate algorithms for the special case of pair-wise and triplewise pixel interactions . our experiments show that our new graph cut based algorithms are much more efficient than existing graph cut based algorithms .
a laboratory exercise for sampling , aliasing , and quantization is presented . the laboratory exercise is based on display capabilities for sampling , aliasing , and quantization . the laboratory exercise is tested with an a/d converter .
in this paper , we propose a vector l1 penalized pca criterion based on geodesic . the proposed vector l1 penalized pca criterion is a generalization of the svpca algorithm in that vector l1 penalized pca criterion is applied to the problem of pca or-thog, i.e. , finding the optimal solution of the original vector l1 penalized pca criterion . we show that the proposed vector l1 penalized pca criterion is superior to the svpca algorithm , and that vector l1 penalized pca criterion is much faster than the svpca algorithm .
in this paper , we present an instrumental speech-quality measure based on auditory-nerve ring-patterns . the instrumental speech-quality measure is based on the hypothesis that the mean opinion scores of the instrumental speech-quality measure are very close to those of that of the instrumental speech-quality measure . the instrumental speech-quality measure is based on the hypothesis that the mean opinion scores of the inner hair-cell model are very close to those of the inner hair-cell model . the instrumental speech-quality measure is based on the hypothesis that the instrumental speech-quality measure is very close to the mean opinion scores obtained by the instrumental speech-quality measure .
comss -lrb- maximal satisfiable subset -rrb- , minimal correction subset -rrb- , and mss -lrb- maximal satisfiable subset -rrb- , have been shown to be effective in solving a boolean cnf formula . however , comss -lrb- maximal satisfiable subset -rrb- and minimal correction subset -rrb- have not been studied in the literature . in this paper , we propose a new algorithm , called minimal correction subset -rrb- , which is based on a combination of comss -lrb- maximal satisfiable subset -rrb- and minimal correction subset -rrb- . we show that the proposed algorithm is much more efficient than comss -lrb- maximal satisfiable subset -rrb- and minimal correction subset -rrb- , and that it is much more efficient than comss and minimal correction subset -rrb- . moreover , we show that the proposed algorithm is much more efficient than comss and minimal correction subset -rrb- , and that it is much more efficient than comss -lrb- maximal satisfiable subset -rrb- .
in this paper , we propose a rapid language adaptation toolkit for automatic speech recognition of broadcast news . the rapid language adaptation toolkit consists of a language model and an un-supervised text collection and decoding strategy for text normalization . language modeling is performed on time-and topic-relevant text data . the language model interpolation is performed by 2-pass decoding of the language model and an un-supervised text collection and decoding strategy for text normalization . the proposed rapid language adaptation toolkit is evaluated on french broadcast news shows , and the word error rates are comparable to those obtained using the web 2.0 . the proposed rapid language adaptation toolkit is applied to the task of language model interpolation on twitter . the experimental results show that the proposed rapid language adaptation toolkit is very effective for language model interpolation . the proposed rapid language adaptation toolkit has been evaluated on the french broadcast news shows , and the proposed rapid language adaptation toolkit can be used for language model interpolation .
we present a wide-coverage statistical parser that uses dependency structures extracted from a combinatory categorial grammar treebank of ccg normal-form derivations . our wide-coverage statistical parser uses dependency structures as input to a wide-coverage statistical parser that uses a combinatory categorial grammar treebank of ccg normal-form derivations . unlike previous wide-coverage tree-bank parsers , our wide-coverage statistical parser does not rely on labelled dependencies , and can handle long-range dependencies . we evaluate our wide-coverage statistical parser on the penn treebank and show that our wide-coverage statistical parser outperforms previous wide-coverage tree-bank parsers . we also show that our wide-coverage statistical parser is robust to errors in extraction , control , and the presence of local predicate-argument dependencies .
in this paper , we propose a non-intrusive wide-band quality assessment algorithm based on a narrow-band quality estimate . the proposed non-intrusive wide-band quality assessment algorithm incorporates a quality prior into the non-intrusive wide-band quality assessment algorithm . the proposed non-intrusive wide-band quality assessment algorithm uses a narrow-band prior to guide the estimation of speech signal quality based on objective models . the proposed non-intrusive wide-band quality assessment algorithm is evaluated on two databases and compared with a baseline wide-band system . the results show that the proposed non-intrusive wide-band quality assessment algorithm outperforms the baseline wide-band system . moreover , the proposed non-intrusive wide-band quality assessment algorithm does not require any manually labelled databases and can be easily extended to other quality assessment models .
this paper investigates the predictive power of three different speaking styles : conversational speaking style and hyper-articulated -rrb- speaking style . we use multi-layer perceptrons and decision tree classifiers to extract spectral and prosodic features . we find that prosodic features are more robust than spectral cues , and that prosodic features are more robust to changes in speaking style than spectral cues alone . we also find that classification performance can be improved by using prosodic features alone . we also find that classification performance can be improved by using prosodic features alone .
resource constrained trustee agents in multi-agent trust networks have been shown to be an effective intelligent agent to make decisions about the worker 's reputation epinions . in this paper , we propose a reputation aware task sub-delegation approach to compute sub-delegation decisions in a crowdsourcing system . our reputation aware task sub-delegation approach is based on the concept of trust network , which has been shown to be effective in handling the resource constrained trustee agents in multi-agent trust networks . we evaluate our reputation aware task sub-delegation approach on three benchmark datasets , and show that reputation aware task sub-delegation approach can significantly improve the performance of a crowdsourcing system with high workload conditions . in addition , we show that our reputation aware task sub-delegation approach can significantly improve the quality of the sub-delegation decisions in the presence of workload . moreover , we show that our reputation aware task sub-delegation approach can be used to improve the performance of a crowdsourcing system with high workload conditions .
microphone array speech recognition -lrb- microphone array speech recognition systems -rrb- systems have been widely used for speech recognition . however , the performance of these microphone array speech recognition systems degrades significantly when the amount of noisy input is small . in this paper , we propose a new approach to improve the recognition performance of small microphone arrays by exploiting the reliability mask in missing data speech recognition . the missing data speech recognition is based on the assumption that the frequency band reliability of the decoded sequence is known . the missing data speech recognition performance of the proposed approach is evaluated by comparing the recognition performance of a baseline missing data system and a microphone array enhancement . the experimental results show that the proposed approach improves the recognition performance of small microphone arrays .
in this paper , we present a reconstruction algorithm for drawing entities from low quality drawings . our reconstruction algorithm is based on recognized dimension annotations , which are used for the detection of dimension sets in engineering drawings . the two-dimensional spatial constraints are derived from a coordinate grid structure , which allows us to extract dimension symbols from a set of dimension frames . the reconstruction algorithm is independent of the number of dimension symbols , and can be used for symbol recognition . the reconstruction algorithm is applicable to a wide range of engineering drawings . the reconstruction algorithm is applicable to a wide range of drawing entities , ranging from scanning to superresolution . the reconstruction algorithm is applicable to a wide range of engineering drawings .
in this paper , we propose an hmm-based speech synthesis system based on hmm with explicit state duration probability distributions . in the hmm-based speech synthesis system , the speech parameter vector sequence is divided into two parts : rhythm and tempo . in the hmm-based speech synthesis system , the speech parameter vector sequence is generated by hsmm training . in the hmm-based speech synthesis system , the state duration probability distributions are modeled by single gaussian distributions . in the hmm-based speech synthesis system , the speech parameter vector sequence is generated by the hsmm training . the experimental results show that the proposed hmm-based speech synthesis system can synthesize synthesized speech with high quality speech .
in this paper , we address the problem of speaker adaptation with continuous-density hidden markov model parameters . in contrast to conventional adaptation methods , where the speaker-independent hmm parameters are estimated using a set of transformation functions , we propose to use map adaptation to adapt the hmm parameters . in particular , we propose a transfer vector interpolation scheme to adapt the adaptation data to unseen units . we also propose a maximum a posteriori learning algorithm to estimate the transformation functions of the speaker-independent hmm parameters . experimental results show that the proposed transfer vector interpolation scheme is effective in reducing the mismatch between the unseen units and the adaptation data .
in this paper , we present a novel approach to modeling the compositional nature of visual objects . we propose a graphical model that captures the compo-sitional structure of objects , and a hierarchy of relevant compositions . the graphical model allows us to capture the global shape of objects , and to learn a compositional representation that captures the compositional nature of visual objects . the graphical model is then used to perform inference in a category level object recognition system based on a statistical model of the object . the compositional representation is learned from training data without supervision , and the representation complexity is linear in the number of training examples . we propose a mod-eling strategy to learn the compositions and probability distributions of the compositions . we demonstrate the effectiveness of our approach on two large standard benchmark datasets . the results show that our approach is able to learn structured object models without supervision , and that it is able to learn a compositional representation without supervision .
action recognition in videos is a challenging problem due to the high dimensionality of video data . recently , deep learning has been successfully applied to image classification . in this paper , we propose a hybrid video classification architec-tures based on unsupervised representations of hand-crafted spatio-temporal features extracted from supervised deep networks . in order to learn spatio-temporal patterns from video data , we propose a hybrid model to capture the details of the spatio-temporal patterns in video data . in addition , we propose a hybrid model to learn the parameters of these hybrid video classification architec-tures . our experimental results show that our hybrid model significantly outperforms state-of-the-art action recognition methods based on hand-crafted features . moreover , we show that our hybrid model is able to learn the parameters of deep models from manually labelled images and videos .
in this paper , we propose a novel approach for translingual spoken document retrieval -lrb- cl-sdr -rrb- based on multi-scale audio indexing . the basic idea is to use subword units to represent the chinese word tokenization ambiguity , chinese homophone ambiguity and out-of-vocabulary words in the audio indexing . the basic idea is to use subword units to represent the word unit in the multi-scale paradigm . in this way , the mei syllable recognizer is adopted as the basic unit for indexing spoken documents . in order to improve the retrieval performance of the mei syllable recognizer , we use the lattice structures and overlapping subword n-grams as the basic unit . the proposed approach is evaluated on two different tasks : speech recognition for voice of america mandarin news broadcasts and information retrieval technologies . the experimental results show that the proposed approach can improve the retrieval performance of speech recognition in both word and subword scales .
this paper presents a robust speech understanding system for spoken language processing for database retrieval . the robust speech understanding system consists of a speech recognizer , a natural language parser , a speech recognizer , and a speech recognizer based on conceptual relational grammar . the robust speech understanding system consists of three components : a robust speech understanding system , a data retrieval system based on hmm , and a robust speech understanding system based on conceptual relational grammar . the robust speech understanding system consists of three components : a robust speech understanding system , a robust speech understanding system based on hmm , and a natural language parser based on the conceptual relational grammar . the robust speech understanding system has been tested on the atis database for database query tasks . the experimental results show that the robust speech understanding system is robust and robust to large vocabulary tasks .
in this paper , we propose an analog equalization approach to reduce the reduced system complexity of a digital adaptive channel equalizer . the proposed analog equalization approach is based on a direct equalization method , where the transmitter has access to the receiver and the receiver has access to inter-symbol interference . the proposed analog equalization approach is based on the idea of digital adaptive signal processing , where transmission media uses an unshielded pair to generate local distribution networks . the proposed analog equalization approach is based on the idea of the direct equalization method . the proposed analog equalization approach is shown to be capable of achieving a reduced system complexity when compared to a conventional analog receiver .
spectral methods for semi-supervised clustering have become popular in recent years . however , most semi-supervised learning algorithms rely on background knowledge , which is often expensive to obtain . in this paper , we propose a novel approach to semi-supervised clustering , which is based on the eigenvec-tor computations of the data laplacian matrix . the key idea of our approach is to use partial supervision in the data laplacian matrix to guide the construction of a continuous semi-supervised solution . the proposed method is based on a novel clustering coherence measure , which can be interpreted as a continuous extension of the standard spectral methods to semi-supervised clustering . we provide theoretical intuitions for the proposed method , and show that it can be applied to text clustering , where the context quality of the data is measured by the proposed method . experimental results show that the proposed method can significantly improve the performance of semi-supervised methods .
in this paper , we propose a unified formulation for calcium image sequences . our unified formulation jointly estimates cell segmentations , activity estimates , impulse responses , cell shapes , and cell segmentations . we formulate the problem as an optimization problem , and solve it efficiently using heuristic pre-or postprocessing . we demonstrate the effectiveness of our unified formulation on both real and synthetic data .
in this paper , we propose a novel agcv likelihood based gaussian mixture optimization algorithm for gaussian mixture optimization . cv is a bagging-like approach in cv framework to improve model selection ability . the bagging-like approach is based on aggregated cross-validation to select a held-out subset from the model structure . the bagging-like approach is further extended to the cv framework to improve model selection ability . experiments on speech recognition show that the proposed agcv likelihood based gaussian mixture optimization algorithm outperforms the cv and mdl based methods in terms of both word error rates and score estimation in oral presentations .
in this paper , we propose a novel generative model for cosegmentation , where each image pair is represented by a set of appearance histograms . each image pair is represented by a set of patches , and each image pair is represented by a set of patches . each image pair is represented by a set of patches , and the image pair is represented by a set of patches . each image pair is represented by a set of patches , and the image pair is represented by a set of histogram matching -lrb- mrf term encoding -rrb- . inference in this generative model is np-hard , so we propose a novel optimization scheme , called trust region graph cuts , to solve the problem of term cosegmentation . in contrast to existing methods , the proposed optimization scheme does not require any global constraint on the image pair , and can be applied to many applications such as interactive image editing , video tracking , object driven image retrieval , etc. . our experimental results show that the proposed optimization scheme can significantly improve the performance of term cosegmentation .
in this paper , we address the problem of relation extraction from labeled data . we propose a joint space to jointly learn relation specific term embeddings and term pairs for each pair of term pairs . we propose a closed-form solution to solve the problem . experiments on dbpedia and medical relations show that the proposed joint space can significantly improve the performance of relation specific term embeddings .
in this paper , we propose a new method to track the separations of target in noisy speech using dynamic programming algorithms . the pitch information is used to estimate the harmonic content of the target speech signal . the pitch candidates are selected by a multi-channel autocorrelation-based estimator . the pitch tracking is performed by comparing the voiced or voiceless pitch estimates of the target speech with those of the target speech . the pitch candidates are selected based on the pitch information of the target speech signal . the proposed method is evaluated by comparing the performance of the proposed method with the conventional pitch tracking . the results show that the proposed method is effective in identifying the separations of target in interfering speech .
we present a parallel hierarchical expectation maximization algorithm for 3d point cloud data . our parallel hierarchical expectation maximization algorithm combines the advantages of deterministic spatial subdivision methods with the flexibility of stochastic sampling , allowing for compact generative representations of pcd . the key idea of our parallel hierarchical expectation maximization algorithm is to approximate the probabilistic subdivisions of the 3d point cloud data using gener-ative models , such as octrees , voxel grids , and their deterministic structures -lrb- e.g. , octrees or voxel grids -rrb- . we show that the probabilistic subdivisions of the 3d point cloud data can be approximated by a set of probabilistic subdivisions , which can be efficiently solved by maximum likelihood segmentation . we demonstrate that our parallel hierarchical expectation maximization algorithm is able to handle a wide range of spatial perception applications , including the dynamic creation of voxel grids , the model fidelity , and the model size . furthermore , we show that our parallel hierarchical expectation maximization algorithm can be used for local mixture modeling , and that parallel hierarchical expectation maximization algorithm can be used for 3d point cloud data with para-metric sparsity . we show that our parallel hierarchical expectation maximization algorithm outperforms state-of-the-art octree and ndt-based methods in terms of both run-time occupancy calculations and run-time occupancy calculations .
modern multi-modal/multimedia language resources such as collaborative annotation have become increasingly popular in recent years . however , there is still a lack of metadata descriptions for multimodal/multimedia language resources such as synchronized media and text streams . in this paper , we present a novel approach for collaborative annotation in distributed environments . our approach is based on the use of the metadata descriptions for collaborative annotation , which is based on distributed environments .
multiuser detection in ds-cdma systems requires aperiodic spreading codes , which can be used for multiuser digital signals . in this paper , we consider a multiuser parameter estimation problem , where the channel parameters are estimated by the maximum likelihood ml estimator . we propose an iterative algorithm to estimate the channel parameters by alternating optimization . the iterative algorithm converges to the global maxima of the maximum likelihood ml estimator for the channel estimation . computer simulation shows that the proposed iterative algorithm converges to the global maxima of the channel parameters , even when the medium snr values are large .
many signal processing applications rely on the dependency structure of the observed data . however , in many applications , it is often desirable to measure the significance of the observed data . in this paper , we propose a novel approach to quantify the significance of data association in high-dimensional observations . our approach is based on nonparametric tests , and is applicable to high-dimensional measurements . we demonstrate the effectiveness of our approach by comparing it to other state-of-the-art methods .
in this paper , we propose a binary mask approach to improve speech intelligibility . the binary mask is based on noise distortion constraints , which are imposed on time-frequency units of the binary mask . in the proposed binary mask approach , noise distortion constraints are imposed on the binary mask to enhance noise-corrupted speech . in the proposed binary mask approach , noise distortion constraints are imposed on the binary mask to improve speech intelligibility . in the proposed binary mask approach , noise distortion constraints are incorporated into the binary mask to improve speech intelligibility . the experimental results show that the proposed binary mask approach is effective in reducing interfering noise while maintaining high intelligibility .
in this paper , we address the problem of high-resolution color image reconstruction using a multi-scale tensor voting framework . the multi-scale tensor voting framework is used to obtain a multi-scale edge representation for high-resolution color image reconstruction from color channels . we propose a computational framework for perceptual grouping and segmentation , which is based on an edge-preserving smoothness prior . in the proposed computational framework , multi-scale tensor voting is used to recover high-resolution curves from the low-resolution color image . in the proposed computational framework , multi-scale tensor voting is used to recover the color image from the low-resolution color image , and a time-consuming learning procedure is employed to enforce the back projection constraint . the experimental results show that the proposed computational framework is effective for color image super-resolution .
in this paper , we consider frequency analysis on non-uniform data in the frequency domain . non-uniform sampling is an extension of the fourier transform approximation to the continuous time signal . we derive analytical expressions for non-uniform sampling in the frequency domain , and apply it to real life problems . in particular , we show that for embedded systems with non-uniform data , frequency analysis can be performed on the basis of non-uniform data . in particular , we show that for embedded systems with non-uniform data , the fourier transform approximation can be used to obtain a lower bound on the variance of the frequency windows . in particular , we show that the variance of the non-uniform sampling can be controlled by the use of the analytical expressions for the variance of the non-uniform sampling . finally , we discuss the application of the method to the problem of frequency analysis in the presence of non-uniform data .
in this paper , we propose a dimensionality reduction method for the segmental unit input hmm . the proposed dimensionality reduction method is called power linear discriminant analysis , which is a generalization of heteroscedastic discriminant analysis and heteroscedastic discriminant analysis to other data sets . in speech recognition experiments , the proposed dimensionality reduction method achieved better performance than conventional power linear discriminant analysis , pca , linear discriminant analysis , and heteroscedastic discriminant analysis . moreover , the proposed dimensionality reduction method can reduce the dimensionality of the segmental unit input hmm by removing the discriminative information of the input data . experimental results show that the proposed dimensionality reduction method can reduce the dimensionality of the input data by about 10 % without dimension-ality reduction .
in this paper , we propose a novel approach to nonlinear acoustic echo cancellation based on the use of a linear echo canceller . the basic idea is to use a non-linear preprocessor to estimate the echo path , which is then used as a preprocessor for echo cancellation . the proposed approach is based on the use of a linear echo canceller , which consists of two stages : -lrb- 1 -rrb- a non-linear preprocessor is used to estimate the echo path and -lrb- 2 -rrb- a set of linear kernels of the , and -lrb- 3 -rrb- a linear echo canceller . the computational complexity of the proposed approach is o -lrb- n 2 -rrb- , where n is the number of microphones and n is the number of microphones and n is the number of microphones . experimental results on speech recordings show that the proposed approach is able to outperform the state-of-the-art methods .
in this paper , we present a probabilistic model for contour discriminant observation densities in the context of localising objects . the proposed probabilistic model is based on a probabilistic model of the feature detection process . the likelihood ratio of the likelihood ratio of the likelihood ratio of the likelihood ratio of the likelihood ratio of the likelihood ratio of the likelihood of an image is derived . the proposed probabilistic model is applied to the problem of detecting and localizing objects in an image with clutter and clutter . the proposed probabilistic model is compared with other initialising contour trackers based on sampling methods .
two-dimensional frequency estimation -lrb- two-dimensional frequency estimation -rrb- is a widely used method for local frequency estimation in white gaussian additive noise . in this paper , we propose a new frequency estimator based on least square plane fitting . the new frequency estimator is shown to be robust to white gaussian additive noise , and can be interpreted as a 2-d phase unwrapping step . the robustness of the proposed 2-d frequency esti-mator is evaluated using monte carlo simulations . the results show that the proposed 2-d frequency esti-mator achieves higher noise ratio -lrb- accuracy -rrb- than the conventional 2-d frequency esti-mator in terms of robustness to white gaussian additive noise .
goal driven learning -lrb- goal driven learning -rrb- is an important component of ai systems . goal driven learning is a meta-reasoner in which learning goals are represented by a set of examples . goal driven learning is a form of goal driven learning . goal driven learning uses meta-reasoning capabilities to build a base reasoner for goal driven learning . in this paper , we present a meta-reasoning module for goal driven learning . goal driven learning is based on the observation that goal driven learning can be applied to a wide range of learning paradigms . the meta-reasoning module is based on the observation that goal driven learning can be used as a base reasoner in the airspace task orders domain . we illustrate the utility of goal driven learning by comparing goal driven learning with other learning strategies .
in this paper , we investigate the use of textual information to improve speech recognition performance on spontaneous speech . we use a lexicon and language model to recognize named entities and named entities in a speaker-by-speaker basis . the lexicon and language model are used to recognize named entities in the corpus of holocaust testials and side information . the recognition experiments were conducted on two lvcsr tasks . the recognition accuracies were compared to those obtained by using the lexicon and language model . the recognition results showed that the word error rate was reduced from 35.2 % to 36.2 % . the recognition accuracies were obtained by combining the recognition accuracies obtained by using the lexicon and language model .
in real-world customer behavior prediction problems , the objective function for a wireless service provider is to maximize the expected classification rate of a service provider . in this paper , we propose a novel classifier based on gradient-based methods to approximate the roc curve of a wireless service provider . the wilcoxon-mann-whitened statistic is a generalization of the roc curve to a wide range of real-world classification problems , such as the cross entropy and the mean squared error . the wilcoxon-mann-whitened statistic is a generalization of the roc curve to a wide range of cost functions . the wilcoxon-mann-whitened statistic is a generalization of the roc curve to a wide range of cost functions . the proposed classifier is evaluated by comparing its performance to that of a conventional cable service provider . the results show that the proposed classifier is able to predict the roc curve of a wireless service provider .
the recursive least squares algorithm is widely used in many applications . however , its convergence guarantees depend on the noise process . in this paper , we propose a new algorithm , called recursive least squares algorithm , which exploits the structure of structured input data to improve the performance of the recursive least squares algorithm . the algorithm is based on the idea of additive analysis on human speech , and it is shown that the algorithm converges to an optimal solution in the presence of noise . moreover , it is shown that the proposed algorithm converges to an optimal solution in the presence of noise .
bayesian networks are powerful tools for learning and inference tasks . in this paper , we study the structure of bayesian networks with bounded tree-width bayesian networks . we show that bounded vertex cover number bayesian networks can be learned in polynomial time with bounded tree-width networks , and that bounded vertex cover number bayesian networks can be learned in polynomial time by integer linear programming . empirically , we show that bounded vertex cover number bayesian networks can be learned in practice by solving a learning problem with bounded vertex cover number bayesian networks .
modeling pattern formation in cortical development has been studied extensively in recent years . however , little is known about the relationship between competitive and interactive cortical influences . in this paper , we analyze the relationship between competitive and competitive hebbian algorithms and common footing in the context of cortical development . we find that common footing is more likely to lead to more stable results than hebbian and competitive hebbian algorithms .
we present a framework for learning and learning trajectories from complex trajectories , using natural and artificial neural circuits . the approach is based on the idea that trajectories can be represented as a set of bounded frequencies , which are characterized by a set of paths . we show that such a framework can be used to learn models of complex trajectories , such as fast and slow oscillations . we show that these models can be used to learn models of complex trajectories , and that they can be used to learn models of complex trajectories . we also show that these models can be used to learn models of the dynamics of a robot , and that they can be used to learn models of the dynamics of the robot . we also show that these models can be used to learn models of the dynamics of the system , and that they can be used to learn models of the dynamics of the system . finally , we show that these models can be used to learn models of the dynamics of the system , and that they can be used to learn models of the dynamics of the system . finally , we show that these models can be used to learn models of the dynamics of the system , and that their universal approximation properties can be used to learn models of the dynamics of the system .
pomdp planning is the problem of finding the optimal policy for a partially observed state variables given a set of partially observed state variables . most point-based algorithms assume that the belief space is sparse , smooth beliefs , and circulant state-transition matrices . in this paper , we consider pomdp problems with sparse support and smooth beliefs , and show that the optimal policy can be computed in polynomial time . our main result is to show that , under certain belief-space properties , the optimal policy can be computed in a time polynomial time , and that the optimal solution can be computed in polynomial time . we also show that the optimal policy can be computed in time polynomial time , and that the optimal solution can be computed in time polynomial in the size of the belief space . finally , we show that the approximate solution can be computed in time polynomial in the size of the belief space .
in this paper , we present a probabilistic framework for clustering data . the probabilistic framework is based on a set of global optimization algorithms , each of which represents a taxonomy as a set of local maxima . the local maxima of the hierarchy are determined by a prob-abilistic model of the data , and the sensitivity of the hierarchy to noise is measured by a set of local steps . the proposed probabilistic framework is based on the assumption that the data are generated by a set of local maxima of the data . the proposed probabilistic framework is applied to both synthetic data and real data , and the results show that the proposed probabilistic framework is able to discover clusters with high accuracy . the proposed probabilistic framework can also be applied to other tasks such as clustering data , where the number of clusters is unknown .
in this paper , we present a method for camera calibration from uncalibrated perspective views . the method is based on the assumption that the camera parameters are known to be projective invariants of 3-d geometric configurations . the method is based on image correspondences and iterative methods . it does not require model restrictions or iterative methods . it does not require any assumptions about the camera calibration , nor does not require any assumptions about the camera parameters . the method is demonstrated on several examples .
in this paper , we propose a new clustering method based on vocal-tract parameters . the speaker clusters are clustered according to acoustic criteria , and the speaker clusters are clustered according to their acoustic criteria . the speaker clusters are clustered according to the vocal-tract parameters , and a baseline gender dependent model is adopted . the proposed clustering method is applied to japanese phoneme recognition using the vocal-tract-size related articulatory parameters . the experimental results show that the proposed clustering method can reduce recognition error by about 10 % compared to the baseline method .
in this paper , we propose a joint model for video and natural language narration in an unsupervised manner . in particular , we propose a novel annotated dataset for internet instruction videos , called narrated instruction videos , which can be used for car tire . in addition , we propose a joint model for video and natural language narration , which can be used for joint modeling video . the proposed joint model can be trained in an unsupervised manner . experimental results show that our joint model outperforms the state-of-the-art single-modality baselines .
in this paper , we propose a peak picking approach to estimate the fundamental frequency -lrb- f 0 -rrb- of an adaptive iterative refinement algorithm for speech recording . the peak picking approach is based on a full-band adaptive harmonic model , and peak picking approach is applied to the least squares solution of the least squares solution . in the proposed peak picking approach , the fundamental frequency -lrb- f 0 -rrb- is estimated from the frequency basis of an adaptive discrete fourier transform , and the f 0 curve is estimated from the training data . the proposed peak picking approach is compared with the ls solution approach in terms of average time reduction and quality of the ahm-air quality . the results show that the proposed peak picking approach is very effective in estimating the fundamental frequency -lrb- f 0 -rrb- of a speech recording .
in this paper , we present an adaptive approach for designing robust object recognition system in the wild . the proposed adaptive approach is based on the g-incorporated kernel descriptor , which is a combination of several post processing functions : photography effect filters , color tone , contrast , etc. . in order to reduce the complexity of gradient-based image descriptors , we use gradient-based image descriptors and image de-scriptors for object recognition . in order to reduce the complexity of the proposed adaptive approach , we use a set of image de-scriptors and a pixel mapping function g to learn the picture styles for object recognition . the proposed adaptive approach has been evaluated on the oxford flower data set , and the results show that the proposed adaptive approach achieves better recognition performance than the state-of-the-art methods on the oxford flower data set . moreover , the proposed adaptive approach can be applied to any domain adaptation data set , which includes digital images and photography effects .
within-class covariance normalization -lrb- within-class covariance normalization -rrb- is one of the most popular methods for intersession variability compensation in svm based speaker verification systems . within-class covariance normalization is one of the most popular methods for intersession variability compensation in svm based speaker verification systems . in this paper , we propose to use within-class covariance normalization as an alternative to within-class covariance normalization . in within-class covariance normalization , within-class covariance normalization is performed in a low dimensional feature space , and within-class covariance normalization is performed in the feature space by transforming within-class covariance normalization into a subspace . in the proposed method , within-class covariance normalization is performed by transforming within-class covariance normalization into a nuisance subspace and then applying within-class covariance normalization to within-class covariance normalization . the proposed method is evaluated on the nist sre tasks . experimental results show that within-class covariance normalization performs better than within-class covariance normalization and nuisance attribute projection .
depression state is a major depression disorder in conversational speech , sustained vowels , and vocal tract formant frequencies . in this study , we investigate the influence of articulatory precision on speech production in terms of articulatory precision on speech production . we used gaussian mixture model and support vector machine classifiers for automatically classifying depression state in audio . the gaussian mixture model was used to extract articulatory features from formant frequency tracks . the gaussian mixture model was used to train the gmms and support vector machine classifiers . the gaussian mixture model was used to classify depression state into normal , normal , normal , normal , and female speakers . the results showed that the vocal tract formant frequencies and dynamic features contribute to the depression state . the gaussian mixture model was also used to classify depression state into normal , normal , normal , and female subjects . the gaussian mixture model was able to distinguish between normal and female subjects . the results showed that the proposed gaussian mixture model was able to distinguish between depression state and depression state , and that the proposed gaussian mixture model was able to distinguish between depression state and depression state . the results also showed that the proposed gaussian mixture model was able to distinguish between depression state and depression state , which is a major depression disorder .
in this paper , we present a method for word sense disam-biguation based on the co-occurrence frequency matrix of a word . the method is applied to a set of raw corpora containing synonyms , hypernyms , merand synonyms . the method has been tested on english datum . the results show that the method is effective in identifying the correct sense of a word .
distributed kalman filtering is a classical problem in which the communication resource allocation policy is maximized . in this paper , we propose a scal-able wireless communication architecture based on the data driven average consensus framework . the scal-able wireless communication architecture allows us to exploit the inherent structure of the distributed application in wireless sensor networks . the scal-able wireless communication architecture is based on a data driven average consensus framework , which allows us to exploit the inherent structure of the kalman filtering in order to reduce the component-wise state estimation error . we show that the proposed scal-able wireless communication architecture can be applied to any number of distributed filtering computations . the proposed scal-able wireless communication architecture can be easily applied to any distributed application where filtering is performed .
in this paper , we consider the problem of variational image segmentation using shape priors . in particular , we consider the problem of learning a probabilis-tic representation of shape from a set of training images , where each pixel is represented by a set of implicit shape representations -lrb- e.g. , the space of shapes -rrb- . we show that such a probabilis-tic representation of shape can be used to define a set of shape priors for variational image segmentation . in particular , we show that under mild regularity assumptions , the shape priors can be expressed as an implicit representation of shape , which can be solved efficiently using a level set method . in particular , we show that the global versus local optimality of the solution can be achieved by exploiting the convexity of the shape priors . we demonstrate the effectiveness of our approach in the context of segmentation , tracking , and segmentation .
in this paper , we consider the problem of approximate signal processing in the presence of tradeoo between solution quality and computational cost . we propose two design criteria that guarantee the trade-off between solution quality and computational cost . the first one is based on a combination of multi-stage incremen-tal reenement algorithms . the second one is based on a combination of these two design criteria . the third one is based on a combination of these design criteria .
recently , speaker recognition technology has been successfully applied to legacy problems . in this paper , we propose a novel statistical migration technique based on stochastic synthesis of feature sequences for model migration . the statistical migration technique is based on gaussian mixture models , where the distribution of speech waveforms is represented by a set of gaussian means , priors , and configuration changes . the proposed statistical migration technique has been evaluated on the nist 2003 cellular task , and the results show that the proposed statistical migration technique outperforms the baseline mean-only migration technique in terms of mismatch accuracy . in addition , the proposed statistical migration technique does not require any prior knowledge of the distribution of the speech waveforms , and therefore can be used for migration in user voice accounts . in addition , the proposed statistical migration technique is shown to be effective in reducing the mismatch between the gaussian means and the priors . in addition , the proposed statistical migration technique is also shown to be effective in reducing the mismatch caused by configuration changes . the proposed statistical migration technique is evaluated on the nist 2003 cellular task , and the results show that the proposed statistical migration technique outperforms the mean-only method in terms of mismatch and accuracy .
automated spoken dialog systems -lrb- automated spoken dialog systems -rrb- are becoming increasingly popular in directed-dialog and natural-language applications . however , automated spoken dialog systems require systematic procedures for analyzing problems in the form of dialog system developers . in this paper , we present an interactive tool for analyzing spoken dialog systems based on empirical dialog trajectory analysis , such as stochastic finite state machines . the complexity of the automated spoken dialog systems is determined by an automatic tokenization procedure , and the application of the interactive tool to call data is discussed . the application of the proposed interactive tool to the application of dialog system developers is described . the application of the interactive tool to the application of a web dialog is discussed .
in this paper , we present a method to remove motion artifacts from mri . the method is based on a noise-free mr ima , where each subband is represented by a set of subbands , each of which represents the relative motion between the two subbands . the motion parameters of the noise-free mr ima are estimated by minimizing the sum of moand ~ l parameters . the motion parameters of the noise-free mr ima are estimated by minimizing the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the
in this paper , we present a connectionist architecture for learning the world model of behavior planning in complex environments . the central idea of our connectionist architecture is to learn state representations from motor signals , and to learn a dynamic field for the planning process . the dynamic field is based on a growing self-organizing layer , which learns the state representations of the motor layer , perception , and the motor layer . the self-organizing layer is learned from data , and the dynamics of the motor signals are learned from data . the learning process is based on the principle of lateral connectivity between the motor layer and the perception . the learning process is based on learning a dynamic field from data , and the learning process is based on hebbian ideas . we show that our connectionist architecture is able to learn both local and adaptation in complex environments .
semantic parsing -lrb- csl -rrb- is the task of assigning semantic information to a concept seg-mentation and labeling . in this paper , we propose a novel approach to semantic parsing based on similarity measures between words in the restaurant domain . specifically , we propose two semantic tree kernels : the brown clusters and the brown clusters . the first one is a classifier that uses the semantic similarity between words in the tree structures . the second one is a classifier that uses the semantic similarity between words . the second one is a csl parser that uses the semantic similarity between words in the tree structures . the third one is a classifier that uses the same processing structures in the classifier . we evaluate the performance of our approach on two benchmark datasets and show that our approach outperforms the state-of-the-art csl parser .
many machine learning applications involve model-incompatible inputs -lrb- e.g. , outliers -rrb- , such as probabilistic clustering , fuzzy k-means , and hard k-means . in this paper , we consider the problem of clustering , i.e. , the scarcity of outliers , i.e. , the number of cluster centers , and the number of clusters . we propose a general framework for clustering with well-separated subsets , where the number of clusters is unknown , and the number of clusters is unknown . we show that the computational complexity of the proposed framework is polynomial in the number of clusters , and that computational complexity is polynomial in the size of the input vectors . moreover , we show that the proposed algorithm can be implemented in closed form , and can be implemented in a variety of clustering schemes , including probabilistic clustering and fuzzy k-means . experimental results show that the proposed algorithm is much more efficient than the existing algorithms .
word segmentation and part-of-speech tagging are two important tasks in language processing . in this paper , we propose a support vector machine based chunking model to jointly estimate the pos tag and part-of-speech tagging simultaneously . in the support vector machine based chunking model , a set of predefined dictionaries are used to represent word boundaries . in the support vector machine based chunking model , a set of sequential tagging models are employed to extract the pos tag from the segmented word . support vector machine based chunking model is applied to the pos tag in the pos tagging task . the experimental results on the ws task show that the proposed support vector machine based chunking model can significantly improve the performance of the baseline system . moreover , the proposed support vector machine based chunking model achieves the best performance on the ws task .
in this paper , we propose a rspec based instantaneous frequency estimator for the analysis of nonstationary signals corrupted by heavy-tailed distribution noise in the analysis of signals . the rspec based instantaneous frequency estimator is based on a time-varying window length , which is known to be robust to rare high magnitude noise values . the proposed rspec based instantaneous frequency estimator is based on the analysis of signals corrupted by heavy-tailed distribution noise . the proposed rspec based instantaneous frequency estimator has a bias-variance trade-off between the accuracy of the rspec based if estimation and the performance of the adaptive algorithm . simulation results show that the proposed rspec based instantaneous frequency estimator outperforms the existing methods in terms of the accuracy of the estimation of the window length .
in this paper , we propose a vote-based random-projection combination for random-projection-based features . the proposed vote-based random-projection combination is a computationally simple method for computing the euclidean distance between a random matrix and a random matrix . in contrast to random projection , the proposed vote-based random-projection combination does not require any knowledge of the number of random matrices . instead , the proposed vote-based random-projection combination does not require any knowledge of the number of random matrices or the number of vectors in the sub-space . the proposed vote-based random-projection combination does not require any knowledge of the number of vectors in the training data , and can be used for speech feature extraction by random projection . the experimental results show that the proposed vote-based random-projection combination can improve the speech recognition accuracy of random-projection-based features , especially when the number of random matrices is large . the proposed vote-based random-projection combination can also be used for dimension-ality reduction in word recognition .
multi-view stereo -lrb- multi-view stereo methods -rrb- methods attempt to recover 3d reconstruction from unstructured photo collections . in this paper , we propose a novel merging algorithm that takes advantage of global visibility constraints in order to improve the quality of multi-view stereo methods . the key idea is to cast the overlapping clustering problem as constrained optimization over a set of filtering steps , which can be solved efficiently . our merging algorithm does not require any assumptions about the structure of the scene or the structure of the scene . we demonstrate the effectiveness of our merging algorithm on several challenging datasets and show that our merging algorithm significantly improves the quality of low-quality reconstructions .
in many visual recognition problems , the latent domains in the image or video datasets can be transformed into discrete domains using standard adaptation algorithms . in this paper , we consider the problem of domain adaptation , where the training and test data are drawn from different domains , and the testing data are drawn from different domains . in particular , we consider the problem of domain adaptation , where the training and test data are drawn from different domains , and the testing data are drawn from different domains . we propose a discriminative model where the training and test data are drawn from different domains , and the testing data are drawn from different domains . we propose an optimization procedure based on a nonparametric formulation of maximum distinctiveness , maximum learnability , and maximum distinctiveness . we demonstrate the effectiveness of our discriminative model on object recognition and human activity recognition tasks . in particular , we show that our discriminative model is able to deal with data distribution mismatches in the latent domains , even when the training and test data are drawn from different domains .
high efficiency video coding -lrb- hevc -rrb- is a powerful video coding standard . in this paper , we present a new paradigm for high efficiency video coding . the basic idea is to exploit the spatio-temporal redundancies present in the video sequences to improve the coding efficiency . the basic idea is to use a decoder for the encoder to reduce the signaling bitrate . the basic idea is to exploit the fact that the signal coding modes of the encoder are independent of the coding modes . the proposed paradigm is based on the observation that the signal coding modes of the encoder are independent of the coding modes of the en-coder , and the causal references of the decoder are independent of the coding scheme . we show that the proposed paradigm can achieve average bitrate saving of up to 11 % compared to hevc .
we consider the problem of predicting the conditional distribution of heuristic values given a static distribution of heuristic values , given a random sample of the start states . the conditional distribution of heuristic values is based on the assumption that the conditional distribution of heuristic values is a random sample from the static distribution of heuristic values . we propose a method to estimate the conditional distribution of heuristic values from the static distribution of heuristic values , based on the assumption that the conditional distribution of heuristic values is a random sample of the start states . we show that our method is able to estimate the exact distribution of the start states , even when the conditional distribution of heuristic values is not known . we evaluate the accuracy of our method by comparing it to a heuristic based on single start states , and show that our method is able to learn inconsistent heuristics .
in this paper , a novel array signal processing technique based on particle swarm optimization is proposed to estimate the multipath channel parameters from the transmitted signal . the proposed array signal processing technique uses particle swarm optimization to estimate the multipath channel parameters from the received signal . in the proposed array signal processing technique , the channel parameters are estimated by solving an optimization problem . simulation results show that the proposed array signal processing technique outperforms the conventional generalized expectation maximization technique and the pso based technique is robust to the snr values .
